{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install fastbpe -y\n",
    "#!conda install clang -y\n",
    "#!pip install clang\n",
    "#!pip install sacrebleu==\"1.2.11\"\n",
    "#!conda remove sacrebleu -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastBPE\n",
    "\n",
    "import preprocessing.src.code_tokenizer as code_tokenizer\n",
    "from XLM.src.data.dictionary import Dictionary, BOS_WORD, EOS_WORD, PAD_WORD, UNK_WORD, MASK_WORD\n",
    "from XLM.src.model import build_model\n",
    "from XLM.src.utils import AttrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH='model/model_1.pth'\n",
    "\n",
    "model = torch.load(MODEL_PATH, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 30,\n",
       " 'n_total_iter': 3255,\n",
       " 'best_metrics': {},\n",
       " 'best_stopping_criterion': None,\n",
       " 'encoder': OrderedDict([('module.position_embeddings.weight',\n",
       "               tensor([[-0.0095,  0.0503,  0.0038,  ...,  0.0156, -0.0090, -0.0427],\n",
       "                       [ 0.0224,  0.0274, -0.0191,  ..., -0.0009, -0.0053, -0.0260],\n",
       "                       [ 0.0108,  0.0206,  0.0008,  ...,  0.0028, -0.0196, -0.0109],\n",
       "                       ...,\n",
       "                       [ 0.0151, -0.0050,  0.0265,  ..., -0.0256,  0.0176, -0.0139],\n",
       "                       [ 0.0186, -0.0235, -0.0098,  ..., -0.0160,  0.0303,  0.0023],\n",
       "                       [-0.0230,  0.0086,  0.0015,  ...,  0.0154, -0.0029,  0.0096]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.lang_embeddings.weight',\n",
       "               tensor([[ 0.0027,  0.0025,  0.0109,  ..., -0.0143,  0.0063,  0.0066],\n",
       "                       [ 0.0016, -0.0080,  0.0105,  ..., -0.0008,  0.0116,  0.0109],\n",
       "                       [ 0.0046, -0.0050,  0.0110,  ...,  0.0222,  0.0029,  0.0070]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.embeddings.weight',\n",
       "               tensor([[-0.0027,  0.0350, -0.0067,  ..., -0.0880,  0.0496,  0.0398],\n",
       "                       [-0.0480,  0.0035,  0.0121,  ...,  0.0016, -0.0303,  0.0152],\n",
       "                       [-0.0391,  0.0273,  0.0157,  ..., -0.0782, -0.0212,  0.0021],\n",
       "                       ...,\n",
       "                       [-0.0252, -0.0506, -0.0354,  ..., -0.0431,  0.0506,  0.0500],\n",
       "                       [-0.0274,  0.0699,  0.0352,  ..., -0.0271, -0.0021, -0.0391],\n",
       "                       [ 0.0297, -0.0688, -0.0042,  ..., -0.0880,  0.0251, -0.0300]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm_emb.weight',\n",
       "               tensor([0.5601, 0.4932, 0.4907,  ..., 0.3596, 0.4226, 0.5029],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm_emb.bias',\n",
       "               tensor([-0.0169, -0.0542, -0.0559,  ..., -0.0329,  0.0228, -0.0206],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.q_lin.weight',\n",
       "               tensor([[-0.0002, -0.0928,  0.0327,  ..., -0.0751,  0.0234,  0.0571],\n",
       "                       [-0.0903, -0.0177, -0.0189,  ..., -0.0553, -0.0143, -0.0099],\n",
       "                       [ 0.0669, -0.0993,  0.0330,  ...,  0.0161, -0.0320, -0.0341],\n",
       "                       ...,\n",
       "                       [-0.0138, -0.0271, -0.0089,  ..., -0.0439, -0.0521,  0.0711],\n",
       "                       [ 0.0374,  0.0258, -0.0851,  ...,  0.0525,  0.0072,  0.0685],\n",
       "                       [ 0.0829,  0.1621, -0.0424,  ...,  0.0088,  0.0141, -0.0450]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.q_lin.bias',\n",
       "               tensor([-0.1901,  0.1615,  0.1757,  ...,  0.1613, -0.2607,  0.1310],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.k_lin.weight',\n",
       "               tensor([[ 0.0300,  0.0428,  0.0322,  ..., -0.0221,  0.0182, -0.0563],\n",
       "                       [-0.0394,  0.0177, -0.0555,  ...,  0.0102,  0.0197,  0.0043],\n",
       "                       [-0.1019,  0.0801,  0.0087,  ..., -0.0273,  0.0535,  0.0184],\n",
       "                       ...,\n",
       "                       [ 0.0354,  0.0318,  0.0123,  ..., -0.0131, -0.0063, -0.0378],\n",
       "                       [ 0.0194, -0.0528,  0.0505,  ..., -0.0173, -0.0578,  0.0383],\n",
       "                       [ 0.0053,  0.0151,  0.0151,  ...,  0.0604, -0.0360, -0.0142]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.k_lin.bias',\n",
       "               tensor([ 0.0111, -0.0001, -0.0178,  ..., -0.0212,  0.0528,  0.0181],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.v_lin.weight',\n",
       "               tensor([[-0.0320, -0.0184, -0.0451,  ...,  0.0589,  0.0177, -0.0008],\n",
       "                       [-0.0392,  0.0094,  0.0145,  ..., -0.0828, -0.0083, -0.0208],\n",
       "                       [-0.0576,  0.0473, -0.0302,  ...,  0.0293,  0.0500, -0.0223],\n",
       "                       ...,\n",
       "                       [-0.0263,  0.0237,  0.0413,  ..., -0.0270,  0.0013, -0.0373],\n",
       "                       [-0.0179, -0.0203, -0.0350,  ...,  0.0303,  0.0090, -0.0045],\n",
       "                       [-0.0432,  0.0806,  0.0044,  ..., -0.0026, -0.0193,  0.0249]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.v_lin.bias',\n",
       "               tensor([ 0.0030, -0.0265,  0.0111,  ..., -0.0245,  0.0073, -0.0233],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.out_lin.weight',\n",
       "               tensor([[ 0.0064, -0.0244,  0.0326,  ..., -0.0139,  0.0169,  0.0025],\n",
       "                       [ 0.0378, -0.0291, -0.0259,  ...,  0.0065,  0.0332, -0.0193],\n",
       "                       [ 0.0351, -0.0189,  0.0518,  ...,  0.0363, -0.0025,  0.0011],\n",
       "                       ...,\n",
       "                       [ 0.0742,  0.0276, -0.0202,  ...,  0.0162, -0.0029, -0.0204],\n",
       "                       [-0.0510, -0.0577, -0.0445,  ...,  0.0403, -0.0041,  0.0245],\n",
       "                       [-0.0279,  0.0540, -0.0317,  ...,  0.0056, -0.0108,  0.0189]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.out_lin.bias',\n",
       "               tensor([-0.0124,  0.0069,  0.0312,  ..., -0.0095,  0.0230, -0.0049],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.q_lin.weight',\n",
       "               tensor([[-0.0028,  0.0179, -0.0191,  ..., -0.0524, -0.0042, -0.0524],\n",
       "                       [-0.0009, -0.0567, -0.0369,  ...,  0.0163,  0.0640,  0.0174],\n",
       "                       [ 0.0043, -0.0142,  0.0571,  ...,  0.0301, -0.0587, -0.0476],\n",
       "                       ...,\n",
       "                       [ 0.0219,  0.0385,  0.0159,  ...,  0.0838,  0.0373, -0.0009],\n",
       "                       [ 0.0223,  0.0156,  0.0057,  ...,  0.0069, -0.0258, -0.0513],\n",
       "                       [-0.0052, -0.0086,  0.0649,  ...,  0.0953,  0.0144,  0.0701]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.q_lin.bias',\n",
       "               tensor([ 0.0551, -0.0065, -0.0593,  ...,  0.3005, -0.3032, -0.1682],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.k_lin.weight',\n",
       "               tensor([[ 0.0198, -0.0086,  0.0364,  ...,  0.0160,  0.0341, -0.0120],\n",
       "                       [-0.0731,  0.0085, -0.0406,  ...,  0.0040,  0.0510,  0.0282],\n",
       "                       [-0.0253, -0.0368,  0.0006,  ..., -0.0197, -0.0003,  0.0284],\n",
       "                       ...,\n",
       "                       [ 0.0862,  0.0092,  0.0069,  ...,  0.0620, -0.0040, -0.0325],\n",
       "                       [ 0.0013, -0.0064,  0.0390,  ..., -0.0029, -0.0352, -0.0739],\n",
       "                       [-0.0143,  0.0452,  0.0676,  ...,  0.0252,  0.1487, -0.0208]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.k_lin.bias',\n",
       "               tensor([ 0.0150,  0.0450,  0.0295,  ...,  0.0539, -0.1843, -0.0031],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.v_lin.weight',\n",
       "               tensor([[-0.0177, -0.0336,  0.0242,  ...,  0.0378, -0.0171, -0.0774],\n",
       "                       [-0.0143, -0.0141, -0.0953,  ...,  0.0056,  0.0065, -0.0152],\n",
       "                       [-0.0408, -0.0168, -0.0078,  ..., -0.0191,  0.0343,  0.0098],\n",
       "                       ...,\n",
       "                       [ 0.0032, -0.0036,  0.0463,  ..., -0.0187, -0.0197,  0.0305],\n",
       "                       [ 0.0143,  0.0255,  0.0441,  ...,  0.0300,  0.0248,  0.0107],\n",
       "                       [ 0.0630, -0.0036, -0.0258,  ...,  0.0434,  0.0277, -0.0803]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.v_lin.bias',\n",
       "               tensor([ 0.0060,  0.0144, -0.0057,  ..., -0.0203,  0.0001, -0.0097],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.out_lin.weight',\n",
       "               tensor([[ 0.0029, -0.0006, -0.0013,  ...,  0.0144, -0.0140, -0.0247],\n",
       "                       [ 0.0491, -0.0112,  0.0438,  ..., -0.0211,  0.0517, -0.0309],\n",
       "                       [-0.0314,  0.0101,  0.0350,  ..., -0.0345,  0.0686, -0.0065],\n",
       "                       ...,\n",
       "                       [ 0.0621,  0.0025,  0.0962,  ...,  0.0405, -0.2051,  0.0036],\n",
       "                       [-0.0520,  0.0010, -0.0526,  ...,  0.0267,  0.0806, -0.0306],\n",
       "                       [ 0.0452, -0.0349,  0.0165,  ..., -0.0801,  0.0390, -0.0182]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.out_lin.bias',\n",
       "               tensor([-0.0059,  0.0039,  0.0001,  ..., -0.0106,  0.0061, -0.0131],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.q_lin.weight',\n",
       "               tensor([[ 0.0402,  0.0368, -0.0126,  ...,  0.0286, -0.0384, -0.0308],\n",
       "                       [-0.0737, -0.0246, -0.1005,  ..., -0.0056, -0.0938,  0.0116],\n",
       "                       [ 0.1061, -0.0526, -0.1038,  ..., -0.0176,  0.0779, -0.0242],\n",
       "                       ...,\n",
       "                       [ 0.0182,  0.0084, -0.0211,  ..., -0.0175, -0.0880,  0.0059],\n",
       "                       [ 0.0451,  0.0326, -0.0325,  ...,  0.0398,  0.0236, -0.0475],\n",
       "                       [-0.0153,  0.0044, -0.0194,  ..., -0.0167, -0.0471, -0.0410]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.q_lin.bias',\n",
       "               tensor([ 0.3979, -0.0129,  0.0826,  ..., -0.0617, -0.0966,  0.0656],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.k_lin.weight',\n",
       "               tensor([[ 0.0055,  0.0467,  0.0225,  ...,  0.0938, -0.1024, -0.0219],\n",
       "                       [-0.0188,  0.0248, -0.0058,  ..., -0.2227, -0.0073, -0.0417],\n",
       "                       [-0.0710,  0.1197,  0.0423,  ..., -0.0319, -0.0534, -0.0028],\n",
       "                       ...,\n",
       "                       [-0.0164, -0.0435,  0.0470,  ..., -0.0638, -0.0125, -0.0266],\n",
       "                       [-0.0595,  0.0235,  0.0153,  ..., -0.0413,  0.0030,  0.0337],\n",
       "                       [-0.0205, -0.0384,  0.0145,  ...,  0.0139,  0.0339, -0.0261]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.k_lin.bias',\n",
       "               tensor([-0.1293,  0.0322,  0.0640,  ..., -0.0770,  0.0099,  0.0219],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.v_lin.weight',\n",
       "               tensor([[-0.0768,  0.0840,  0.0336,  ...,  0.0534,  0.0300,  0.0362],\n",
       "                       [ 0.0668,  0.0085,  0.0027,  ..., -0.0174,  0.0234,  0.0260],\n",
       "                       [-0.0186,  0.0021, -0.0245,  ...,  0.0012, -0.0205, -0.0329],\n",
       "                       ...,\n",
       "                       [ 0.0236, -0.0043,  0.0736,  ..., -0.0105, -0.0732,  0.0489],\n",
       "                       [-0.0126, -0.0323, -0.0109,  ...,  0.0359, -0.0509, -0.0013],\n",
       "                       [-0.0616,  0.0628, -0.0333,  ..., -0.0367, -0.0078,  0.0045]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.v_lin.bias',\n",
       "               tensor([-0.0159,  0.0046, -0.0006,  ...,  0.0019, -0.0158, -0.0016],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.out_lin.weight',\n",
       "               tensor([[-0.0170,  0.0345,  0.0330,  ...,  0.0271, -0.0151, -0.0114],\n",
       "                       [ 0.0317, -0.0509,  0.0146,  ...,  0.0522,  0.0878,  0.0468],\n",
       "                       [-0.0975,  0.0401, -0.0169,  ..., -0.0090,  0.0340, -0.0034],\n",
       "                       ...,\n",
       "                       [-0.0273,  0.0890,  0.0139,  ..., -0.0178,  0.0077,  0.0688],\n",
       "                       [-0.0023, -0.0113, -0.0268,  ...,  0.0253,  0.0643,  0.0478],\n",
       "                       [ 0.0277, -0.0142, -0.0253,  ...,  0.0029, -0.0643,  0.0466]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.out_lin.bias',\n",
       "               tensor([-0.0040,  0.0004,  0.0007,  ..., -0.0214, -0.0071, -0.0083],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.q_lin.weight',\n",
       "               tensor([[-0.0477, -0.0248,  0.0435,  ...,  0.0011, -0.0369,  0.0167],\n",
       "                       [-0.0665, -0.0251, -0.0437,  ...,  0.0767,  0.0412, -0.1169],\n",
       "                       [ 0.0265, -0.0374, -0.0162,  ..., -0.0131, -0.0010, -0.0021],\n",
       "                       ...,\n",
       "                       [ 0.0262, -0.0312, -0.1578,  ...,  0.0844,  0.0616, -0.0328],\n",
       "                       [ 0.0747,  0.0233, -0.0244,  ...,  0.0720,  0.0944, -0.0407],\n",
       "                       [-0.0074,  0.0075, -0.0137,  ...,  0.1180,  0.0013,  0.1410]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.q_lin.bias',\n",
       "               tensor([-0.0316,  0.1356, -0.0358,  ..., -0.1119,  0.1421,  0.1515],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.k_lin.weight',\n",
       "               tensor([[-0.0047, -0.0127, -0.0429,  ..., -0.0031,  0.0204,  0.0027],\n",
       "                       [ 0.0485, -0.0887,  0.0336,  ...,  0.0482,  0.0077, -0.0086],\n",
       "                       [-0.0670, -0.0246, -0.0545,  ...,  0.1289, -0.0397, -0.0382],\n",
       "                       ...,\n",
       "                       [-0.0619, -0.0244,  0.0872,  ..., -0.0328, -0.0990, -0.0829],\n",
       "                       [ 0.0227, -0.0465,  0.0147,  ..., -0.0802, -0.1226, -0.0598],\n",
       "                       [-0.0739, -0.0132, -0.0905,  ..., -0.0454,  0.0459,  0.0190]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.k_lin.bias',\n",
       "               tensor([ 0.0374,  0.1003,  0.0879,  ..., -0.2991,  0.3259,  0.3665],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.v_lin.weight',\n",
       "               tensor([[-0.0172,  0.0559,  0.0200,  ...,  0.0096, -0.0989, -0.0117],\n",
       "                       [-0.0279,  0.0076, -0.0551,  ...,  0.0513,  0.0144,  0.0150],\n",
       "                       [ 0.0523, -0.0528, -0.0613,  ..., -0.0386, -0.0104,  0.0157],\n",
       "                       ...,\n",
       "                       [ 0.0192, -0.0045, -0.0023,  ...,  0.0197, -0.0243, -0.0232],\n",
       "                       [-0.0260,  0.0276,  0.0021,  ..., -0.0432,  0.0251, -0.0545],\n",
       "                       [ 0.0033, -0.0253,  0.0136,  ..., -0.0900, -0.0645, -0.0084]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.v_lin.bias',\n",
       "               tensor([-0.0108, -0.0138,  0.0017,  ...,  0.0117, -0.0091,  0.0004],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.out_lin.weight',\n",
       "               tensor([[-0.0036,  0.0098,  0.0107,  ...,  0.0284, -0.0263, -0.0210],\n",
       "                       [-0.0257, -0.0029, -0.0077,  ..., -0.0082, -0.0072, -0.0323],\n",
       "                       [-0.0520, -0.0257,  0.0284,  ..., -0.0239, -0.0168,  0.0344],\n",
       "                       ...,\n",
       "                       [ 0.0376, -0.0014, -0.0262,  ...,  0.0442,  0.1093,  0.0102],\n",
       "                       [ 0.0478,  0.0622,  0.0797,  ..., -0.0311,  0.1453, -0.0765],\n",
       "                       [ 0.0642,  0.0417, -0.0370,  ...,  0.0048, -0.0715, -0.0309]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.out_lin.bias',\n",
       "               tensor([-0.0015,  0.0024,  0.0005,  ..., -0.0156,  0.0009, -0.0150],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.q_lin.weight',\n",
       "               tensor([[-0.0584, -0.0447, -0.0182,  ...,  0.0171,  0.0061,  0.0104],\n",
       "                       [ 0.0309, -0.0195, -0.0170,  ..., -0.0275,  0.0169, -0.0515],\n",
       "                       [-0.0069,  0.0171, -0.0150,  ...,  0.0468,  0.0429, -0.0150],\n",
       "                       ...,\n",
       "                       [-0.0046,  0.0144,  0.0897,  ...,  0.1763, -0.0276,  0.1179],\n",
       "                       [ 0.0410, -0.0154,  0.0063,  ..., -0.0611, -0.0475,  0.0127],\n",
       "                       [ 0.0051, -0.0192,  0.0677,  ..., -0.0191,  0.0469,  0.0282]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.q_lin.bias',\n",
       "               tensor([-0.0175,  0.1377, -0.0790,  ...,  0.2505,  0.1559, -0.3853],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.k_lin.weight',\n",
       "               tensor([[-0.0276,  0.0535, -0.0023,  ...,  0.1101, -0.0703,  0.0051],\n",
       "                       [-0.0172,  0.0762, -0.0359,  ...,  0.0157,  0.0238, -0.0010],\n",
       "                       [ 0.0458,  0.0311, -0.0058,  ..., -0.0060,  0.0419, -0.0924],\n",
       "                       ...,\n",
       "                       [-0.0489,  0.0759,  0.0923,  ..., -0.0296, -0.0823,  0.0508],\n",
       "                       [ 0.0807,  0.0574,  0.0544,  ...,  0.0358,  0.0541, -0.0645],\n",
       "                       [ 0.0453, -0.0209, -0.0840,  ..., -0.1143, -0.0113, -0.0099]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.k_lin.bias',\n",
       "               tensor([-0.8550, -0.9575,  0.4434,  ...,  3.2734,  2.6250, -3.4473],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.v_lin.weight',\n",
       "               tensor([[ 0.0147,  0.0395, -0.0349,  ...,  0.0089,  0.0054,  0.0709],\n",
       "                       [-0.1148,  0.0044,  0.0215,  ..., -0.0731,  0.0490,  0.0275],\n",
       "                       [ 0.0214,  0.1035, -0.0464,  ..., -0.0443,  0.0454, -0.0004],\n",
       "                       ...,\n",
       "                       [ 0.0506, -0.0343, -0.0086,  ...,  0.0165,  0.0790, -0.0521],\n",
       "                       [-0.0189,  0.0217,  0.0020,  ..., -0.0575, -0.0102,  0.0115],\n",
       "                       [ 0.0190, -0.0331, -0.0972,  ..., -0.0690,  0.0441, -0.0471]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.v_lin.bias',\n",
       "               tensor([ 0.0362,  0.0098,  0.0057,  ...,  0.0289,  0.0240, -0.0414],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.out_lin.weight',\n",
       "               tensor([[-0.0041,  0.0811, -0.0045,  ...,  0.0187, -0.0185,  0.0095],\n",
       "                       [ 0.0178,  0.0233, -0.0916,  ...,  0.0399,  0.0011,  0.0388],\n",
       "                       [ 0.0156,  0.0382, -0.0121,  ...,  0.0069, -0.0313,  0.0237],\n",
       "                       ...,\n",
       "                       [-0.0107,  0.0635,  0.0764,  ..., -0.0250,  0.0937, -0.0369],\n",
       "                       [-0.0045, -0.0231,  0.0089,  ...,  0.0616, -0.0612,  0.0663],\n",
       "                       [-0.0394, -0.0218,  0.0052,  ..., -0.0108, -0.0547,  0.0573]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.out_lin.bias',\n",
       "               tensor([-0.0014,  0.0017,  0.0007,  ..., -0.0096, -0.0039, -0.0081],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.q_lin.weight',\n",
       "               tensor([[-0.0652, -0.0032, -0.1063,  ..., -0.0244, -0.0614,  0.0612],\n",
       "                       [ 0.0180, -0.0564,  0.0019,  ...,  0.1289,  0.0436, -0.0083],\n",
       "                       [-0.0444, -0.0141,  0.0049,  ..., -0.0644,  0.0157,  0.0701],\n",
       "                       ...,\n",
       "                       [-0.0007, -0.1107, -0.0499,  ...,  0.0476, -0.0714, -0.0472],\n",
       "                       [-0.0295, -0.0382, -0.0248,  ..., -0.0374,  0.0054,  0.0707],\n",
       "                       [ 0.0287, -0.0442, -0.0306,  ..., -0.0065, -0.0037,  0.0526]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.q_lin.bias',\n",
       "               tensor([-0.0857,  0.1884, -0.0797,  ..., -0.1194, -0.0158,  0.2791],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.k_lin.weight',\n",
       "               tensor([[ 0.0291, -0.0966, -0.0467,  ...,  0.0589,  0.0702,  0.0047],\n",
       "                       [ 0.0369,  0.0034,  0.0159,  ...,  0.0684, -0.0358, -0.0467],\n",
       "                       [ 0.0466, -0.0124, -0.0529,  ...,  0.0092,  0.0130,  0.0030],\n",
       "                       ...,\n",
       "                       [-0.0534,  0.0468, -0.0251,  ..., -0.1199, -0.0768, -0.0129],\n",
       "                       [-0.0633,  0.0246, -0.0445,  ..., -0.0330,  0.0546,  0.0044],\n",
       "                       [ 0.0275, -0.0037, -0.0208,  ...,  0.1007, -0.0388, -0.0194]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.k_lin.bias',\n",
       "               tensor([-0.0364,  0.6230, -0.3999,  ..., -0.4846,  0.4460,  0.0729],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.v_lin.weight',\n",
       "               tensor([[ 1.1368e-02,  1.5587e-02,  3.0777e-02,  ..., -3.4515e-02,\n",
       "                        -1.4259e-02,  2.1957e-02],\n",
       "                       [ 1.0406e-01,  4.0591e-05,  3.6591e-02,  ..., -2.3514e-02,\n",
       "                        -5.9753e-02, -3.5736e-02],\n",
       "                       [-5.6122e-02,  7.8201e-03,  2.6245e-03,  ..., -4.9103e-02,\n",
       "                         2.7832e-02,  1.1681e-02],\n",
       "                       ...,\n",
       "                       [-5.1147e-02, -9.0103e-03, -7.1411e-02,  ..., -8.3313e-03,\n",
       "                         2.6932e-02, -3.5797e-02],\n",
       "                       [ 5.9967e-02,  2.8198e-02, -1.9028e-02,  ...,  2.3254e-02,\n",
       "                         3.6560e-02, -9.3918e-03],\n",
       "                       [-2.9129e-02, -4.6814e-02, -1.5821e-03,  ..., -4.0192e-02,\n",
       "                         3.4515e-02, -3.6652e-02]], dtype=torch.float16)),\n",
       "              ('module.attentions.5.v_lin.bias',\n",
       "               tensor([-0.0019,  0.0050, -0.0175,  ...,  0.0061,  0.0261,  0.0131],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.out_lin.weight',\n",
       "               tensor([[ 0.0006, -0.0637,  0.0027,  ..., -0.0238,  0.0579, -0.0399],\n",
       "                       [ 0.0154,  0.0568, -0.0033,  ...,  0.0185, -0.0366,  0.0253],\n",
       "                       [-0.0320, -0.0348,  0.0147,  ..., -0.0371,  0.0132,  0.0064],\n",
       "                       ...,\n",
       "                       [-0.0861, -0.0598,  0.0033,  ...,  0.0009, -0.0272,  0.0029],\n",
       "                       [ 0.0056,  0.0277,  0.0811,  ...,  0.0282,  0.0030,  0.0611],\n",
       "                       [ 0.0205, -0.0101, -0.0248,  ..., -0.0356, -0.0320, -0.0183]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.out_lin.bias',\n",
       "               tensor([-0.0010, -0.0147,  0.0208,  ...,  0.0020, -0.0163,  0.0132],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.0.weight',\n",
       "               tensor([0.4712, 0.4229, 0.3940,  ..., 0.3726, 0.3804, 0.3962],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.0.bias',\n",
       "               tensor([ 0.0020, -0.0575,  0.0043,  ...,  0.2175, -0.1443,  0.0602],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.1.weight',\n",
       "               tensor([0.4480, 0.3967, 0.3914,  ..., 0.3599, 0.3635, 0.3904],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.1.bias',\n",
       "               tensor([-0.0199, -0.0865,  0.0547,  ...,  0.0919, -0.0456,  0.0950],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.2.weight',\n",
       "               tensor([0.4807, 0.3843, 0.3748,  ..., 0.3413, 0.3337, 0.3779],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.2.bias',\n",
       "               tensor([ 0.0261, -0.1305, -0.0236,  ...,  0.0554,  0.0613,  0.0740],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.3.weight',\n",
       "               tensor([0.4844, 0.3765, 0.3745,  ..., 0.3362, 0.3337, 0.3787],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.3.bias',\n",
       "               tensor([ 0.0476, -0.1022,  0.0265,  ...,  0.0762,  0.0576,  0.0409],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.4.weight',\n",
       "               tensor([0.4646, 0.3889, 0.3455,  ..., 0.3271, 0.3503, 0.3887],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.4.bias',\n",
       "               tensor([ 0.0408, -0.0358,  0.0135,  ...,  0.0689,  0.0548,  0.0196],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.5.weight',\n",
       "               tensor([0.4092, 0.4019, 0.3723,  ..., 0.3582, 0.3445, 0.4158],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.5.bias',\n",
       "               tensor([ 0.0302, -0.0669,  0.0896,  ...,  0.1204,  0.1602,  0.0087],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin1.weight',\n",
       "               tensor([[ 0.0007, -0.0422, -0.0061,  ..., -0.0985, -0.0322, -0.0010],\n",
       "                       [ 0.0202,  0.0160, -0.0251,  ...,  0.0224,  0.0384,  0.0166],\n",
       "                       [ 0.0310,  0.0129,  0.0010,  ..., -0.0720,  0.0677,  0.0501],\n",
       "                       ...,\n",
       "                       [ 0.0210, -0.0432,  0.0447,  ...,  0.0139,  0.0088, -0.0943],\n",
       "                       [-0.0098, -0.0218,  0.0257,  ...,  0.0271,  0.0680,  0.0193],\n",
       "                       [ 0.0338, -0.0103,  0.0428,  ...,  0.0626,  0.0759,  0.0077]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin1.bias',\n",
       "               tensor([-0.0109, -0.0760, -0.0343,  ..., -0.0852, -0.0796, -0.0481],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin2.weight',\n",
       "               tensor([[ 0.0088, -0.0275,  0.0637,  ...,  0.0074, -0.0379,  0.0243],\n",
       "                       [-0.0121,  0.0244,  0.0258,  ...,  0.0368, -0.0152,  0.0274],\n",
       "                       [-0.0024,  0.0300,  0.0003,  ..., -0.0744, -0.0080, -0.0366],\n",
       "                       ...,\n",
       "                       [ 0.0378,  0.0406,  0.0716,  ...,  0.0904, -0.0764, -0.0520],\n",
       "                       [-0.0345, -0.0046, -0.0007,  ..., -0.0320, -0.0031,  0.0025],\n",
       "                       [ 0.0010,  0.0051, -0.0495,  ..., -0.0055,  0.0056,  0.0134]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin2.bias',\n",
       "               tensor([-0.0311,  0.0083, -0.0075,  ..., -0.0293, -0.0263,  0.0345],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin1.weight',\n",
       "               tensor([[ 0.0007,  0.0620, -0.0337,  ..., -0.0637,  0.0470, -0.0246],\n",
       "                       [-0.0092,  0.0086,  0.0195,  ..., -0.0276,  0.0393,  0.0104],\n",
       "                       [-0.0403,  0.0284,  0.0389,  ..., -0.0580,  0.0966,  0.0159],\n",
       "                       ...,\n",
       "                       [ 0.0006,  0.0917, -0.0681,  ...,  0.0665,  0.1055,  0.0176],\n",
       "                       [-0.0334, -0.0555,  0.0066,  ...,  0.0880,  0.0530,  0.1096],\n",
       "                       [ 0.0309, -0.0598,  0.0203,  ..., -0.0037,  0.0774,  0.0291]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin1.bias',\n",
       "               tensor([-0.0177, -0.2449, -0.0693,  ..., -0.0707, -0.1311, -0.0587],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin2.weight',\n",
       "               tensor([[-0.0281, -0.0073, -0.0254,  ..., -0.0201,  0.0008,  0.0353],\n",
       "                       [-0.0204, -0.0070,  0.0370,  ...,  0.1047,  0.0870, -0.0997],\n",
       "                       [ 0.0193, -0.0085, -0.0489,  ...,  0.0591,  0.0648, -0.0010],\n",
       "                       ...,\n",
       "                       [-0.0635,  0.0362,  0.0112,  ...,  0.0592, -0.0180,  0.0460],\n",
       "                       [ 0.0265, -0.0071,  0.0033,  ...,  0.1191,  0.1353, -0.0203],\n",
       "                       [-0.0179, -0.0368, -0.0794,  ..., -0.1379, -0.0097,  0.0436]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin2.bias',\n",
       "               tensor([-0.0060,  0.0115, -0.0646,  ...,  0.0149, -0.0020,  0.0096],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin1.weight',\n",
       "               tensor([[-0.0139,  0.0313, -0.0180,  ...,  0.0679, -0.0549,  0.0288],\n",
       "                       [-0.0106,  0.0690, -0.0363,  ..., -0.0415,  0.0344, -0.0978],\n",
       "                       [-0.0063,  0.0479, -0.0700,  ...,  0.0824, -0.0221, -0.0417],\n",
       "                       ...,\n",
       "                       [ 0.0565,  0.0384, -0.0273,  ..., -0.0638, -0.0006,  0.0975],\n",
       "                       [ 0.0184,  0.0108, -0.0679,  ..., -0.1029, -0.0191, -0.0641],\n",
       "                       [-0.0005,  0.0721,  0.0406,  ..., -0.0679,  0.0453,  0.0370]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin1.bias',\n",
       "               tensor([-0.0519, -0.0515,  0.0024,  ..., -0.0844, -0.0381, -0.0318],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin2.weight',\n",
       "               tensor([[ 0.0070, -0.0068, -0.0003,  ...,  0.0480,  0.0171, -0.0159],\n",
       "                       [ 0.0363, -0.0167,  0.0126,  ..., -0.0603,  0.0184,  0.0783],\n",
       "                       [ 0.0036,  0.0230,  0.0336,  ..., -0.0554, -0.0089,  0.0223],\n",
       "                       ...,\n",
       "                       [ 0.0628, -0.0362, -0.0595,  ..., -0.0503, -0.0097, -0.0110],\n",
       "                       [-0.0442, -0.0509, -0.0085,  ..., -0.0001,  0.0380, -0.0061],\n",
       "                       [ 0.0043, -0.0093,  0.0198,  ..., -0.0134, -0.0250,  0.0525]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin2.bias',\n",
       "               tensor([-0.0133,  0.0490, -0.0589,  ..., -0.0296, -0.0545, -0.0221],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin1.weight',\n",
       "               tensor([[-0.0138, -0.0362, -0.0608,  ...,  0.0004, -0.0471,  0.0521],\n",
       "                       [ 0.0202,  0.0316,  0.0145,  ...,  0.0738, -0.0511,  0.0267],\n",
       "                       [-0.0072,  0.0684,  0.0477,  ..., -0.0596, -0.0135,  0.0644],\n",
       "                       ...,\n",
       "                       [-0.0080, -0.0089, -0.0329,  ...,  0.0011, -0.0356, -0.0132],\n",
       "                       [ 0.0202,  0.0048, -0.0258,  ...,  0.0088, -0.0235,  0.0178],\n",
       "                       [ 0.0233,  0.0261,  0.0778,  ..., -0.0297,  0.0468,  0.0266]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin1.bias',\n",
       "               tensor([-0.0160, -0.0761,  0.0062,  ..., -0.0717, -0.0530, -0.0025],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin2.weight',\n",
       "               tensor([[ 0.0268, -0.0094, -0.0058,  ..., -0.0035,  0.0051, -0.0198],\n",
       "                       [-0.0173,  0.0476,  0.0087,  ..., -0.0147,  0.0105, -0.0047],\n",
       "                       [ 0.0583,  0.1274, -0.0103,  ...,  0.0205, -0.0757, -0.0398],\n",
       "                       ...,\n",
       "                       [-0.0310, -0.0691,  0.0180,  ...,  0.0068, -0.0185,  0.0080],\n",
       "                       [ 0.0273, -0.0080, -0.0120,  ..., -0.0470, -0.0533,  0.0035],\n",
       "                       [-0.0215, -0.1024,  0.0116,  ...,  0.0353, -0.0309, -0.0076]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin2.bias',\n",
       "               tensor([-0.0061,  0.0240, -0.0620,  ..., -0.0294, -0.0032, -0.0584],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin1.weight',\n",
       "               tensor([[-0.0403,  0.0564, -0.0741,  ...,  0.0721, -0.1115, -0.0460],\n",
       "                       [-0.0415,  0.0145, -0.0496,  ..., -0.0340,  0.0883, -0.1158],\n",
       "                       [-0.0480,  0.0676,  0.0537,  ...,  0.0441, -0.0698, -0.0224],\n",
       "                       ...,\n",
       "                       [ 0.0542, -0.0162, -0.0431,  ..., -0.0077,  0.0360, -0.0208],\n",
       "                       [ 0.0615,  0.0222,  0.0396,  ..., -0.0404,  0.0083,  0.0224],\n",
       "                       [ 0.0729,  0.0449, -0.0033,  ...,  0.0079, -0.0576,  0.0162]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin1.bias',\n",
       "               tensor([-0.0916, -0.0941, -0.0753,  ..., -0.0301, -0.0494, -0.0543],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin2.weight',\n",
       "               tensor([[-0.0151, -0.0600, -0.0658,  ...,  0.0171,  0.0414,  0.1212],\n",
       "                       [ 0.0057,  0.0150, -0.0118,  ..., -0.0213, -0.0140, -0.0477],\n",
       "                       [-0.0526,  0.0341, -0.0359,  ...,  0.0231, -0.0930, -0.0945],\n",
       "                       ...,\n",
       "                       [-0.0266,  0.0607, -0.0302,  ...,  0.0003,  0.0215,  0.0321],\n",
       "                       [-0.0468,  0.0363,  0.0282,  ..., -0.0090, -0.0459, -0.0569],\n",
       "                       [-0.0242,  0.0309, -0.0355,  ..., -0.0215,  0.0445,  0.0622]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin2.bias',\n",
       "               tensor([-0.0355,  0.0273, -0.0327,  ...,  0.0294,  0.0208, -0.0289],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin1.weight',\n",
       "               tensor([[-0.0363,  0.0604, -0.0422,  ..., -0.1138,  0.1040, -0.1379],\n",
       "                       [ 0.0359,  0.0100, -0.0083,  ...,  0.0510, -0.0461,  0.0044],\n",
       "                       [ 0.0189, -0.0305, -0.0081,  ..., -0.0003,  0.0202, -0.0197],\n",
       "                       ...,\n",
       "                       [ 0.0022, -0.0038,  0.0044,  ..., -0.0020, -0.0805, -0.0123],\n",
       "                       [ 0.0227,  0.0420,  0.0057,  ...,  0.0166, -0.0623, -0.0376],\n",
       "                       [-0.0088, -0.0440, -0.0156,  ...,  0.0076,  0.0121,  0.0806]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin1.bias',\n",
       "               tensor([-0.0724, -0.0308, -0.1382,  ..., -0.0644, -0.0447, -0.0426],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin2.weight',\n",
       "               tensor([[ 0.0234, -0.0211,  0.0505,  ...,  0.0394, -0.0629, -0.0147],\n",
       "                       [ 0.1150,  0.0366, -0.0087,  ..., -0.0290, -0.0562,  0.0009],\n",
       "                       [ 0.0648, -0.0213,  0.0163,  ...,  0.0135,  0.0379,  0.0239],\n",
       "                       ...,\n",
       "                       [-0.0335, -0.0388, -0.0412,  ..., -0.0332,  0.0309,  0.0072],\n",
       "                       [ 0.0776, -0.0124, -0.0125,  ..., -0.0635,  0.0110,  0.0064],\n",
       "                       [-0.0765, -0.0048, -0.0095,  ..., -0.0129,  0.0225,  0.0006]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin2.bias',\n",
       "               tensor([-0.0103,  0.0053, -0.0017,  ...,  0.0085, -0.0037,  0.0116],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.0.weight',\n",
       "               tensor([0.5845, 0.5259, 0.5054,  ..., 0.4084, 0.4626, 0.5278],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.0.bias',\n",
       "               tensor([-0.0050,  0.0632,  0.0094,  ..., -0.1214,  0.1025, -0.0444],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.1.weight',\n",
       "               tensor([0.6011, 0.5366, 0.5083,  ..., 0.4585, 0.4807, 0.5254],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.1.bias',\n",
       "               tensor([ 0.0194,  0.0606, -0.0400,  ..., -0.0543,  0.0469, -0.0469],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.2.weight',\n",
       "               tensor([0.6509, 0.5659, 0.5303,  ..., 0.5127, 0.5410, 0.5640],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.2.bias',\n",
       "               tensor([-0.0128,  0.0864, -0.0230,  ..., -0.0502, -0.0465, -0.0566],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.3.weight',\n",
       "               tensor([0.6045, 0.5449, 0.5166,  ..., 0.5146, 0.5181, 0.5420],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.3.bias',\n",
       "               tensor([-0.0200,  0.0376, -0.0291,  ..., -0.0511, -0.0533, -0.0215],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.4.weight',\n",
       "               tensor([0.6465, 0.5459, 0.5317,  ..., 0.5293, 0.5322, 0.5527],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.4.bias',\n",
       "               tensor([-0.0444,  0.0101, -0.0301,  ..., -0.0716, -0.0665,  0.0212],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.5.weight',\n",
       "               tensor([2.3379, 2.3320, 2.5098,  ..., 2.6113, 2.4688, 2.6328],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.5.bias',\n",
       "               tensor([ 0.0023, -0.0372, -0.1794,  ..., -0.0319, -0.0022,  0.1282],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.pred_layer.proj.weight',\n",
       "               tensor([[-0.0027,  0.0350, -0.0067,  ..., -0.0880,  0.0496,  0.0398],\n",
       "                       [-0.0480,  0.0035,  0.0121,  ...,  0.0016, -0.0303,  0.0152],\n",
       "                       [-0.0391,  0.0273,  0.0157,  ..., -0.0782, -0.0212,  0.0021],\n",
       "                       ...,\n",
       "                       [-0.0252, -0.0506, -0.0354,  ..., -0.0431,  0.0506,  0.0500],\n",
       "                       [-0.0274,  0.0699,  0.0352,  ..., -0.0271, -0.0021, -0.0391],\n",
       "                       [ 0.0297, -0.0688, -0.0042,  ..., -0.0880,  0.0251, -0.0300]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.pred_layer.proj.bias',\n",
       "               tensor([-2.2363, -0.1102, -2.4336,  ..., -1.3066, -1.1992, -1.6650],\n",
       "                      dtype=torch.float16))]),\n",
       " 'decoder': OrderedDict([('module.position_embeddings.weight',\n",
       "               tensor([[ 0.0169,  0.0241, -0.0060,  ...,  0.0101, -0.0061, -0.0215],\n",
       "                       [-0.0008,  0.0224, -0.0236,  ..., -0.0059,  0.0085, -0.0200],\n",
       "                       [ 0.0017,  0.0092, -0.0068,  ..., -0.0009, -0.0055, -0.0101],\n",
       "                       ...,\n",
       "                       [ 0.0151, -0.0050,  0.0265,  ..., -0.0256,  0.0176, -0.0139],\n",
       "                       [ 0.0186, -0.0235, -0.0098,  ..., -0.0160,  0.0303,  0.0023],\n",
       "                       [-0.0230,  0.0086,  0.0015,  ...,  0.0154, -0.0029,  0.0096]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.lang_embeddings.weight',\n",
       "               tensor([[ 0.0026,  0.0028,  0.0092,  ..., -0.0212,  0.0106,  0.0093],\n",
       "                       [ 0.0001, -0.0105,  0.0124,  ...,  0.0010,  0.0093,  0.0107],\n",
       "                       [ 0.0053, -0.0068,  0.0115,  ...,  0.0285, -0.0015,  0.0062]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.embeddings.weight',\n",
       "               tensor([[-0.0026,  0.0328, -0.0086,  ..., -0.0876,  0.0523,  0.0307],\n",
       "                       [-0.0312, -0.0044,  0.0104,  ...,  0.0131, -0.0293,  0.0129],\n",
       "                       [-0.0401,  0.0246,  0.0135,  ..., -0.0760, -0.0206, -0.0047],\n",
       "                       ...,\n",
       "                       [-0.0231, -0.0485, -0.0335,  ..., -0.0450,  0.0485,  0.0441],\n",
       "                       [-0.0276,  0.0656,  0.0337,  ..., -0.0289,  0.0030, -0.0454],\n",
       "                       [ 0.0289, -0.0684, -0.0053,  ..., -0.0873,  0.0255, -0.0303]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm_emb.weight',\n",
       "               tensor([0.5498, 0.5029, 0.5142,  ..., 0.3647, 0.4312, 0.5176],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm_emb.bias',\n",
       "               tensor([-0.0169, -0.0587, -0.0549,  ..., -0.0388,  0.0223, -0.0176],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.q_lin.weight',\n",
       "               tensor([[-0.0043, -0.0729,  0.0070,  ..., -0.0604,  0.0269,  0.0612],\n",
       "                       [-0.1085,  0.0158, -0.0091,  ..., -0.0595, -0.0339, -0.0075],\n",
       "                       [ 0.0622, -0.1025,  0.0161,  ...,  0.0095, -0.0420, -0.0350],\n",
       "                       ...,\n",
       "                       [-0.0133, -0.0447,  0.0023,  ..., -0.0583, -0.0375,  0.0749],\n",
       "                       [ 0.0382,  0.0060, -0.0842,  ...,  0.0512, -0.0005,  0.0809],\n",
       "                       [ 0.0687,  0.1794, -0.0467,  ..., -0.0248,  0.0008, -0.0285]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.q_lin.bias',\n",
       "               tensor([-0.2025,  0.1639,  0.1984,  ...,  0.1594, -0.2856,  0.1133],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.k_lin.weight',\n",
       "               tensor([[ 0.0479,  0.0311,  0.0366,  ..., -0.0161,  0.0282, -0.0157],\n",
       "                       [-0.0728,  0.0075, -0.0539,  ...,  0.0124,  0.0340, -0.0237],\n",
       "                       [-0.1002,  0.0902, -0.0173,  ..., -0.0428,  0.0588, -0.0083],\n",
       "                       ...,\n",
       "                       [ 0.0459,  0.0380,  0.0378,  ...,  0.0071,  0.0002, -0.0406],\n",
       "                       [ 0.0086, -0.0291,  0.0411,  ..., -0.0108, -0.0641,  0.0215],\n",
       "                       [ 0.0139,  0.0242,  0.0092,  ...,  0.0569, -0.0153, -0.0244]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.k_lin.bias',\n",
       "               tensor([ 0.0202, -0.0085, -0.0071,  ..., -0.0100,  0.0629,  0.0086],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.v_lin.weight',\n",
       "               tensor([[-0.0279, -0.0247, -0.0394,  ...,  0.0485, -0.0208,  0.0070],\n",
       "                       [-0.0435,  0.0191,  0.0127,  ..., -0.0835, -0.0028, -0.0161],\n",
       "                       [-0.0741,  0.0283, -0.0427,  ...,  0.0254,  0.0217, -0.0373],\n",
       "                       ...,\n",
       "                       [-0.0062,  0.0125,  0.0538,  ..., -0.0334,  0.0087, -0.0485],\n",
       "                       [-0.0198, -0.0053, -0.0225,  ...,  0.0387, -0.0032, -0.0055],\n",
       "                       [-0.0499,  0.0803, -0.0130,  ..., -0.0090, -0.0219,  0.0441]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.v_lin.bias',\n",
       "               tensor([ 0.0024, -0.0310,  0.0071,  ..., -0.0263,  0.0051, -0.0223],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.out_lin.weight',\n",
       "               tensor([[ 0.0004, -0.0238,  0.0440,  ..., -0.0275,  0.0071, -0.0008],\n",
       "                       [ 0.0305, -0.0435, -0.0258,  ...,  0.0079,  0.0416, -0.0004],\n",
       "                       [ 0.0330, -0.0141,  0.0393,  ...,  0.0448,  0.0118,  0.0019],\n",
       "                       ...,\n",
       "                       [ 0.0760,  0.0312, -0.0205,  ...,  0.0163, -0.0065, -0.0256],\n",
       "                       [-0.0452, -0.0448, -0.0447,  ...,  0.0287, -0.0105,  0.0093],\n",
       "                       [-0.0242,  0.0554, -0.0307,  ..., -0.0168, -0.0230,  0.0121]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.0.out_lin.bias',\n",
       "               tensor([-0.0182,  0.0042,  0.0304,  ..., -0.0137,  0.0234, -0.0019],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.q_lin.weight',\n",
       "               tensor([[ 0.0053,  0.0266, -0.0297,  ..., -0.0122,  0.0093, -0.0558],\n",
       "                       [-0.0234, -0.0466, -0.0363,  ...,  0.0195,  0.0640,  0.0158],\n",
       "                       [-0.0048, -0.0143,  0.0695,  ...,  0.0267, -0.0708, -0.0504],\n",
       "                       ...,\n",
       "                       [ 0.0177,  0.0451, -0.0178,  ...,  0.0773,  0.0126,  0.0102],\n",
       "                       [ 0.0299,  0.0116, -0.0033,  ...,  0.0288, -0.0435, -0.0249],\n",
       "                       [-0.0168, -0.0255,  0.0155,  ...,  0.0726, -0.0038,  0.0454]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.q_lin.bias',\n",
       "               tensor([ 0.0563, -0.0114, -0.0822,  ...,  0.2834, -0.2988, -0.1582],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.k_lin.weight',\n",
       "               tensor([[ 0.0173, -0.0038,  0.0294,  ...,  0.0548,  0.0297, -0.0260],\n",
       "                       [-0.0654,  0.0186, -0.0394,  ..., -0.0403,  0.0367,  0.0309],\n",
       "                       [-0.0057, -0.0308, -0.0003,  ..., -0.0290,  0.0091,  0.0198],\n",
       "                       ...,\n",
       "                       [ 0.0829,  0.0178,  0.0185,  ...,  0.0566, -0.0164, -0.0333],\n",
       "                       [ 0.0131,  0.0528,  0.0478,  ..., -0.0007,  0.0010, -0.0765],\n",
       "                       [-0.0593,  0.0420,  0.0434,  ...,  0.0012,  0.1042, -0.0172]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.k_lin.bias',\n",
       "               tensor([ 0.0158,  0.0432,  0.0420,  ...,  0.0515, -0.1752, -0.0056],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.v_lin.weight',\n",
       "               tensor([[-0.0126, -0.0242,  0.0257,  ...,  0.0390, -0.0143, -0.0688],\n",
       "                       [-0.0300, -0.0135, -0.0692,  ..., -0.0046,  0.0271, -0.0214],\n",
       "                       [-0.0389, -0.0229,  0.0114,  ..., -0.0298,  0.0132,  0.0150],\n",
       "                       ...,\n",
       "                       [ 0.0116,  0.0064,  0.0255,  ..., -0.0256, -0.0098,  0.0347],\n",
       "                       [ 0.0101,  0.0155,  0.0202,  ...,  0.0410,  0.0107,  0.0211],\n",
       "                       [ 0.0430,  0.0066, -0.0103,  ...,  0.0394,  0.0195, -0.0594]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.v_lin.bias',\n",
       "               tensor([ 0.0071,  0.0188, -0.0065,  ..., -0.0233,  0.0008, -0.0129],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.out_lin.weight',\n",
       "               tensor([[ 0.0181, -0.0060,  0.0070,  ...,  0.0130, -0.0222, -0.0111],\n",
       "                       [ 0.0407, -0.0177,  0.0442,  ..., -0.0122,  0.0438, -0.0116],\n",
       "                       [-0.0328,  0.0282,  0.0403,  ...,  0.0024,  0.0401, -0.0273],\n",
       "                       ...,\n",
       "                       [ 0.0662,  0.0037,  0.0857,  ...,  0.0352, -0.1829,  0.0194],\n",
       "                       [-0.0499, -0.0127, -0.0430,  ..., -0.0016,  0.0779, -0.0214],\n",
       "                       [ 0.0453, -0.0242,  0.0194,  ..., -0.0646,  0.0268, -0.0188]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.1.out_lin.bias',\n",
       "               tensor([-0.0070,  0.0046,  0.0010,  ..., -0.0148,  0.0072, -0.0115],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.q_lin.weight',\n",
       "               tensor([[ 0.0267,  0.0294, -0.0184,  ...,  0.0393, -0.0230, -0.0384],\n",
       "                       [-0.0911, -0.0426, -0.0960,  ..., -0.0198, -0.0576,  0.0310],\n",
       "                       [ 0.1108, -0.0692, -0.0945,  ..., -0.0174,  0.1122, -0.0460],\n",
       "                       ...,\n",
       "                       [ 0.0325,  0.0313, -0.0009,  ..., -0.0204, -0.1429,  0.0504],\n",
       "                       [ 0.0334,  0.0920, -0.0553,  ...,  0.0224, -0.0040, -0.0745],\n",
       "                       [ 0.0434, -0.0139,  0.0173,  ..., -0.0091, -0.0447, -0.0451]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.q_lin.bias',\n",
       "               tensor([ 0.3914, -0.0019,  0.0880,  ..., -0.0479, -0.0942,  0.0611],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.k_lin.weight',\n",
       "               tensor([[-7.2479e-03,  4.4220e-02,  3.0609e-02,  ...,  8.9844e-02,\n",
       "                        -8.7830e-02, -6.7825e-03],\n",
       "                       [-1.8143e-02,  3.5370e-02, -1.4549e-02,  ..., -1.7969e-01,\n",
       "                        -6.8703e-03, -3.8239e-02],\n",
       "                       [-5.1514e-02,  9.4116e-02,  3.6316e-02,  ..., -5.8014e-02,\n",
       "                        -4.4159e-02, -1.3153e-02],\n",
       "                       ...,\n",
       "                       [-3.1412e-05, -8.8379e-02,  5.0873e-02,  ..., -4.3762e-02,\n",
       "                        -9.6607e-04, -6.8054e-03],\n",
       "                       [-7.2449e-02, -1.1490e-02,  3.6469e-02,  ..., -2.8091e-02,\n",
       "                         8.4000e-03,  3.2401e-04],\n",
       "                       [-3.1082e-02, -3.8147e-02,  9.4986e-03,  ...,  3.7445e-02,\n",
       "                         9.9182e-03, -3.7689e-02]], dtype=torch.float16)),\n",
       "              ('module.attentions.2.k_lin.bias',\n",
       "               tensor([-0.1434,  0.0362,  0.0589,  ..., -0.0784,  0.0018,  0.0213],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.v_lin.weight',\n",
       "               tensor([[-0.0439,  0.0933,  0.0386,  ...,  0.0391,  0.0202,  0.0432],\n",
       "                       [ 0.0735,  0.0101, -0.0274,  ..., -0.0017,  0.0382,  0.0117],\n",
       "                       [-0.0158, -0.0080, -0.0196,  ...,  0.0014, -0.0242,  0.0054],\n",
       "                       ...,\n",
       "                       [ 0.0214, -0.0228,  0.0650,  ..., -0.0106, -0.0736,  0.0395],\n",
       "                       [ 0.0005, -0.0108, -0.0226,  ...,  0.0237, -0.0484, -0.0049],\n",
       "                       [-0.0588,  0.0681, -0.0263,  ..., -0.0410,  0.0104, -0.0114]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.v_lin.bias',\n",
       "               tensor([-0.0169,  0.0031, -0.0011,  ...,  0.0018, -0.0169, -0.0022],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.out_lin.weight',\n",
       "               tensor([[-0.0176,  0.0222,  0.0245,  ...,  0.0262, -0.0013, -0.0046],\n",
       "                       [ 0.0071, -0.0213,  0.0294,  ...,  0.0596,  0.0868,  0.0118],\n",
       "                       [-0.1110,  0.0413, -0.0158,  ..., -0.0172,  0.0201,  0.0041],\n",
       "                       ...,\n",
       "                       [-0.0251,  0.0579,  0.0374,  ..., -0.0290,  0.0209,  0.1043],\n",
       "                       [ 0.0136, -0.0317, -0.0289,  ...,  0.0272,  0.0955,  0.0442],\n",
       "                       [ 0.0461, -0.0077, -0.0143,  ..., -0.0015, -0.0581,  0.0541]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.2.out_lin.bias',\n",
       "               tensor([-0.0019, -0.0030,  0.0083,  ..., -0.0156, -0.0054, -0.0080],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.q_lin.weight',\n",
       "               tensor([[-0.0437, -0.0318,  0.0687,  ..., -0.0018, -0.0308, -0.0028],\n",
       "                       [-0.0443, -0.0256,  0.0007,  ...,  0.0670,  0.0379, -0.0993],\n",
       "                       [ 0.0336, -0.0477, -0.0236,  ..., -0.0286, -0.0033,  0.0184],\n",
       "                       ...,\n",
       "                       [ 0.0333, -0.0394, -0.1803,  ...,  0.0793,  0.0743,  0.0076],\n",
       "                       [ 0.0622,  0.0037, -0.0454,  ...,  0.0629,  0.0887, -0.0440],\n",
       "                       [-0.0089, -0.0105, -0.0463,  ...,  0.0999,  0.0369,  0.1378]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.q_lin.bias',\n",
       "               tensor([-0.0401,  0.1438, -0.0385,  ..., -0.1106,  0.1564,  0.1642],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.k_lin.weight',\n",
       "               tensor([[-0.0089, -0.0113, -0.0468,  ...,  0.0158,  0.0071,  0.0091],\n",
       "                       [ 0.0339, -0.0971,  0.0461,  ...,  0.0589,  0.0176, -0.0330],\n",
       "                       [-0.0699, -0.0306, -0.0803,  ...,  0.1022, -0.0597, -0.0564],\n",
       "                       ...,\n",
       "                       [-0.0717, -0.0049,  0.0654,  ..., -0.0099, -0.0762, -0.0661],\n",
       "                       [ 0.0359, -0.0930,  0.0182,  ..., -0.0942, -0.1132, -0.0389],\n",
       "                       [-0.0750, -0.0406, -0.0811,  ..., -0.0624,  0.0540,  0.0132]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.k_lin.bias',\n",
       "               tensor([ 0.0595,  0.1484,  0.0822,  ..., -0.3538,  0.2563,  0.4055],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.v_lin.weight',\n",
       "               tensor([[-0.0426,  0.0713,  0.0256,  ..., -0.0038, -0.0739, -0.0043],\n",
       "                       [-0.0133,  0.0279, -0.0675,  ...,  0.0524,  0.0303,  0.0208],\n",
       "                       [ 0.0614, -0.0576, -0.0627,  ..., -0.0679, -0.0173,  0.0283],\n",
       "                       ...,\n",
       "                       [ 0.0206, -0.0275, -0.0056,  ...,  0.0048, -0.0276, -0.0093],\n",
       "                       [-0.0340,  0.0428,  0.0120,  ..., -0.0428,  0.0313, -0.0415],\n",
       "                       [-0.0115, -0.0214,  0.0282,  ..., -0.1031, -0.0457, -0.0007]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.v_lin.bias',\n",
       "               tensor([-0.0124, -0.0127, -0.0002,  ...,  0.0131, -0.0091,  0.0046],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.out_lin.weight',\n",
       "               tensor([[-0.0154,  0.0176,  0.0097,  ...,  0.0276, -0.0131, -0.0201],\n",
       "                       [-0.0484, -0.0124, -0.0100,  ..., -0.0098, -0.0043, -0.0400],\n",
       "                       [-0.0574, -0.0160,  0.0063,  ..., -0.0325, -0.0172,  0.0134],\n",
       "                       ...,\n",
       "                       [ 0.0446, -0.0113, -0.0161,  ...,  0.0532,  0.0723,  0.0326],\n",
       "                       [ 0.0285,  0.0688,  0.0612,  ..., -0.0648,  0.1399, -0.0521],\n",
       "                       [ 0.0464,  0.0538, -0.0357,  ...,  0.0007, -0.0655, -0.0172]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.3.out_lin.bias',\n",
       "               tensor([-7.9513e-05,  1.7147e-03,  3.5152e-03,  ..., -3.3512e-03,\n",
       "                        2.7122e-03, -1.1055e-02], dtype=torch.float16)),\n",
       "              ('module.attentions.4.q_lin.weight',\n",
       "               tensor([[-0.0768, -0.0859, -0.0081,  ...,  0.0459, -0.0064,  0.0063],\n",
       "                       [ 0.0338, -0.0207, -0.0061,  ..., -0.0358, -0.0027, -0.0474],\n",
       "                       [ 0.0192, -0.0024, -0.0321,  ...,  0.0154,  0.0111, -0.0280],\n",
       "                       ...,\n",
       "                       [-0.0234,  0.0063,  0.0596,  ...,  0.1387, -0.0035,  0.1093],\n",
       "                       [ 0.0451,  0.0087,  0.0492,  ..., -0.0793, -0.0057, -0.0173],\n",
       "                       [ 0.0035, -0.0416,  0.0917,  ..., -0.0295,  0.0230, -0.0055]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.q_lin.bias',\n",
       "               tensor([-0.0097,  0.1564, -0.0774,  ...,  0.2532,  0.1469, -0.3921],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.k_lin.weight',\n",
       "               tensor([[-0.0035,  0.0604, -0.0149,  ...,  0.1118, -0.0576, -0.0138],\n",
       "                       [-0.0270,  0.0627, -0.0443,  ...,  0.0195,  0.0113,  0.0050],\n",
       "                       [ 0.0545,  0.0119,  0.0008,  ...,  0.0079,  0.0373, -0.0565],\n",
       "                       ...,\n",
       "                       [-0.0431,  0.0623,  0.0901,  ..., -0.0215, -0.0908,  0.0480],\n",
       "                       [ 0.0696,  0.0371,  0.0318,  ...,  0.0635,  0.0421, -0.0577],\n",
       "                       [ 0.0425, -0.0455, -0.0744,  ..., -0.1096, -0.0046, -0.0120]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.k_lin.bias',\n",
       "               tensor([-0.8740, -0.9863,  0.4763,  ...,  3.3633,  2.6602, -3.6270],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.v_lin.weight',\n",
       "               tensor([[ 0.0009,  0.0343, -0.0281,  ...,  0.0300, -0.0071,  0.0831],\n",
       "                       [-0.1259,  0.0029,  0.0212,  ..., -0.0983,  0.0259,  0.0238],\n",
       "                       [ 0.0161,  0.1008, -0.0624,  ..., -0.0837,  0.0424,  0.0107],\n",
       "                       ...,\n",
       "                       [ 0.0623, -0.0114, -0.0339,  ...,  0.0167,  0.0645, -0.0671],\n",
       "                       [-0.0007,  0.0299,  0.0007,  ..., -0.0168,  0.0137, -0.0013],\n",
       "                       [ 0.0120, -0.0375, -0.0798,  ..., -0.0443,  0.0429, -0.0204]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.v_lin.bias',\n",
       "               tensor([ 0.0363,  0.0111,  0.0014,  ...,  0.0290,  0.0269, -0.0399],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.out_lin.weight',\n",
       "               tensor([[ 0.0031,  0.0902, -0.0256,  ...,  0.0080, -0.0081,  0.0010],\n",
       "                       [ 0.0286,  0.0235, -0.0779,  ...,  0.0255, -0.0071,  0.0461],\n",
       "                       [ 0.0339,  0.0282, -0.0197,  ...,  0.0150, -0.0605,  0.0026],\n",
       "                       ...,\n",
       "                       [-0.0292,  0.0674,  0.0641,  ..., -0.0616,  0.0869, -0.0434],\n",
       "                       [-0.0052,  0.0090,  0.0329,  ...,  0.0828, -0.0631,  0.0629],\n",
       "                       [-0.0200, -0.0223, -0.0185,  ..., -0.0068, -0.0553,  0.0658]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.4.out_lin.bias',\n",
       "               tensor([ 0.0006,  0.0025,  0.0045,  ..., -0.0044,  0.0001, -0.0082],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.q_lin.weight',\n",
       "               tensor([[-0.0481,  0.0115, -0.0793,  ..., -0.0409, -0.0302,  0.0596],\n",
       "                       [-0.0180, -0.0493,  0.0148,  ...,  0.1443,  0.0234,  0.0047],\n",
       "                       [-0.0615, -0.0373,  0.0298,  ..., -0.0769,  0.0114,  0.0572],\n",
       "                       ...,\n",
       "                       [ 0.0097, -0.0750, -0.0284,  ..., -0.0072, -0.0565, -0.0234],\n",
       "                       [-0.0479, -0.0382, -0.0438,  ..., -0.0702,  0.0371,  0.0330],\n",
       "                       [ 0.0585, -0.0688, -0.0097,  ..., -0.0352, -0.0202,  0.0487]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.q_lin.bias',\n",
       "               tensor([-0.1088,  0.1940, -0.0720,  ..., -0.1114, -0.0144,  0.2751],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.k_lin.weight',\n",
       "               tensor([[ 0.0362, -0.1041, -0.0922,  ...,  0.0563,  0.0562,  0.0347],\n",
       "                       [ 0.0234, -0.0155, -0.0113,  ...,  0.0410, -0.0269, -0.0474],\n",
       "                       [ 0.0586, -0.0470, -0.0215,  ...,  0.0417, -0.0301, -0.0015],\n",
       "                       ...,\n",
       "                       [-0.0455,  0.0467, -0.0510,  ..., -0.1193, -0.0488,  0.0047],\n",
       "                       [-0.0658,  0.0326, -0.0063,  ..., -0.0195,  0.0502,  0.0352],\n",
       "                       [ 0.0037, -0.0090, -0.0455,  ...,  0.0751, -0.0598, -0.0387]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.k_lin.bias',\n",
       "               tensor([-0.3066,  0.6680, -0.2798,  ..., -0.4404,  0.3975,  0.2445],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.v_lin.weight',\n",
       "               tensor([[ 0.0024,  0.0089,  0.0248,  ..., -0.0161, -0.0038,  0.0039],\n",
       "                       [ 0.0965, -0.0063,  0.0718,  ..., -0.0328, -0.0514, -0.0617],\n",
       "                       [-0.0652,  0.0271,  0.0274,  ..., -0.0714,  0.0446,  0.0225],\n",
       "                       ...,\n",
       "                       [-0.0546,  0.0199, -0.0602,  ..., -0.0051,  0.0083, -0.0450],\n",
       "                       [ 0.0529,  0.0351, -0.0341,  ...,  0.0054,  0.0280, -0.0197],\n",
       "                       [-0.0217, -0.0485,  0.0039,  ..., -0.0531,  0.0249, -0.0432]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.v_lin.bias',\n",
       "               tensor([-9.5725e-05,  4.9934e-03, -1.6739e-02,  ...,  4.9629e-03,\n",
       "                        2.6413e-02,  1.5160e-02], dtype=torch.float16)),\n",
       "              ('module.attentions.5.out_lin.weight',\n",
       "               tensor([[-0.0045, -0.0420, -0.0112,  ..., -0.0230,  0.0352, -0.0358],\n",
       "                       [ 0.0228,  0.0529,  0.0025,  ...,  0.0205, -0.0223,  0.0493],\n",
       "                       [-0.0285, -0.0188,  0.0067,  ..., -0.0230,  0.0076, -0.0072],\n",
       "                       ...,\n",
       "                       [-0.1318, -0.0543,  0.0020,  ...,  0.0169,  0.0001,  0.0162],\n",
       "                       [ 0.0305,  0.0203,  0.0722,  ...,  0.0331, -0.0155,  0.0476],\n",
       "                       [ 0.0052,  0.0072, -0.0370,  ..., -0.0474, -0.0356, -0.0217]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.attentions.5.out_lin.bias',\n",
       "               tensor([-0.0012, -0.0107,  0.0136,  ...,  0.0031, -0.0117,  0.0165],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.0.weight',\n",
       "               tensor([0.4771, 0.4324, 0.4082,  ..., 0.3828, 0.3962, 0.4077],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.0.bias',\n",
       "               tensor([-0.0116, -0.0559,  0.0009,  ...,  0.2216, -0.1543,  0.0580],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.1.weight',\n",
       "               tensor([0.4519, 0.4087, 0.3955,  ..., 0.3677, 0.3760, 0.4023],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.1.bias',\n",
       "               tensor([-0.0217, -0.0818,  0.0562,  ...,  0.0906, -0.0440,  0.0921],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.2.weight',\n",
       "               tensor([0.4844, 0.3989, 0.3936,  ..., 0.3545, 0.3567, 0.3977],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.2.bias',\n",
       "               tensor([ 0.0224, -0.1289, -0.0190,  ...,  0.0580,  0.0618,  0.0776],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.3.weight',\n",
       "               tensor([0.5220, 0.4221, 0.4097,  ..., 0.3643, 0.3679, 0.4192],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.3.bias',\n",
       "               tensor([ 0.0439, -0.0983,  0.0282,  ...,  0.0829,  0.0564,  0.0471],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.4.weight',\n",
       "               tensor([0.5005, 0.4321, 0.4062,  ..., 0.3882, 0.4019, 0.4404],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.4.bias',\n",
       "               tensor([ 0.0378, -0.0317,  0.0154,  ...,  0.0796,  0.0571,  0.0237],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.5.weight',\n",
       "               tensor([0.4067, 0.4434, 0.4287,  ..., 0.4167, 0.4004, 0.4785],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm1.5.bias',\n",
       "               tensor([ 0.0358, -0.0662,  0.0774,  ...,  0.1306,  0.1550, -0.0004],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin1.weight',\n",
       "               tensor([[-1.2672e-02, -3.8788e-02,  3.2306e-05,  ..., -8.1482e-02,\n",
       "                        -3.4790e-02,  2.1866e-02],\n",
       "                       [-6.6261e-03,  9.7580e-03, -1.5320e-02,  ...,  1.8555e-02,\n",
       "                         3.8696e-02,  3.7170e-02],\n",
       "                       [ 1.1742e-02,  4.8340e-02,  1.3351e-02,  ..., -8.4778e-02,\n",
       "                         6.3904e-02,  6.1218e-02],\n",
       "                       ...,\n",
       "                       [ 3.6011e-02, -3.1525e-02,  1.8738e-02,  ..., -1.7105e-02,\n",
       "                         1.3329e-02, -1.1017e-01],\n",
       "                       [-1.8951e-02, -2.9190e-02,  3.0548e-02,  ...,  2.7420e-02,\n",
       "                         6.9946e-02,  2.0924e-03],\n",
       "                       [ 3.3813e-02, -2.0172e-02,  3.8116e-02,  ...,  5.7312e-02,\n",
       "                         9.3994e-02,  1.2379e-03]], dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin1.bias',\n",
       "               tensor([-0.0131, -0.0759, -0.0362,  ..., -0.0826, -0.0804, -0.0515],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin2.weight',\n",
       "               tensor([[ 0.0046,  0.0079,  0.0529,  ...,  0.0258, -0.0221,  0.0339],\n",
       "                       [-0.0076,  0.0289,  0.0086,  ...,  0.0246,  0.0062,  0.0142],\n",
       "                       [-0.0093,  0.0363,  0.0158,  ..., -0.0796, -0.0113, -0.0455],\n",
       "                       ...,\n",
       "                       [ 0.0407,  0.0439,  0.0706,  ...,  0.0773, -0.0735, -0.0439],\n",
       "                       [-0.0270,  0.0094, -0.0075,  ..., -0.0200,  0.0424, -0.0061],\n",
       "                       [ 0.0181,  0.0336, -0.0385,  ..., -0.0266, -0.0147, -0.0220]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.0.lin2.bias',\n",
       "               tensor([-0.0343,  0.0078, -0.0060,  ..., -0.0272, -0.0274,  0.0338],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin1.weight',\n",
       "               tensor([[ 0.0227,  0.0876, -0.0132,  ..., -0.0718,  0.0081, -0.0114],\n",
       "                       [ 0.0071,  0.0038,  0.0141,  ..., -0.0280,  0.0219,  0.0181],\n",
       "                       [-0.0223, -0.0004,  0.0231,  ..., -0.0387,  0.0682,  0.0191],\n",
       "                       ...,\n",
       "                       [-0.0041,  0.0643, -0.0310,  ...,  0.0630,  0.0699,  0.0247],\n",
       "                       [ 0.0149, -0.0413, -0.0088,  ...,  0.1096,  0.0022,  0.1032],\n",
       "                       [-0.0101, -0.0541,  0.0403,  ..., -0.0012,  0.0643,  0.0296]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin1.bias',\n",
       "               tensor([-0.0133, -0.2512, -0.0746,  ..., -0.0648, -0.1320, -0.0579],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin2.weight',\n",
       "               tensor([[-0.0138, -0.0021, -0.0194,  ..., -0.0113,  0.0578,  0.0502],\n",
       "                       [-0.0067,  0.0012,  0.0370,  ...,  0.0709,  0.0808, -0.1228],\n",
       "                       [-0.0168, -0.0160, -0.0573,  ...,  0.0444,  0.1133,  0.0057],\n",
       "                       ...,\n",
       "                       [-0.0868,  0.0316,  0.0164,  ...,  0.0447, -0.0241,  0.0619],\n",
       "                       [ 0.0534, -0.0126,  0.0133,  ...,  0.1046,  0.1536, -0.0081],\n",
       "                       [-0.0398, -0.0207, -0.0770,  ..., -0.1133, -0.0060,  0.0650]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.1.lin2.bias',\n",
       "               tensor([-8.2474e-03,  1.2993e-02, -6.5002e-02,  ...,  1.6815e-02,\n",
       "                       -7.9632e-05,  5.3940e-03], dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin1.weight',\n",
       "               tensor([[-0.0262,  0.0486, -0.0066,  ...,  0.0448, -0.0556,  0.0503],\n",
       "                       [-0.0012,  0.0766, -0.0321,  ..., -0.0068,  0.0307, -0.0942],\n",
       "                       [-0.0112,  0.0356, -0.0873,  ...,  0.0812, -0.0235, -0.0278],\n",
       "                       ...,\n",
       "                       [ 0.0489,  0.0567, -0.0620,  ..., -0.0385,  0.0042,  0.0978],\n",
       "                       [ 0.0258,  0.0103, -0.0751,  ..., -0.0847,  0.0089, -0.0850],\n",
       "                       [-0.0068,  0.0457,  0.0385,  ..., -0.0710,  0.0565,  0.0436]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin1.bias',\n",
       "               tensor([-0.0541, -0.0539,  0.0065,  ..., -0.0884, -0.0382, -0.0329],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin2.weight',\n",
       "               tensor([[ 0.0011, -0.0010, -0.0041,  ...,  0.0072,  0.0250, -0.0147],\n",
       "                       [ 0.0252, -0.0105,  0.0042,  ..., -0.0570,  0.0276,  0.0704],\n",
       "                       [ 0.0375,  0.0313,  0.0132,  ..., -0.0443, -0.0424,  0.0126],\n",
       "                       ...,\n",
       "                       [ 0.0312, -0.0418, -0.0685,  ..., -0.0935,  0.0022, -0.0210],\n",
       "                       [-0.0708, -0.0626,  0.0083,  ..., -0.0435,  0.0522, -0.0146],\n",
       "                       [ 0.0221, -0.0071,  0.0397,  ...,  0.0045, -0.0598,  0.0453]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.2.lin2.bias',\n",
       "               tensor([-0.0127,  0.0516, -0.0605,  ..., -0.0313, -0.0528, -0.0266],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin1.weight',\n",
       "               tensor([[-0.0157, -0.0170, -0.0318,  ..., -0.0128, -0.0076,  0.0305],\n",
       "                       [ 0.0141, -0.0147,  0.0178,  ...,  0.0695, -0.0634,  0.0175],\n",
       "                       [-0.0073,  0.0404,  0.0450,  ..., -0.0242, -0.0070,  0.0155],\n",
       "                       ...,\n",
       "                       [ 0.0166, -0.0082, -0.0556,  ...,  0.0216, -0.0241,  0.0147],\n",
       "                       [ 0.0530, -0.0104, -0.0126,  ...,  0.0005, -0.0279,  0.0038],\n",
       "                       [ 0.0338,  0.0043,  0.0775,  ..., -0.0059,  0.0440,  0.0228]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin1.bias',\n",
       "               tensor([-0.0148, -0.0742,  0.0119,  ..., -0.0707, -0.0592, -0.0018],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin2.weight',\n",
       "               tensor([[ 2.0004e-02, -1.0902e-02,  4.1771e-03,  ..., -2.0004e-02,\n",
       "                        -9.8114e-03,  6.7711e-05],\n",
       "                       [-3.1311e-02,  4.5532e-02,  2.9892e-02,  ..., -2.5082e-03,\n",
       "                         8.6517e-03, -6.9923e-03],\n",
       "                       [ 2.7847e-02,  1.3794e-01, -3.1616e-02,  ...,  2.7588e-02,\n",
       "                        -7.2510e-02, -4.5319e-02],\n",
       "                       ...,\n",
       "                       [-5.6091e-02, -7.2021e-02,  5.9479e-02,  ...,  2.2919e-02,\n",
       "                         2.4780e-02,  2.7771e-02],\n",
       "                       [ 4.1290e-02,  2.2797e-02, -2.3254e-02,  ..., -8.3740e-02,\n",
       "                        -5.9357e-02, -1.4275e-02],\n",
       "                       [-2.1103e-02, -7.8308e-02,  3.3112e-02,  ...,  3.4119e-02,\n",
       "                        -6.9656e-03, -2.0081e-02]], dtype=torch.float16)),\n",
       "              ('module.ffns.3.lin2.bias',\n",
       "               tensor([-0.0090,  0.0278, -0.0587,  ..., -0.0312, -0.0074, -0.0637],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin1.weight',\n",
       "               tensor([[-0.0677,  0.0052, -0.1005,  ...,  0.0771, -0.1050, -0.0384],\n",
       "                       [-0.0512,  0.0034, -0.0509,  ..., -0.0155,  0.0776, -0.0857],\n",
       "                       [-0.0600,  0.0778,  0.0810,  ...,  0.0157, -0.0954, -0.0230],\n",
       "                       ...,\n",
       "                       [ 0.0418, -0.0148, -0.0379,  ..., -0.0205,  0.0207, -0.0225],\n",
       "                       [ 0.0346,  0.0348,  0.0593,  ..., -0.0584,  0.0012,  0.0373],\n",
       "                       [ 0.0545,  0.0556, -0.0768,  ...,  0.0014, -0.0168,  0.0004]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin1.bias',\n",
       "               tensor([-0.0869, -0.0952, -0.0798,  ..., -0.0242, -0.0565, -0.0575],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin2.weight',\n",
       "               tensor([[ 0.0040, -0.0289, -0.0290,  ...,  0.0137,  0.0110,  0.1158],\n",
       "                       [ 0.0149,  0.0246, -0.0155,  ..., -0.0367,  0.0259, -0.0410],\n",
       "                       [ 0.0186,  0.0055, -0.0522,  ...,  0.0167, -0.1021, -0.0504],\n",
       "                       ...,\n",
       "                       [-0.0483,  0.0542, -0.0554,  ...,  0.0244,  0.0205,  0.0349],\n",
       "                       [-0.0431,  0.0266,  0.0493,  ..., -0.0117,  0.0237, -0.0996],\n",
       "                       [ 0.0181, -0.0209,  0.0030,  ..., -0.0360,  0.0212,  0.0717]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.4.lin2.bias',\n",
       "               tensor([-0.0346,  0.0327, -0.0313,  ...,  0.0316,  0.0242, -0.0279],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin1.weight',\n",
       "               tensor([[ 0.0108,  0.0593, -0.0305,  ..., -0.1803,  0.0803, -0.1282],\n",
       "                       [ 0.0214,  0.0107,  0.0014,  ...,  0.0175, -0.0432, -0.0064],\n",
       "                       [ 0.0007, -0.0363,  0.0270,  ..., -0.0061,  0.0106,  0.0102],\n",
       "                       ...,\n",
       "                       [ 0.0056, -0.0023,  0.0199,  ..., -0.0339, -0.0433, -0.0308],\n",
       "                       [ 0.0441,  0.0565, -0.0056,  ...,  0.0247, -0.0573, -0.0717],\n",
       "                       [-0.0349, -0.0391, -0.0258,  ...,  0.0273, -0.0069,  0.0550]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin1.bias',\n",
       "               tensor([-0.0715, -0.0273, -0.1344,  ..., -0.0511, -0.0499, -0.0345],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin2.weight',\n",
       "               tensor([[-0.0015, -0.0022,  0.0561,  ...,  0.0202, -0.0457, -0.0123],\n",
       "                       [ 0.0644,  0.0430, -0.0257,  ..., -0.0504, -0.0732,  0.0125],\n",
       "                       [ 0.0464, -0.0112,  0.0099,  ...,  0.0137,  0.0497,  0.0237],\n",
       "                       ...,\n",
       "                       [-0.0373, -0.0254, -0.0321,  ...,  0.0042,  0.0180,  0.0110],\n",
       "                       [ 0.0528, -0.0042, -0.0142,  ..., -0.0712,  0.0045,  0.0144],\n",
       "                       [-0.0551, -0.0016, -0.0011,  ..., -0.0149,  0.0220,  0.0027]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.ffns.5.lin2.bias',\n",
       "               tensor([-0.0070,  0.0261, -0.0081,  ...,  0.0008,  0.0010,  0.0005],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.0.weight',\n",
       "               tensor([0.5762, 0.5234, 0.5015,  ..., 0.4077, 0.4795, 0.5229],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.0.bias',\n",
       "               tensor([-0.0064,  0.0586,  0.0102,  ..., -0.1186,  0.0911, -0.0417],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.1.weight',\n",
       "               tensor([0.5996, 0.5444, 0.5117,  ..., 0.4646, 0.4966, 0.5342],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.1.bias',\n",
       "               tensor([ 0.0169,  0.0590, -0.0360,  ..., -0.0582,  0.0399, -0.0467],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.2.weight',\n",
       "               tensor([0.6504, 0.5767, 0.5435,  ..., 0.5156, 0.5376, 0.5723],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.2.bias',\n",
       "               tensor([-0.0163,  0.0878, -0.0190,  ..., -0.0497, -0.0433, -0.0519],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.3.weight',\n",
       "               tensor([0.6050, 0.5459, 0.5356,  ..., 0.5298, 0.5205, 0.5537],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.3.bias',\n",
       "               tensor([-0.0227,  0.0378, -0.0240,  ..., -0.0473, -0.0534, -0.0234],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.4.weight',\n",
       "               tensor([0.6416, 0.5654, 0.5488,  ..., 0.5430, 0.5352, 0.5723],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.4.bias',\n",
       "               tensor([-0.0452,  0.0023, -0.0241,  ..., -0.0692, -0.0674,  0.0176],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.5.weight',\n",
       "               tensor([2.4316, 2.4395, 2.6172,  ..., 2.7090, 2.5801, 2.7852],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm2.5.bias',\n",
       "               tensor([-0.0137, -0.0698, -0.1873,  ..., -0.0140, -0.0352,  0.1290],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.0.weight',\n",
       "               tensor([0.9834, 0.9771, 0.9771,  ..., 0.9790, 0.9844, 0.9766],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.0.bias',\n",
       "               tensor([-0.0090,  0.0011, -0.0072,  ...,  0.0047, -0.0094, -0.0048],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.1.weight',\n",
       "               tensor([0.9790, 0.9746, 0.9688,  ..., 0.9746, 0.9746, 0.9712],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.1.bias',\n",
       "               tensor([ 0.0006, -0.0021, -0.0020,  ..., -0.0026, -0.0066, -0.0065],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.2.weight',\n",
       "               tensor([0.9780, 0.9766, 0.9805,  ..., 0.9736, 0.9722, 0.9849],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.2.bias',\n",
       "               tensor([-0.0017,  0.0021,  0.0053,  ...,  0.0020, -0.0029, -0.0007],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.3.weight',\n",
       "               tensor([0.9629, 0.9795, 0.9707,  ..., 0.9673, 0.9736, 0.9780],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.3.bias',\n",
       "               tensor([-0.0017,  0.0026,  0.0002,  ...,  0.0014, -0.0027, -0.0002],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.4.weight',\n",
       "               tensor([0.9746, 0.9780, 0.9575,  ..., 0.9639, 0.9634, 0.9746],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.4.bias',\n",
       "               tensor([-0.0072, -0.0010,  0.0022,  ...,  0.0084,  0.0062, -0.0062],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.5.weight',\n",
       "               tensor([0.9810, 0.9746, 0.9634,  ..., 0.9707, 0.9600, 0.9805],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.layer_norm15.5.bias',\n",
       "               tensor([ 0.0163,  0.0045,  0.0228,  ...,  0.0189, -0.0037,  0.0126],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.q_lin.weight',\n",
       "               tensor([[ 0.0164,  0.0308,  0.0518,  ..., -0.0311,  0.0111, -0.0059],\n",
       "                       [-0.0075,  0.0033,  0.0101,  ..., -0.0020, -0.0101, -0.0029],\n",
       "                       [ 0.0324,  0.0136,  0.0188,  ...,  0.0181, -0.0217, -0.0249],\n",
       "                       ...,\n",
       "                       [ 0.0107, -0.0217, -0.0229,  ...,  0.0354, -0.0202,  0.0420],\n",
       "                       [-0.0061, -0.0128, -0.0047,  ..., -0.0179,  0.0064, -0.0171],\n",
       "                       [-0.0095,  0.0062, -0.0494,  ..., -0.0125, -0.0032, -0.0164]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.q_lin.bias',\n",
       "               tensor([-0.0225, -0.0379,  0.0187,  ...,  0.0264,  0.0071, -0.0247],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.k_lin.weight',\n",
       "               tensor([[ 2.8572e-03,  3.1952e-02,  3.4088e-02,  ..., -7.3509e-03,\n",
       "                         2.0081e-02,  3.3417e-02],\n",
       "                       [-1.8492e-03,  2.2316e-03,  9.2773e-03,  ...,  2.4261e-02,\n",
       "                         4.0619e-02, -4.1366e-05],\n",
       "                       [ 3.4149e-02, -1.2970e-03, -2.8343e-03,  ...,  1.0468e-02,\n",
       "                        -6.8169e-03, -1.0010e-02],\n",
       "                       ...,\n",
       "                       [-8.5220e-03,  3.4180e-02, -2.8717e-02,  ..., -1.0674e-02,\n",
       "                        -1.4473e-02, -2.6657e-02],\n",
       "                       [ 1.6617e-02, -1.9741e-03, -1.6388e-02,  ..., -2.3041e-02,\n",
       "                         2.0294e-02, -4.2053e-02],\n",
       "                       [-4.3579e-02,  1.3977e-02,  4.4174e-03,  ..., -1.1154e-02,\n",
       "                        -5.6028e-04,  1.5091e-02]], dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.k_lin.bias',\n",
       "               tensor([-0.0140, -0.0288,  0.0210,  ..., -0.0076,  0.0244,  0.0043],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.v_lin.weight',\n",
       "               tensor([[ 0.0113, -0.0058, -0.0080,  ...,  0.0298,  0.0231,  0.0166],\n",
       "                       [-0.0257, -0.0104, -0.0416,  ...,  0.0216, -0.0304,  0.0100],\n",
       "                       [ 0.0238,  0.0001,  0.0289,  ...,  0.0073, -0.0228, -0.0145],\n",
       "                       ...,\n",
       "                       [ 0.0187,  0.0370, -0.0218,  ..., -0.0012, -0.0201,  0.0201],\n",
       "                       [ 0.0169, -0.0114, -0.0286,  ...,  0.0137,  0.0161, -0.0247],\n",
       "                       [-0.0155, -0.0278, -0.0107,  ..., -0.0450, -0.0192,  0.0044]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.v_lin.bias',\n",
       "               tensor([-0.0005,  0.0070,  0.0117,  ...,  0.0017, -0.0085, -0.0157],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.out_lin.weight',\n",
       "               tensor([[ 0.0044, -0.0038, -0.0193,  ..., -0.0091,  0.0374, -0.0304],\n",
       "                       [-0.0086, -0.0187,  0.0193,  ...,  0.0109, -0.0038,  0.0230],\n",
       "                       [ 0.0166,  0.0071,  0.0010,  ...,  0.0082,  0.0079,  0.0371],\n",
       "                       ...,\n",
       "                       [-0.0009,  0.0097,  0.0147,  ..., -0.0178, -0.0005,  0.0055],\n",
       "                       [-0.0034, -0.0280, -0.0188,  ..., -0.0157, -0.0159,  0.0083],\n",
       "                       [-0.0324,  0.0076, -0.0265,  ...,  0.0440,  0.0119,  0.0032]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.0.out_lin.bias',\n",
       "               tensor([-0.0184,  0.0186,  0.0087,  ..., -0.0038,  0.0106,  0.0066],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.q_lin.weight',\n",
       "               tensor([[-0.0164, -0.0345, -0.0269,  ...,  0.0255, -0.0297,  0.0016],\n",
       "                       [-0.0018, -0.0036,  0.0195,  ..., -0.0250, -0.0199,  0.0102],\n",
       "                       [-0.0066, -0.0629, -0.0019,  ...,  0.0254,  0.0356,  0.0268],\n",
       "                       ...,\n",
       "                       [ 0.0096,  0.0519,  0.0172,  ..., -0.0445,  0.0519,  0.0086],\n",
       "                       [ 0.0112,  0.0225, -0.0233,  ...,  0.0010,  0.0106, -0.0304],\n",
       "                       [-0.0099, -0.0239, -0.0472,  ..., -0.0106, -0.0237,  0.0122]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.q_lin.bias',\n",
       "               tensor([ 0.0093, -0.0022,  0.0051,  ..., -0.0119, -0.0138, -0.0093],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.k_lin.weight',\n",
       "               tensor([[ 0.0278, -0.0126,  0.0149,  ..., -0.0121, -0.0450, -0.0329],\n",
       "                       [ 0.0170,  0.0064,  0.0023,  ..., -0.0340, -0.0085, -0.0176],\n",
       "                       [-0.0035,  0.0009,  0.0122,  ...,  0.0414,  0.0206,  0.0355],\n",
       "                       ...,\n",
       "                       [ 0.0042,  0.0174, -0.0121,  ...,  0.0498,  0.0006, -0.0078],\n",
       "                       [ 0.0080,  0.0082, -0.0217,  ..., -0.0178, -0.0379, -0.0184],\n",
       "                       [ 0.0022, -0.0091, -0.0108,  ..., -0.0438, -0.0316,  0.0008]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.k_lin.bias',\n",
       "               tensor([ 0.0316, -0.0262,  0.0284,  ..., -0.0101,  0.0186, -0.0077],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.v_lin.weight',\n",
       "               tensor([[-0.0017,  0.0128,  0.0244,  ...,  0.0035, -0.0289, -0.0163],\n",
       "                       [-0.0006, -0.0073,  0.0075,  ..., -0.0364, -0.0291, -0.0050],\n",
       "                       [-0.0042, -0.0134, -0.0031,  ..., -0.0036,  0.0018,  0.0061],\n",
       "                       ...,\n",
       "                       [ 0.0169,  0.0150, -0.0268,  ..., -0.0056,  0.0253, -0.0209],\n",
       "                       [-0.0074,  0.0120,  0.0197,  ..., -0.0145,  0.0176, -0.0029],\n",
       "                       [ 0.0273, -0.0017, -0.0068,  ..., -0.0281,  0.0271,  0.0339]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.v_lin.bias',\n",
       "               tensor([-0.0157, -0.0086,  0.0218,  ..., -0.0131, -0.0040, -0.0253],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.out_lin.weight',\n",
       "               tensor([[ 0.0076, -0.0167,  0.0005,  ..., -0.0427,  0.0084, -0.0185],\n",
       "                       [ 0.0053,  0.0308, -0.0035,  ...,  0.0198,  0.0293, -0.0113],\n",
       "                       [-0.0189,  0.0108,  0.0241,  ..., -0.0227,  0.0103, -0.0304],\n",
       "                       ...,\n",
       "                       [ 0.0047, -0.0064,  0.0216,  ..., -0.0111, -0.0409, -0.0191],\n",
       "                       [-0.0060, -0.0067,  0.0134,  ...,  0.0093, -0.0108, -0.0130],\n",
       "                       [-0.0326,  0.0088, -0.0160,  ...,  0.0051,  0.0370,  0.0150]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.1.out_lin.bias',\n",
       "               tensor([-0.0115, -0.0105, -0.0131,  ..., -0.0121,  0.0199,  0.0102],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.q_lin.weight',\n",
       "               tensor([[-2.2888e-02,  4.4006e-02,  3.8208e-02,  ..., -2.4414e-02,\n",
       "                         1.9653e-02,  2.3270e-03],\n",
       "                       [-2.3087e-02,  4.1687e-02, -2.5826e-03,  ..., -3.6774e-02,\n",
       "                        -1.4763e-02,  2.6917e-02],\n",
       "                       [ 7.3254e-05,  2.7191e-02,  3.4485e-02,  ...,  2.9831e-02,\n",
       "                         5.1231e-03, -6.2294e-03],\n",
       "                       ...,\n",
       "                       [-8.3618e-03, -1.2619e-02,  1.4091e-02,  ...,  2.1729e-02,\n",
       "                        -2.3392e-02,  1.8356e-02],\n",
       "                       [ 1.6327e-02,  8.7128e-03, -3.3752e-02,  ..., -1.5991e-02,\n",
       "                         3.6621e-02, -2.2186e-02],\n",
       "                       [-2.7252e-02,  1.3189e-03,  2.1225e-02,  ..., -1.5507e-03,\n",
       "                        -7.7782e-03,  6.9122e-03]], dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.q_lin.bias',\n",
       "               tensor([-0.0061,  0.0068, -0.0189,  ...,  0.0206,  0.0042, -0.0330],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.k_lin.weight',\n",
       "               tensor([[ 0.0187,  0.0256, -0.0263,  ..., -0.0067,  0.0086, -0.0363],\n",
       "                       [ 0.0326,  0.0173, -0.0128,  ..., -0.0196, -0.0090, -0.0098],\n",
       "                       [-0.0160, -0.0124,  0.0399,  ...,  0.0163,  0.0072,  0.0071],\n",
       "                       ...,\n",
       "                       [-0.0252,  0.0114,  0.0105,  ..., -0.0002, -0.0021, -0.0393],\n",
       "                       [ 0.0161, -0.0331,  0.0052,  ..., -0.0156,  0.0297, -0.0427],\n",
       "                       [ 0.0009, -0.0320,  0.0344,  ...,  0.0158,  0.0137,  0.0025]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.k_lin.bias',\n",
       "               tensor([-0.0516, -0.0485, -0.0151,  ...,  0.0021,  0.0146,  0.0302],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.v_lin.weight',\n",
       "               tensor([[ 0.0075,  0.0027, -0.0115,  ..., -0.0119, -0.0291, -0.0243],\n",
       "                       [-0.0094,  0.0194, -0.0049,  ..., -0.0045,  0.0326,  0.0132],\n",
       "                       [-0.0102, -0.0183, -0.0282,  ...,  0.0093,  0.0064,  0.0009],\n",
       "                       ...,\n",
       "                       [-0.0465, -0.0222,  0.0399,  ..., -0.0275, -0.0048, -0.0037],\n",
       "                       [ 0.0057,  0.0204,  0.0044,  ..., -0.0210, -0.0065,  0.0157],\n",
       "                       [-0.0311,  0.0096,  0.0195,  ...,  0.0164,  0.0133, -0.0112]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.v_lin.bias',\n",
       "               tensor([ 0.0155, -0.0134,  0.0168,  ..., -0.0027, -0.0037, -0.0041],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.out_lin.weight',\n",
       "               tensor([[-0.0229,  0.0203,  0.0286,  ...,  0.0187, -0.0040, -0.0107],\n",
       "                       [-0.0311,  0.0038, -0.0357,  ..., -0.0018,  0.0192, -0.0151],\n",
       "                       [ 0.0010, -0.0086, -0.0320,  ..., -0.0021,  0.0122, -0.0174],\n",
       "                       ...,\n",
       "                       [-0.0148, -0.0189, -0.0184,  ..., -0.0149,  0.0082, -0.0198],\n",
       "                       [ 0.0202, -0.0093, -0.0207,  ...,  0.0152, -0.0081,  0.0157],\n",
       "                       [ 0.0015,  0.0185,  0.0205,  ...,  0.0109,  0.0060, -0.0277]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.2.out_lin.bias',\n",
       "               tensor([ 0.0005,  0.0114, -0.0077,  ..., -0.0139, -0.0114, -0.0040],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.q_lin.weight',\n",
       "               tensor([[ 0.0083,  0.0048,  0.0354,  ..., -0.0069, -0.0061,  0.0516],\n",
       "                       [-0.0266,  0.0428, -0.0094,  ..., -0.0153,  0.0114,  0.0001],\n",
       "                       [ 0.0226,  0.0194, -0.0440,  ...,  0.0261,  0.0285,  0.0228],\n",
       "                       ...,\n",
       "                       [ 0.0226,  0.0331,  0.0158,  ..., -0.0182, -0.0257, -0.0004],\n",
       "                       [-0.0154,  0.0352, -0.0091,  ...,  0.0003, -0.0126, -0.0278],\n",
       "                       [-0.0388,  0.0029,  0.0352,  ...,  0.0261,  0.0468, -0.0033]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.q_lin.bias',\n",
       "               tensor([-0.0073,  0.0450, -0.0249,  ..., -0.0199, -0.0353, -0.0004],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.k_lin.weight',\n",
       "               tensor([[-6.1584e-02,  2.0691e-02,  5.7648e-02,  ..., -1.5869e-02,\n",
       "                        -1.0376e-02,  2.4307e-02],\n",
       "                       [-9.8825e-05,  1.9699e-02,  7.7896e-03,  ...,  2.6608e-03,\n",
       "                         1.7593e-02,  8.2245e-03],\n",
       "                       [ 8.1711e-03, -1.9058e-02, -3.9917e-02,  ...,  4.7058e-02,\n",
       "                        -4.4525e-02, -3.7262e-02],\n",
       "                       ...,\n",
       "                       [ 7.8659e-03,  3.8242e-03, -5.4245e-03,  ..., -4.9988e-02,\n",
       "                        -2.9251e-02, -1.4824e-02],\n",
       "                       [-3.1982e-02,  2.9861e-02,  5.8289e-03,  ..., -2.4929e-03,\n",
       "                        -3.5034e-02,  6.7406e-03],\n",
       "                       [-4.1351e-02, -3.4058e-02,  3.6407e-02,  ..., -1.7456e-02,\n",
       "                        -5.7449e-03, -4.4434e-02]], dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.k_lin.bias',\n",
       "               tensor([ 0.0232, -0.2113,  0.0778,  ..., -0.0478,  0.0316, -0.0240],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.v_lin.weight',\n",
       "               tensor([[-0.0049,  0.0349, -0.0371,  ...,  0.0011,  0.0059,  0.0065],\n",
       "                       [-0.0074,  0.0060, -0.0242,  ...,  0.0328,  0.0080, -0.0034],\n",
       "                       [-0.0025,  0.0171,  0.0103,  ...,  0.0164, -0.0231, -0.0162],\n",
       "                       ...,\n",
       "                       [ 0.0021, -0.0066,  0.0044,  ...,  0.0178,  0.0146, -0.0224],\n",
       "                       [ 0.0206, -0.0110,  0.0119,  ...,  0.0148, -0.0268,  0.0065],\n",
       "                       [-0.0311, -0.0127, -0.0153,  ..., -0.0095, -0.0108,  0.0402]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.v_lin.bias',\n",
       "               tensor([-0.0094,  0.0096, -0.0099,  ..., -0.0060,  0.0084,  0.0071],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.out_lin.weight',\n",
       "               tensor([[ 0.0142,  0.0025, -0.0037,  ...,  0.0022,  0.0059, -0.0096],\n",
       "                       [-0.0133, -0.0204,  0.0145,  ...,  0.0077, -0.0150,  0.0172],\n",
       "                       [-0.0010, -0.0033, -0.0013,  ...,  0.0129,  0.0289,  0.0125],\n",
       "                       ...,\n",
       "                       [ 0.0114,  0.0275, -0.0099,  ..., -0.0067, -0.0263,  0.0160],\n",
       "                       [-0.0186, -0.0236,  0.0155,  ...,  0.0093,  0.0192,  0.0027],\n",
       "                       [-0.0224, -0.0154, -0.0078,  ..., -0.0159,  0.0038,  0.0106]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.3.out_lin.bias',\n",
       "               tensor([ 0.0019,  0.0133,  0.0081,  ..., -0.0032, -0.0145, -0.0097],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.q_lin.weight',\n",
       "               tensor([[-0.0150, -0.0229, -0.0005,  ..., -0.0162,  0.0262,  0.0452],\n",
       "                       [-0.0182,  0.0263, -0.0275,  ..., -0.0012, -0.0123,  0.0051],\n",
       "                       [-0.0326,  0.0172, -0.0178,  ..., -0.0385,  0.0220,  0.0158],\n",
       "                       ...,\n",
       "                       [ 0.0106, -0.0142,  0.0237,  ..., -0.0064, -0.0147,  0.0370],\n",
       "                       [-0.0356,  0.0031,  0.0186,  ..., -0.0237, -0.0619, -0.0416],\n",
       "                       [-0.0300,  0.0509, -0.0502,  ...,  0.0131,  0.0402, -0.0289]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.q_lin.bias',\n",
       "               tensor([-0.0054, -0.0143,  0.0055,  ..., -0.0277,  0.0115, -0.0109],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.k_lin.weight',\n",
       "               tensor([[-0.0097,  0.0383,  0.0359,  ...,  0.0257, -0.0125,  0.0093],\n",
       "                       [ 0.0044,  0.0182, -0.0276,  ...,  0.0072,  0.0100, -0.0299],\n",
       "                       [-0.0331, -0.0576, -0.0332,  ..., -0.0183, -0.0077,  0.0077],\n",
       "                       ...,\n",
       "                       [ 0.0330, -0.0518, -0.0044,  ...,  0.0229, -0.0129,  0.0058],\n",
       "                       [-0.0124, -0.0325, -0.0066,  ...,  0.0240,  0.0205,  0.0245],\n",
       "                       [ 0.0301, -0.0041, -0.0343,  ...,  0.0034, -0.0094, -0.0282]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.k_lin.bias',\n",
       "               tensor([-0.0345,  0.1051, -0.0536,  ..., -0.1884, -0.1255,  0.0742],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.v_lin.weight',\n",
       "               tensor([[ 2.2827e-02, -2.3941e-02, -4.3945e-02,  ..., -3.0136e-02,\n",
       "                        -7.7705e-03, -1.8097e-02],\n",
       "                       [-2.6703e-03,  2.2888e-02,  4.2114e-03,  ...,  2.4872e-02,\n",
       "                         1.1452e-02, -2.0004e-02],\n",
       "                       [-3.2135e-02,  1.4618e-02,  2.0721e-02,  ..., -8.8806e-03,\n",
       "                        -2.6215e-02, -2.4460e-02],\n",
       "                       ...,\n",
       "                       [ 7.1144e-03, -2.7649e-02,  1.1894e-02,  ...,  1.5440e-03,\n",
       "                        -2.3102e-02,  2.7237e-03],\n",
       "                       [ 1.7633e-03,  1.5884e-02, -1.1650e-02,  ...,  1.6037e-02,\n",
       "                         1.2924e-02, -1.1665e-02],\n",
       "                       [-4.4286e-05, -9.0103e-03, -1.2428e-02,  ...,  1.4992e-02,\n",
       "                        -4.7226e-03,  6.3553e-03]], dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.v_lin.bias',\n",
       "               tensor([ 0.0090, -0.0102, -0.0250,  ..., -0.0100, -0.0058,  0.0164],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.out_lin.weight',\n",
       "               tensor([[ 0.0089, -0.0007, -0.0273,  ...,  0.0024,  0.0021,  0.0211],\n",
       "                       [-0.0010,  0.0103,  0.0240,  ..., -0.0362, -0.0237,  0.0319],\n",
       "                       [-0.0135,  0.0041, -0.0253,  ...,  0.0104, -0.0084,  0.0178],\n",
       "                       ...,\n",
       "                       [ 0.0055, -0.0088,  0.0134,  ..., -0.0066, -0.0142, -0.0122],\n",
       "                       [-0.0022, -0.0150, -0.0187,  ..., -0.0083,  0.0085, -0.0249],\n",
       "                       [-0.0100, -0.0244,  0.0082,  ..., -0.0069, -0.0065,  0.0098]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.4.out_lin.bias',\n",
       "               tensor([ 0.0135, -0.0009,  0.0178,  ..., -0.0086, -0.0131, -0.0152],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.q_lin.weight',\n",
       "               tensor([[ 0.0045,  0.0400,  0.0250,  ..., -0.0507, -0.0172, -0.0699],\n",
       "                       [ 0.0104,  0.0077, -0.0351,  ..., -0.0365, -0.0215,  0.0273],\n",
       "                       [-0.0253,  0.0064, -0.0235,  ...,  0.0100, -0.0077, -0.0109],\n",
       "                       ...,\n",
       "                       [ 0.0221,  0.0023,  0.0629,  ...,  0.0512, -0.0072, -0.0051],\n",
       "                       [-0.0186, -0.0114,  0.0185,  ...,  0.0051, -0.0046, -0.0305],\n",
       "                       [-0.0143,  0.0208,  0.0135,  ..., -0.0596, -0.0375,  0.0126]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.q_lin.bias',\n",
       "               tensor([ 0.0156, -0.0152, -0.0185,  ...,  0.0112, -0.0016,  0.0052],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.k_lin.weight',\n",
       "               tensor([[-0.0485, -0.0308,  0.0188,  ...,  0.0098,  0.0137,  0.0038],\n",
       "                       [-0.0566,  0.0186, -0.0167,  ...,  0.0082, -0.0131,  0.0256],\n",
       "                       [-0.0008,  0.0271,  0.0265,  ..., -0.0289, -0.0056,  0.0504],\n",
       "                       ...,\n",
       "                       [-0.0047, -0.0163,  0.0310,  ...,  0.0072,  0.0494, -0.0442],\n",
       "                       [ 0.0309, -0.0046,  0.0499,  ...,  0.0198,  0.0844, -0.0351],\n",
       "                       [ 0.0175, -0.0252,  0.0158,  ..., -0.0475, -0.0208,  0.0504]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.k_lin.bias',\n",
       "               tensor([ 0.2891, -0.1833,  0.0045,  ...,  0.6196,  0.1527, -0.3357],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.v_lin.weight',\n",
       "               tensor([[ 0.0314, -0.0233, -0.0279,  ..., -0.0146,  0.0153, -0.0135],\n",
       "                       [ 0.0156, -0.0220, -0.0176,  ..., -0.0115,  0.0243,  0.0170],\n",
       "                       [ 0.0249, -0.0171,  0.0405,  ..., -0.0211,  0.0049,  0.0061],\n",
       "                       ...,\n",
       "                       [ 0.0073, -0.0184,  0.0068,  ...,  0.0090,  0.0170,  0.0233],\n",
       "                       [-0.0062, -0.0233,  0.0080,  ...,  0.0136,  0.0130,  0.0341],\n",
       "                       [ 0.0135,  0.0044,  0.0328,  ..., -0.0054,  0.0045, -0.0010]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.v_lin.bias',\n",
       "               tensor([-0.0151,  0.0076, -0.0020,  ..., -0.0197, -0.0026, -0.0288],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.out_lin.weight',\n",
       "               tensor([[-0.0186, -0.0019,  0.0323,  ...,  0.0019, -0.0088, -0.0157],\n",
       "                       [-0.0107, -0.0197,  0.0131,  ...,  0.0075, -0.0117, -0.0156],\n",
       "                       [-0.0162, -0.0208,  0.0166,  ..., -0.0018,  0.0008,  0.0325],\n",
       "                       ...,\n",
       "                       [ 0.0196, -0.0029, -0.0198,  ...,  0.0012,  0.0004, -0.0066],\n",
       "                       [ 0.0253, -0.0099,  0.0022,  ..., -0.0079, -0.0101,  0.0193],\n",
       "                       [-0.0005, -0.0136, -0.0199,  ...,  0.0229,  0.0106,  0.0053]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.encoder_attn.5.out_lin.bias',\n",
       "               tensor([ 0.0178,  0.0137,  0.0197,  ..., -0.0101, -0.0159, -0.0171],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.pred_layer.proj.weight',\n",
       "               tensor([[-0.0026,  0.0328, -0.0086,  ..., -0.0876,  0.0523,  0.0307],\n",
       "                       [-0.0312, -0.0044,  0.0104,  ...,  0.0131, -0.0293,  0.0129],\n",
       "                       [-0.0401,  0.0246,  0.0135,  ..., -0.0760, -0.0206, -0.0047],\n",
       "                       ...,\n",
       "                       [-0.0231, -0.0485, -0.0335,  ..., -0.0450,  0.0485,  0.0441],\n",
       "                       [-0.0276,  0.0656,  0.0337,  ..., -0.0289,  0.0030, -0.0454],\n",
       "                       [ 0.0289, -0.0684, -0.0053,  ..., -0.0873,  0.0255, -0.0303]],\n",
       "                      dtype=torch.float16)),\n",
       "              ('module.pred_layer.proj.bias',\n",
       "               tensor([-2.2031, -0.0828, -2.3945,  ..., -1.2891, -1.1865, -1.6445],\n",
       "                      dtype=torch.float16))]),\n",
       " 'dico_id2word': {0: '<s>',\n",
       "  1: '</s>',\n",
       "  2: '<pad>',\n",
       "  3: '<unk>',\n",
       "  4: '<special0>',\n",
       "  5: '<special1>',\n",
       "  6: '<special2>',\n",
       "  7: '<special3>',\n",
       "  8: '<special4>',\n",
       "  9: '<special5>',\n",
       "  10: '<special6>',\n",
       "  11: '<special7>',\n",
       "  12: '<special8>',\n",
       "  13: '<special9>',\n",
       "  14: '',\n",
       "  15: ')',\n",
       "  16: '(',\n",
       "  17: '.',\n",
       "  18: ',',\n",
       "  19: ';',\n",
       "  20: '=',\n",
       "  21: '*',\n",
       "  22: '-',\n",
       "  23: '\"',\n",
       "  24: 'NEW_LINE',\n",
       "  25: \"'\",\n",
       "  26: 'STRNEWLINE',\n",
       "  27: ':',\n",
       "  28: '}',\n",
       "  29: '{',\n",
       "  30: 'ENDCOM',\n",
       "  31: 'the',\n",
       "  32: '#',\n",
       "  33: '//',\n",
       "  34: ']',\n",
       "  35: '[',\n",
       "  36: '_',\n",
       "  37: 'if',\n",
       "  38: 'self',\n",
       "  39: '>',\n",
       "  40: 'INDENT',\n",
       "  41: 'DEDENT',\n",
       "  42: '<',\n",
       "  43: 'return',\n",
       "  44: '0',\n",
       "  45: '/',\n",
       "  46: '::',\n",
       "  47: '->',\n",
       "  48: '1',\n",
       "  49: '+',\n",
       "  50: 'to',\n",
       "  51: 'a',\n",
       "  52: '@',\n",
       "  53: 'import',\n",
       "  54: 'for',\n",
       "  55: 'of',\n",
       "  56: 'in',\n",
       "  57: 'i',\n",
       "  58: 'int',\n",
       "  59: 'is',\n",
       "  60: 'this',\n",
       "  61: 'public',\n",
       "  62: '==',\n",
       "  63: '%',\n",
       "  64: '&',\n",
       "  65: 'void',\n",
       "  66: 'new',\n",
       "  67: '2',\n",
       "  68: '/*',\n",
       "  69: '*/',\n",
       "  70: 'and',\n",
       "  71: 'def',\n",
       "  72: 's',\n",
       "  73: 'String',\n",
       "  74: 'name',\n",
       "  75: 'const',\n",
       "  76: '_@@',\n",
       "  77: 'TABSYMBOL',\n",
       "  78: 'not',\n",
       "  79: 'or',\n",
       "  80: 'else',\n",
       "  81: 'org',\n",
       "  82: 'License',\n",
       "  83: '!',\n",
       "  84: '\"\"\"',\n",
       "  85: 'class',\n",
       "  86: 'value',\n",
       "  87: 'get@@',\n",
       "  88: 'from',\n",
       "  89: 'null',\n",
       "  90: 'file',\n",
       "  91: 'x',\n",
       "  92: 'data',\n",
       "  93: '3',\n",
       "  94: 'be',\n",
       "  95: 'with',\n",
       "  96: 'm_@@',\n",
       "  97: 'static',\n",
       "  98: '!=',\n",
       "  99: 'final',\n",
       "  100: 'type',\n",
       "  101: 'it',\n",
       "  102: 'false',\n",
       "  103: 'None',\n",
       "  104: '`',\n",
       "  105: 'include',\n",
       "  106: 'true',\n",
       "  107: 'case',\n",
       "  108: 'private',\n",
       "  109: '\\\\n',\n",
       "  110: 'h',\n",
       "  111: 'that',\n",
       "  112: 'id',\n",
       "  113: 'get',\n",
       "  114: 'p',\n",
       "  115: 'size',\n",
       "  116: 'c',\n",
       "  117: 't',\n",
       "  118: '<<',\n",
       "  119: 'set@@',\n",
       "  120: 'code',\n",
       "  121: 'e',\n",
       "  122: 'The',\n",
       "  123: '++',\n",
       "  124: 'as',\n",
       "  125: 'd',\n",
       "  126: 'by',\n",
       "  127: '4',\n",
       "  128: 'com',\n",
       "  129: 'm@@',\n",
       "  130: 'path',\n",
       "  131: '?',\n",
       "  132: '&&',\n",
       "  133: 'result',\n",
       "  134: 'on',\n",
       "  135: 'p@@',\n",
       "  136: 'an',\n",
       "  137: 'string',\n",
       "  138: 'param',\n",
       "  139: 'under',\n",
       "  140: 'b',\n",
       "  141: 'list',\n",
       "  142: 'y',\n",
       "  143: 's@@',\n",
       "  144: 'key',\n",
       "  145: 'java',\n",
       "  146: 'A',\n",
       "  147: '|',\n",
       "  148: 'break',\n",
       "  149: 'Type',\n",
       "  150: 'std',\n",
       "  151: 'r',\n",
       "  152: 'True',\n",
       "  153: 'char',\n",
       "  154: 'f',\n",
       "  155: 'List',\n",
       "  156: 'f@@',\n",
       "  157: 'This',\n",
       "  158: 'is@@',\n",
       "  159: '/@@',\n",
       "  160: 'at',\n",
       "  161: 'bool',\n",
       "  162: 'set',\n",
       "  163: 'Get@@',\n",
       "  164: '</DOCUMENT>',\n",
       "  165: '+=',\n",
       "  166: 'index',\n",
       "  167: 'test',\n",
       "  168: 'n',\n",
       "  169: 'are',\n",
       "  170: 'Exception',\n",
       "  171: '\\\\',\n",
       "  172: 'Override',\n",
       "  173: 'apache',\n",
       "  174: 'context',\n",
       "  175: 'we',\n",
       "  176: 'n@@',\n",
       "  177: 'version',\n",
       "  178: 'Name',\n",
       "  179: 'throws',\n",
       "  180: 'append',\n",
       "  181: '5',\n",
       "  182: 'NULL',\n",
       "  183: 'length',\n",
       "  184: 'http',\n",
       "  185: 'm',\n",
       "  186: 'object',\n",
       "  187: 'util',\n",
       "  188: 'u',\n",
       "  189: 'try',\n",
       "  190: 'use',\n",
       "  191: 'node',\n",
       "  192: 'you',\n",
       "  193: 'C@@',\n",
       "  194: 'str',\n",
       "  195: '||',\n",
       "  196: 'Object',\n",
       "  197: 'distributed',\n",
       "  198: 'out',\n",
       "  199: 'will',\n",
       "  200: 'default',\n",
       "  201: 'Test',\n",
       "  202: 'add',\n",
       "  203: 'may',\n",
       "  204: 'args',\n",
       "  205: 'get_@@',\n",
       "  206: 'len',\n",
       "  207: 'False',\n",
       "  208: 'OR',\n",
       "  209: 'state',\n",
       "  210: '8',\n",
       "  211: 'boolean',\n",
       "  212: 'error',\n",
       "  213: 'Id',\n",
       "  214: 'C',\n",
       "  215: 'can',\n",
       "  216: 'float',\n",
       "  217: 'end',\n",
       "  218: 'j',\n",
       "  219: 'copy',\n",
       "  220: 'v',\n",
       "  221: 'text',\n",
       "  222: 'all',\n",
       "  223: 'os',\n",
       "  224: 'Data',\n",
       "  225: 'test_@@',\n",
       "  226: 'i@@',\n",
       "  227: 'k@@',\n",
       "  228: 'user',\n",
       "  229: 'line',\n",
       "  230: 'If',\n",
       "  231: 'b@@',\n",
       "  232: 'request',\n",
       "  233: 'c@@',\n",
       "  234: 'info',\n",
       "  235: 'double',\n",
       "  236: 'd@@',\n",
       "  237: 'except',\n",
       "  238: 'OF',\n",
       "  239: 'time',\n",
       "  240: 'test@@',\n",
       "  241: 'See',\n",
       "  242: 'Value',\n",
       "  243: 'T',\n",
       "  244: 'ID',\n",
       "  245: 'count',\n",
       "  246: 'module',\n",
       "  247: 'Map',\n",
       "  248: 'Info',\n",
       "  249: 'should',\n",
       "  250: 'ANY',\n",
       "  251: '2.0',\n",
       "  252: 'message',\n",
       "  253: 'have',\n",
       "  254: '6',\n",
       "  255: 'v@@',\n",
       "  256: 'method',\n",
       "  257: 'File',\n",
       "  258: 'long',\n",
       "  259: 'k',\n",
       "  260: '<DOCUMENT_ID=\"@@',\n",
       "  261: 'start',\n",
       "  262: 's_@@',\n",
       "  263: 'www',\n",
       "  264: 'status',\n",
       "  265: '10',\n",
       "  266: 'Set@@',\n",
       "  267: 'assert',\n",
       "  268: 't@@',\n",
       "  269: 'Node',\n",
       "  270: 'item',\n",
       "  271: 'To@@',\n",
       "  272: 'package',\n",
       "  273: 'x@@',\n",
       "  274: 'assertEqual',\n",
       "  275: 'X',\n",
       "  276: 'GNU',\n",
       "  277: 'one',\n",
       "  278: 'values',\n",
       "  279: 'format',\n",
       "  280: 'unsigned',\n",
       "  281: 'Public',\n",
       "  282: 'Copyright',\n",
       "  283: 'model',\n",
       "  284: 'e@@',\n",
       "  285: 'g',\n",
       "  286: 'add@@',\n",
       "  287: 'software',\n",
       "  288: 'I@@',\n",
       "  289: 'a@@',\n",
       "  290: 'link',\n",
       "  291: 'url',\n",
       "  292: 'You',\n",
       "  293: 'fields',\n",
       "  294: 'Error',\n",
       "  295: 'source',\n",
       "  296: 'other',\n",
       "  297: 'config',\n",
       "  298: '$',\n",
       "  299: 'new@@',\n",
       "  300: 'Set',\n",
       "  301: 'General',\n",
       "  302: 'any',\n",
       "  303: 'T@@',\n",
       "  304: 'while',\n",
       "  305: 'event',\n",
       "  306: '-@@',\n",
       "  307: '7',\n",
       "  308: 'no',\n",
       "  309: 'Size',\n",
       "  310: 'response',\n",
       "  311: 'db',\n",
       "  312: 'g@@',\n",
       "  313: 'r@@',\n",
       "  314: 'map',\n",
       "  315: 'required',\n",
       "  316: 'field',\n",
       "  317: 'write',\n",
       "  318: 'params',\n",
       "  319: 'o',\n",
       "  320: 'l',\n",
       "  321: 'licenses',\n",
       "  322: 'Context',\n",
       "  323: 'print',\n",
       "  324: 'client',\n",
       "  325: 'assertEquals',\n",
       "  326: 'S@@',\n",
       "  327: 'used',\n",
       "  328: 'Index',\n",
       "  329: 'output',\n",
       "  330: 'number',\n",
       "  331: 'obj',\n",
       "  332: 'State',\n",
       "  333: 'either',\n",
       "  334: 'Software',\n",
       "  335: 'h@@',\n",
       "  336: 'Version',\n",
       "  337: 'msg',\n",
       "  338: 'dict',\n",
       "  339: 'create@@',\n",
       "  340: 'Q@@',\n",
       "  341: 'throw',\n",
       "  342: 'instance',\n",
       "  343: 'array',\n",
       "  344: 'target',\n",
       "  345: 'P@@',\n",
       "  346: 'input',\n",
       "  347: 'but',\n",
       "  348: 'function',\n",
       "  349: 'w',\n",
       "  350: '2@@',\n",
       "  351: 'D@@',\n",
       "  352: 'buffer',\n",
       "  353: 'ing',\n",
       "  354: 'which',\n",
       "  355: 'l@@',\n",
       "  356: 'endif',\n",
       "  357: 'first',\n",
       "  358: 'more',\n",
       "  359: 'L',\n",
       "  360: 'E@@',\n",
       "  361: 'byte',\n",
       "  362: 'only',\n",
       "  363: 'B@@',\n",
       "  364: '~',\n",
       "  365: 'buf',\n",
       "  366: 'raise',\n",
       "  367: 'in@@',\n",
       "  368: 'WITHOUT',\n",
       "  369: 'Path',\n",
       "  370: 'Test@@',\n",
       "  371: 'Count',\n",
       "  372: 'super',\n",
       "  373: 'my@@',\n",
       "  374: 're@@',\n",
       "  375: 'create',\n",
       "  376: 'when',\n",
       "  377: 'z',\n",
       "  378: 'un@@',\n",
       "  379: 'G@@',\n",
       "  380: 'X@@',\n",
       "  381: 'log',\n",
       "  382: 'B',\n",
       "  383: 'pos',\n",
       "  384: 'implied',\n",
       "  385: 'j@@',\n",
       "  386: 'F@@',\n",
       "  387: 'I',\n",
       "  388: 'group',\n",
       "  389: '__@@',\n",
       "  390: 'R@@',\n",
       "  391: 'protected',\n",
       "  392: 'M@@',\n",
       "  393: 'S',\n",
       "  394: 'w@@',\n",
       "  395: 'width',\n",
       "  396: 'io',\n",
       "  397: 'IS',\n",
       "  398: 'on@@',\n",
       "  399: 'Manager',\n",
       "  400: 'table',\n",
       "  401: 'res',\n",
       "  402: '9',\n",
       "  403: 'options',\n",
       "  404: 'N@@',\n",
       "  405: 'Class',\n",
       "  406: 'so',\n",
       "  407: 'to@@',\n",
       "  408: 'V@@',\n",
       "  409: 'see',\n",
       "  410: 'parent',\n",
       "  411: 'LICENSE',\n",
       "  412: 'using',\n",
       "  413: 'must',\n",
       "  414: 'H@@',\n",
       "  415: '>=',\n",
       "  416: 'np',\n",
       "  417: 'models',\n",
       "  418: 'core',\n",
       "  419: 'L@@',\n",
       "  420: 'A@@',\n",
       "  421: 'R',\n",
       "  422: 'In@@',\n",
       "  423: 'has',\n",
       "  424: 'u@@',\n",
       "  425: 'catch',\n",
       "  426: 'read',\n",
       "  427: 'next',\n",
       "  428: 'mode',\n",
       "  429: 'elif',\n",
       "  430: 'offset',\n",
       "  431: 'val',\n",
       "  432: 'extends',\n",
       "  433: 'specific',\n",
       "  434: 'o@@',\n",
       "  435: 'check',\n",
       "  436: 'y@@',\n",
       "  437: 'ing@@',\n",
       "  438: 'server',\n",
       "  439: 'Event',\n",
       "  440: 'entry',\n",
       "  441: 'IOException',\n",
       "  442: 'AS',\n",
       "  443: '/tree/master/@@',\n",
       "  444: 'Apache',\n",
       "  445: 'base',\n",
       "  446: 'description',\n",
       "  447: 'max',\n",
       "  448: 'K@@',\n",
       "  449: 'q@@',\n",
       "  450: 'namespace',\n",
       "  451: 'current',\n",
       "  452: 'put',\n",
       "  453: 'WARRANTIES',\n",
       "  454: 'Foundation',\n",
       "  455: 'Key',\n",
       "  456: 're',\n",
       "  457: '**',\n",
       "  458: 'do',\n",
       "  459: 'action',\n",
       "  460: 'block',\n",
       "  461: 'delete',\n",
       "  462: 'stream',\n",
       "  463: 'language',\n",
       "  464: 'filename',\n",
       "  465: 'Y',\n",
       "  466: 'without',\n",
       "  467: 'exception',\n",
       "  468: '16',\n",
       "  469: 'element',\n",
       "  470: 'z@@',\n",
       "  471: 'Returns',\n",
       "  472: 'Is@@',\n",
       "  473: 'files',\n",
       "  474: 'is_@@',\n",
       "  475: 'sys',\n",
       "  476: 'P',\n",
       "  477: 'height',\n",
       "  478: 'View',\n",
       "  479: 'join',\n",
       "  480: 'Element',\n",
       "  481: 'content',\n",
       "  482: 'File@@',\n",
       "  483: 'J@@',\n",
       "  484: 'common',\n",
       "  485: 'address',\n",
       "  486: 'Item',\n",
       "  487: 'update',\n",
       "  488: 'api',\n",
       "  489: 'token',\n",
       "  490: 'W@@',\n",
       "  491: 'Integer',\n",
       "  492: 'command',\n",
       "  493: 'django',\n",
       "  494: 'Result',\n",
       "  495: 'option',\n",
       "  496: 'Service',\n",
       "  497: 'Text',\n",
       "  498: 'Data@@',\n",
       "  499: 'E',\n",
       "  500: 'range',\n",
       "  501: 'ret',\n",
       "  502: 'vector',\n",
       "  503: 'Time',\n",
       "  504: '4@@',\n",
       "  505: 'wx@@',\n",
       "  506: 'equals',\n",
       "  507: 'run',\n",
       "  508: 'port',\n",
       "  509: 'QString',\n",
       "  510: 'sizeof',\n",
       "  511: 'Type@@',\n",
       "  512: 'D',\n",
       "  513: 'dir',\n",
       "  514: 'view',\n",
       "  515: '__init__',\n",
       "  516: 'permissions',\n",
       "  517: '<=',\n",
       "  518: 'row',\n",
       "  519: 'O@@',\n",
       "  520: 'close',\n",
       "  521: 'set_@@',\n",
       "  522: 'sub@@',\n",
       "  523: 'image',\n",
       "  524: 'toString',\n",
       "  525: '32',\n",
       "  526: 'query',\n",
       "  527: 'template',\n",
       "  528: 'define',\n",
       "  529: 'System',\n",
       "  530: 'N',\n",
       "  531: 'terms',\n",
       "  532: 'continue',\n",
       "  533: 's/@@',\n",
       "  534: 'call',\n",
       "  535: 'match',\n",
       "  536: 'Builder',\n",
       "  537: 'Message',\n",
       "  538: 'foo',\n",
       "  539: 'begin',\n",
       "  540: 'given',\n",
       "  541: 'empty',\n",
       "  542: 'M',\n",
       "  543: 'U@@',\n",
       "  544: 'KIND',\n",
       "  545: 'tag',\n",
       "  546: 'writing',\n",
       "  547: 'objects',\n",
       "  548: 'program',\n",
       "  549: '3@@',\n",
       "  550: 'main',\n",
       "  551: 'Request',\n",
       "  552: 'kwargs',\n",
       "  553: 'filter',\n",
       "  554: '^',\n",
       "  555: 'names',\n",
       "  556: 'settings',\n",
       "  557: 'date',\n",
       "  558: 'information',\n",
       "  559: 'Free',\n",
       "  560: 'THE',\n",
       "  561: 'src',\n",
       "  562: 'de@@',\n",
       "  563: 'header',\n",
       "  564: 'free',\n",
       "  565: '9@@',\n",
       "  566: '.java\">',\n",
       "  567: 'google',\n",
       "  568: 'position',\n",
       "  569: 'root',\n",
       "  570: '1@@',\n",
       "  571: 'expected',\n",
       "  572: 'property',\n",
       "  573: 'max@@',\n",
       "  574: 'bytes',\n",
       "  575: 'pass',\n",
       "  576: 'Entry',\n",
       "  577: 'cache',\n",
       "  578: 'On@@',\n",
       "  579: 'FOR',\n",
       "  580: 'obtain',\n",
       "  581: 'android',\n",
       "  582: 'All',\n",
       "  583: 'express',\n",
       "  584: 'num@@',\n",
       "  585: 'struct',\n",
       "  586: 'Licensed',\n",
       "  587: 'al@@',\n",
       "  588: 'Model',\n",
       "  589: 'compliance',\n",
       "  590: 'F',\n",
       "  591: 'Mode',\n",
       "  592: 'applicable',\n",
       "  593: 'found',\n",
       "  594: 'q',\n",
       "  595: 'For@@',\n",
       "  596: 'limitations',\n",
       "  597: 'flags',\n",
       "  598: 'Factory',\n",
       "  599: '8@@',\n",
       "  600: 'switch',\n",
       "  601: 'governing',\n",
       "  602: 'id@@',\n",
       "  603: 'CONDITIONS',\n",
       "  604: 'parser',\n",
       "  605: 'BASIS',\n",
       "  606: 'Config',\n",
       "  607: '7@@',\n",
       "  608: '5@@',\n",
       "  609: 'open',\n",
       "  610: 'host',\n",
       "  611: 'up',\n",
       "  612: 'Unless',\n",
       "  613: 'law',\n",
       "  614: '0x00',\n",
       "  615: 'doc',\n",
       "  616: 'arg',\n",
       "  617: 'color',\n",
       "  618: 'Array',\n",
       "  619: 'agreed',\n",
       "  620: 'level',\n",
       "  621: 'form',\n",
       "  622: 'boost',\n",
       "  623: 'Handler',\n",
       "  624: 'was',\n",
       "  625: 'auto',\n",
       "  626: 'Field',\n",
       "  627: 'p_@@',\n",
       "  628: 'assertTrue',\n",
       "  629: 'find',\n",
       "  630: 'able',\n",
       "  631: 'json',\n",
       "  632: 'order',\n",
       "  633: '6@@',\n",
       "  634: 'er@@',\n",
       "  635: 'IN',\n",
       "  636: 'g_@@',\n",
       "  637: 'items',\n",
       "  638: 'its',\n",
       "  639: 'label',\n",
       "  640: \"'''\",\n",
       "  641: 'size_t',\n",
       "  642: 'str@@',\n",
       "  643: 'left',\n",
       "  644: 'javax',\n",
       "  645: 'Status',\n",
       "  646: 'Buffer',\n",
       "  647: 'defined',\n",
       "  648: 'Base',\n",
       "  649: 'V',\n",
       "  650: 'details',\n",
       "  651: 'session',\n",
       "  652: 'd_@@',\n",
       "  653: '100',\n",
       "  654: 'Action',\n",
       "  655: 'remove',\n",
       "  656: 'title',\n",
       "  657: 'With@@',\n",
       "  658: 'service',\n",
       "  659: 'body',\n",
       "  660: 'point',\n",
       "  661: 'connection',\n",
       "  662: 'into',\n",
       "  663: 'utils',\n",
       "  664: 'debug',\n",
       "  665: 'handler',\n",
       "  666: 'Y@@',\n",
       "  667: '12',\n",
       "  668: 'frame',\n",
       "  669: 'env',\n",
       "  670: 'keys',\n",
       "  671: 'm_p@@',\n",
       "  672: 'xml',\n",
       "  673: 'Table',\n",
       "  674: 'work',\n",
       "  675: 'html',\n",
       "  676: 'project',\n",
       "  677: 'Length',\n",
       "  678: '0x00@@',\n",
       "  679: 'me',\n",
       "  680: 'specified',\n",
       "  681: 'Ptr',\n",
       "  682: 'your',\n",
       "  683: 'then',\n",
       "  684: 'read@@',\n",
       "  685: 'cmd',\n",
       "  686: 'From@@',\n",
       "  687: 'second',\n",
       "  688: 'iterator',\n",
       "  689: 'List@@',\n",
       "  690: 'as@@',\n",
       "  691: 'license',\n",
       "  692: 'AND',\n",
       "  693: 'copyright',\n",
       "  694: 'types',\n",
       "  695: 'results',\n",
       "  696: 'has@@',\n",
       "  697: 'do@@',\n",
       "  698: 'Group',\n",
       "  699: 'Z@@',\n",
       "  700: 'Base@@',\n",
       "  701: 'new_@@',\n",
       "  702: 'shape',\n",
       "  703: 'Number',\n",
       "  704: '1.0',\n",
       "  705: 'check@@',\n",
       "  706: 'modify',\n",
       "  707: 'Re@@',\n",
       "  708: 'author',\n",
       "  709: 't_@@',\n",
       "  710: 'Color',\n",
       "  711: 'right',\n",
       "  712: 'following',\n",
       "  713: 'style',\n",
       "  714: 'file@@',\n",
       "  715: 'ed',\n",
       "  716: 'build',\n",
       "  717: 'need',\n",
       "  718: 'tr',\n",
       "  719: 'split',\n",
       "  720: 'logger',\n",
       "  721: 'app',\n",
       "  722: 'Point',\n",
       "  723: 'Offset',\n",
       "  724: '20',\n",
       "  725: 'location',\n",
       "  726: 'cls',\n",
       "  727: 'ArrayList',\n",
       "  728: 'ed@@',\n",
       "  729: 'net',\n",
       "  730: 'builder',\n",
       "  731: 'op',\n",
       "  732: 'current@@',\n",
       "  733: 'prefix',\n",
       "  734: 'handle',\n",
       "  735: 'Get',\n",
       "  736: 'Inc',\n",
       "  737: 'interface',\n",
       "  738: 'lang',\n",
       "  739: 'And@@',\n",
       "  740: '.cpp\">',\n",
       "  741: 'child',\n",
       "  742: 'Key@@',\n",
       "  743: '\\\\x@@',\n",
       "  744: 'ref',\n",
       "  745: 'min',\n",
       "  746: 'ui',\n",
       "  747: 'Add@@',\n",
       "  748: 'page',\n",
       "  749: 'contains',\n",
       "  750: 'idx',\n",
       "  751: 'part',\n",
       "  752: 'isinstance',\n",
       "  753: '11',\n",
       "  754: 'Assert',\n",
       "  755: 'Un@@',\n",
       "  756: '_id',\n",
       "  757: 'st@@',\n",
       "  758: 'URL',\n",
       "  759: '_name',\n",
       "  760: 'clear',\n",
       "  761: 'last',\n",
       "  762: 'push_back',\n",
       "  763: 'Node@@',\n",
       "  764: 'same',\n",
       "  765: 'PURPOSE',\n",
       "  766: 'FITNESS',\n",
       "  767: 'Source',\n",
       "  768: 'ids',\n",
       "  769: '0.0',\n",
       "  770: '>>',\n",
       "  771: 'PARTICULAR',\n",
       "  772: 'MERCHANTABILITY',\n",
       "  773: 'thread',\n",
       "  774: 'Text@@',\n",
       "  775: 'even',\n",
       "  776: 'K',\n",
       "  777: 'device',\n",
       "  778: 'hash',\n",
       "  779: 'no@@',\n",
       "  780: 'library',\n",
       "  781: 'attribute',\n",
       "  782: 'each',\n",
       "  783: 'getName',\n",
       "  784: 'tree',\n",
       "  785: 'c_str',\n",
       "  786: 'uint32',\n",
       "  787: 'num',\n",
       "  788: 'column',\n",
       "  789: 'er',\n",
       "  790: '_S@@',\n",
       "  791: 'Check',\n",
       "  792: 'after',\n",
       "  793: 'Impl',\n",
       "  794: 'now',\n",
       "  795: 'search',\n",
       "  796: 'parameters',\n",
       "  797: 'ts',\n",
       "  798: 'there',\n",
       "  799: '64',\n",
       "  800: 'For',\n",
       "  801: 'Log',\n",
       "  802: 'func',\n",
       "  803: 'U',\n",
       "  804: '1\"',\n",
       "  805: 'Utils',\n",
       "  806: 'Date',\n",
       "  807: 'Event@@',\n",
       "  808: 'Filter',\n",
       "  809: 'directory',\n",
       "  810: 'ctx',\n",
       "  811: 'ptr',\n",
       "  812: 'lines',\n",
       "  813: 'tests',\n",
       "  814: 'Create@@',\n",
       "  815: 'to_@@',\n",
       "  816: 'write@@',\n",
       "  817: 'Value@@',\n",
       "  818: 'In',\n",
       "  819: 'Sub@@',\n",
       "  820: 'mock',\n",
       "  821: 'received',\n",
       "  822: 'err',\n",
       "  823: 'Response',\n",
       "  824: 'nodes',\n",
       "  825: 'init',\n",
       "  826: 'Client',\n",
       "  827: 'task',\n",
       "  828: 'resource',\n",
       "  829: 'User',\n",
       "  830: '0@@',\n",
       "  831: 'TYPE_@@',\n",
       "  832: 'store',\n",
       "  833: 'ar@@',\n",
       "  834: 'before',\n",
       "  835: 'key@@',\n",
       "  836: 'Function',\n",
       "  837: 'does',\n",
       "  838: 'update@@',\n",
       "  839: 'player',\n",
       "  840: 'We',\n",
       "  841: 'Width',\n",
       "  842: 'Start',\n",
       "  843: '.py\">',\n",
       "  844: 'Block',\n",
       "  845: 'headers',\n",
       "  846: 'Object@@',\n",
       "  847: 'an@@',\n",
       "  848: 'last@@',\n",
       "  849: 'Create',\n",
       "  850: 'Pos',\n",
       "  851: 'Code',\n",
       "  852: 'S_@@',\n",
       "  853: 'Format',\n",
       "  854: 'Command',\n",
       "  855: 'en@@',\n",
       "  856: 'able@@',\n",
       "  857: 'add_@@',\n",
       "  858: 'failed',\n",
       "  859: 'String@@',\n",
       "  860: 'exists',\n",
       "  861: '\"@@',\n",
       "  862: 'system',\n",
       "  863: 'NAME',\n",
       "  864: 'tmp',\n",
       "  865: 'Token',\n",
       "  866: 'Method',\n",
       "  867: 'start@@',\n",
       "  868: 'Image',\n",
       "  869: 'c_@@',\n",
       "  870: 'published',\n",
       "  871: 'static_cast',\n",
       "  872: 'stack',\n",
       "  873: '.@@',\n",
       "  874: 'useful',\n",
       "  875: 'timeout',\n",
       "  876: 'conf',\n",
       "  877: 'Configuration',\n",
       "  878: 'Util',\n",
       "  879: 'Map@@',\n",
       "  880: 'domain',\n",
       "  881: 'data@@',\n",
       "  882: 'User@@',\n",
       "  883: '32@@',\n",
       "  884: 'load',\n",
       "  885: 'here',\n",
       "  886: 'Thread',\n",
       "  887: 'addr',\n",
       "  888: 'Z',\n",
       "  889: 'Qt',\n",
       "  890: 'endl',\n",
       "  891: 'Cache',\n",
       "  892: 'WARRANTY',\n",
       "  893: 'top',\n",
       "  894: 'Ref',\n",
       "  895: 'es',\n",
       "  896: 'process',\n",
       "  897: 'non',\n",
       "  898: 'Address',\n",
       "  899: 'bar',\n",
       "  900: 'than',\n",
       "  901: 'password',\n",
       "  902: 'provided',\n",
       "  903: 'returns',\n",
       "  904: 'Listener',\n",
       "  905: 'lib',\n",
       "  906: '_t',\n",
       "  907: 'G',\n",
       "  908: 'Rect',\n",
       "  909: 'later',\n",
       "  910: 'Settings',\n",
       "  911: 'Position',\n",
       "  912: 'conditions',\n",
       "  913: 'min@@',\n",
       "  914: 'ch@@',\n",
       "  915: 'where',\n",
       "  916: 'Frame',\n",
       "  917: 'var',\n",
       "  918: 'ifdef',\n",
       "  919: 'Return',\n",
       "  920: 'out@@',\n",
       "  921: 'end@@',\n",
       "  922: 'connect',\n",
       "  923: 'returned',\n",
       "  924: 'called',\n",
       "  925: 'python',\n",
       "  926: 'hpp',\n",
       "  927: 'Timer',\n",
       "  928: 'example',\n",
       "  929: 'Button',\n",
       "  930: 'cr',\n",
       "  931: 'changed',\n",
       "  932: 'It',\n",
       "  933: 'make',\n",
       "  934: 'nullptr',\n",
       "  935: 'available',\n",
       "  936: 'se@@',\n",
       "  937: 'instanceof',\n",
       "  938: 'insert',\n",
       "  939: 'iter',\n",
       "  940: 'errors',\n",
       "  941: 'No@@',\n",
       "  942: 'some',\n",
       "  943: 'NOT',\n",
       "  944: 'Iterator',\n",
       "  945: 'parameter',\n",
       "  946: 'along',\n",
       "  947: 'co@@',\n",
       "  948: 'additional',\n",
       "  949: 'assertThat',\n",
       "  950: 'internal',\n",
       "  951: '15',\n",
       "  952: 'st',\n",
       "  953: '_p@@',\n",
       "  954: 'log@@',\n",
       "  955: 'W',\n",
       "  956: '\\\\@@',\n",
       "  957: 'Window',\n",
       "  958: 'Add',\n",
       "  959: 'ch',\n",
       "  960: 'intellij',\n",
       "  961: 'lock',\n",
       "  962: 'H',\n",
       "  963: '16@@',\n",
       "  964: 'been',\n",
       "  965: 'uid',\n",
       "  966: 'Image@@',\n",
       "  967: 'Property',\n",
       "  968: 'Vector',\n",
       "  969: 'Line',\n",
       "  970: 'al',\n",
       "  971: 'implements',\n",
       "  972: 'ASF',\n",
       "  973: 'redistribute',\n",
       "  974: 'Item@@',\n",
       "  975: 'println',\n",
       "  976: 'valid',\n",
       "  977: 'Default@@',\n",
       "  978: 'parse',\n",
       "  979: 'flag',\n",
       "  980: 'Name@@',\n",
       "  981: 'O',\n",
       "  982: 'assert@@',\n",
       "  983: 'Field@@',\n",
       "  984: 'datetime',\n",
       "  985: 'sp@@',\n",
       "  986: '1.@@',\n",
       "  987: 'replace',\n",
       "  988: 'window',\n",
       "  989: 'db@@',\n",
       "  990: 'configuration',\n",
       "  991: 'support',\n",
       "  992: 'LOG',\n",
       "  993: 'properties',\n",
       "  994: 'Query',\n",
       "  995: 'Message@@',\n",
       "  996: 'Stream',\n",
       "  997: 'No',\n",
       "  998: 'attr',\n",
       "  999: 'operator',\n",
       "  ...},\n",
       " 'dico_word2id': {'<s>': 0,\n",
       "  '</s>': 1,\n",
       "  '<pad>': 2,\n",
       "  '<unk>': 3,\n",
       "  '<special0>': 4,\n",
       "  '<special1>': 5,\n",
       "  '<special2>': 6,\n",
       "  '<special3>': 7,\n",
       "  '<special4>': 8,\n",
       "  '<special5>': 9,\n",
       "  '<special6>': 10,\n",
       "  '<special7>': 11,\n",
       "  '<special8>': 12,\n",
       "  '<special9>': 13,\n",
       "  '': 14,\n",
       "  ')': 15,\n",
       "  '(': 16,\n",
       "  '.': 17,\n",
       "  ',': 18,\n",
       "  ';': 19,\n",
       "  '=': 20,\n",
       "  '*': 21,\n",
       "  '-': 22,\n",
       "  '\"': 23,\n",
       "  'NEW_LINE': 24,\n",
       "  \"'\": 25,\n",
       "  'STRNEWLINE': 26,\n",
       "  ':': 27,\n",
       "  '}': 28,\n",
       "  '{': 29,\n",
       "  'ENDCOM': 30,\n",
       "  'the': 31,\n",
       "  '#': 32,\n",
       "  '//': 33,\n",
       "  ']': 34,\n",
       "  '[': 35,\n",
       "  '_': 36,\n",
       "  'if': 37,\n",
       "  'self': 38,\n",
       "  '>': 39,\n",
       "  'INDENT': 40,\n",
       "  'DEDENT': 41,\n",
       "  '<': 42,\n",
       "  'return': 43,\n",
       "  '0': 44,\n",
       "  '/': 45,\n",
       "  '::': 46,\n",
       "  '->': 47,\n",
       "  '1': 48,\n",
       "  '+': 49,\n",
       "  'to': 50,\n",
       "  'a': 51,\n",
       "  '@': 52,\n",
       "  'import': 53,\n",
       "  'for': 54,\n",
       "  'of': 55,\n",
       "  'in': 56,\n",
       "  'i': 57,\n",
       "  'int': 58,\n",
       "  'is': 59,\n",
       "  'this': 60,\n",
       "  'public': 61,\n",
       "  '==': 62,\n",
       "  '%': 63,\n",
       "  '&': 64,\n",
       "  'void': 65,\n",
       "  'new': 66,\n",
       "  '2': 67,\n",
       "  '/*': 68,\n",
       "  '*/': 69,\n",
       "  'and': 70,\n",
       "  'def': 71,\n",
       "  's': 72,\n",
       "  'String': 73,\n",
       "  'name': 74,\n",
       "  'const': 75,\n",
       "  '_@@': 76,\n",
       "  'TABSYMBOL': 77,\n",
       "  'not': 78,\n",
       "  'or': 79,\n",
       "  'else': 80,\n",
       "  'org': 81,\n",
       "  'License': 82,\n",
       "  '!': 83,\n",
       "  '\"\"\"': 84,\n",
       "  'class': 85,\n",
       "  'value': 86,\n",
       "  'get@@': 87,\n",
       "  'from': 88,\n",
       "  'null': 89,\n",
       "  'file': 90,\n",
       "  'x': 91,\n",
       "  'data': 92,\n",
       "  '3': 93,\n",
       "  'be': 94,\n",
       "  'with': 95,\n",
       "  'm_@@': 96,\n",
       "  'static': 97,\n",
       "  '!=': 98,\n",
       "  'final': 99,\n",
       "  'type': 100,\n",
       "  'it': 101,\n",
       "  'false': 102,\n",
       "  'None': 103,\n",
       "  '`': 104,\n",
       "  'include': 105,\n",
       "  'true': 106,\n",
       "  'case': 107,\n",
       "  'private': 108,\n",
       "  '\\\\n': 109,\n",
       "  'h': 110,\n",
       "  'that': 111,\n",
       "  'id': 112,\n",
       "  'get': 113,\n",
       "  'p': 114,\n",
       "  'size': 115,\n",
       "  'c': 116,\n",
       "  't': 117,\n",
       "  '<<': 118,\n",
       "  'set@@': 119,\n",
       "  'code': 120,\n",
       "  'e': 121,\n",
       "  'The': 122,\n",
       "  '++': 123,\n",
       "  'as': 124,\n",
       "  'd': 125,\n",
       "  'by': 126,\n",
       "  '4': 127,\n",
       "  'com': 128,\n",
       "  'm@@': 129,\n",
       "  'path': 130,\n",
       "  '?': 131,\n",
       "  '&&': 132,\n",
       "  'result': 133,\n",
       "  'on': 134,\n",
       "  'p@@': 135,\n",
       "  'an': 136,\n",
       "  'string': 137,\n",
       "  'param': 138,\n",
       "  'under': 139,\n",
       "  'b': 140,\n",
       "  'list': 141,\n",
       "  'y': 142,\n",
       "  's@@': 143,\n",
       "  'key': 144,\n",
       "  'java': 145,\n",
       "  'A': 146,\n",
       "  '|': 147,\n",
       "  'break': 148,\n",
       "  'Type': 149,\n",
       "  'std': 150,\n",
       "  'r': 151,\n",
       "  'True': 152,\n",
       "  'char': 153,\n",
       "  'f': 154,\n",
       "  'List': 155,\n",
       "  'f@@': 156,\n",
       "  'This': 157,\n",
       "  'is@@': 158,\n",
       "  '/@@': 159,\n",
       "  'at': 160,\n",
       "  'bool': 161,\n",
       "  'set': 162,\n",
       "  'Get@@': 163,\n",
       "  '</DOCUMENT>': 164,\n",
       "  '+=': 165,\n",
       "  'index': 166,\n",
       "  'test': 167,\n",
       "  'n': 168,\n",
       "  'are': 169,\n",
       "  'Exception': 170,\n",
       "  '\\\\': 171,\n",
       "  'Override': 172,\n",
       "  'apache': 173,\n",
       "  'context': 174,\n",
       "  'we': 175,\n",
       "  'n@@': 176,\n",
       "  'version': 177,\n",
       "  'Name': 178,\n",
       "  'throws': 179,\n",
       "  'append': 180,\n",
       "  '5': 181,\n",
       "  'NULL': 182,\n",
       "  'length': 183,\n",
       "  'http': 184,\n",
       "  'm': 185,\n",
       "  'object': 186,\n",
       "  'util': 187,\n",
       "  'u': 188,\n",
       "  'try': 189,\n",
       "  'use': 190,\n",
       "  'node': 191,\n",
       "  'you': 192,\n",
       "  'C@@': 193,\n",
       "  'str': 194,\n",
       "  '||': 195,\n",
       "  'Object': 196,\n",
       "  'distributed': 197,\n",
       "  'out': 198,\n",
       "  'will': 199,\n",
       "  'default': 200,\n",
       "  'Test': 201,\n",
       "  'add': 202,\n",
       "  'may': 203,\n",
       "  'args': 204,\n",
       "  'get_@@': 205,\n",
       "  'len': 206,\n",
       "  'False': 207,\n",
       "  'OR': 208,\n",
       "  'state': 209,\n",
       "  '8': 210,\n",
       "  'boolean': 211,\n",
       "  'error': 212,\n",
       "  'Id': 213,\n",
       "  'C': 214,\n",
       "  'can': 215,\n",
       "  'float': 216,\n",
       "  'end': 217,\n",
       "  'j': 218,\n",
       "  'copy': 219,\n",
       "  'v': 220,\n",
       "  'text': 221,\n",
       "  'all': 222,\n",
       "  'os': 223,\n",
       "  'Data': 224,\n",
       "  'test_@@': 225,\n",
       "  'i@@': 226,\n",
       "  'k@@': 227,\n",
       "  'user': 228,\n",
       "  'line': 229,\n",
       "  'If': 230,\n",
       "  'b@@': 231,\n",
       "  'request': 232,\n",
       "  'c@@': 233,\n",
       "  'info': 234,\n",
       "  'double': 235,\n",
       "  'd@@': 236,\n",
       "  'except': 237,\n",
       "  'OF': 238,\n",
       "  'time': 239,\n",
       "  'test@@': 240,\n",
       "  'See': 241,\n",
       "  'Value': 242,\n",
       "  'T': 243,\n",
       "  'ID': 244,\n",
       "  'count': 245,\n",
       "  'module': 246,\n",
       "  'Map': 247,\n",
       "  'Info': 248,\n",
       "  'should': 249,\n",
       "  'ANY': 250,\n",
       "  '2.0': 251,\n",
       "  'message': 252,\n",
       "  'have': 253,\n",
       "  '6': 254,\n",
       "  'v@@': 255,\n",
       "  'method': 256,\n",
       "  'File': 257,\n",
       "  'long': 258,\n",
       "  'k': 259,\n",
       "  '<DOCUMENT_ID=\"@@': 260,\n",
       "  'start': 261,\n",
       "  's_@@': 262,\n",
       "  'www': 263,\n",
       "  'status': 264,\n",
       "  '10': 265,\n",
       "  'Set@@': 266,\n",
       "  'assert': 267,\n",
       "  't@@': 268,\n",
       "  'Node': 269,\n",
       "  'item': 270,\n",
       "  'To@@': 271,\n",
       "  'package': 272,\n",
       "  'x@@': 273,\n",
       "  'assertEqual': 274,\n",
       "  'X': 275,\n",
       "  'GNU': 276,\n",
       "  'one': 277,\n",
       "  'values': 278,\n",
       "  'format': 279,\n",
       "  'unsigned': 280,\n",
       "  'Public': 281,\n",
       "  'Copyright': 282,\n",
       "  'model': 283,\n",
       "  'e@@': 284,\n",
       "  'g': 285,\n",
       "  'add@@': 286,\n",
       "  'software': 287,\n",
       "  'I@@': 288,\n",
       "  'a@@': 289,\n",
       "  'link': 290,\n",
       "  'url': 291,\n",
       "  'You': 292,\n",
       "  'fields': 293,\n",
       "  'Error': 294,\n",
       "  'source': 295,\n",
       "  'other': 296,\n",
       "  'config': 297,\n",
       "  '$': 298,\n",
       "  'new@@': 299,\n",
       "  'Set': 300,\n",
       "  'General': 301,\n",
       "  'any': 302,\n",
       "  'T@@': 303,\n",
       "  'while': 304,\n",
       "  'event': 305,\n",
       "  '-@@': 306,\n",
       "  '7': 307,\n",
       "  'no': 308,\n",
       "  'Size': 309,\n",
       "  'response': 310,\n",
       "  'db': 311,\n",
       "  'g@@': 312,\n",
       "  'r@@': 313,\n",
       "  'map': 314,\n",
       "  'required': 315,\n",
       "  'field': 316,\n",
       "  'write': 317,\n",
       "  'params': 318,\n",
       "  'o': 319,\n",
       "  'l': 320,\n",
       "  'licenses': 321,\n",
       "  'Context': 322,\n",
       "  'print': 323,\n",
       "  'client': 324,\n",
       "  'assertEquals': 325,\n",
       "  'S@@': 326,\n",
       "  'used': 327,\n",
       "  'Index': 328,\n",
       "  'output': 329,\n",
       "  'number': 330,\n",
       "  'obj': 331,\n",
       "  'State': 332,\n",
       "  'either': 333,\n",
       "  'Software': 334,\n",
       "  'h@@': 335,\n",
       "  'Version': 336,\n",
       "  'msg': 337,\n",
       "  'dict': 338,\n",
       "  'create@@': 339,\n",
       "  'Q@@': 340,\n",
       "  'throw': 341,\n",
       "  'instance': 342,\n",
       "  'array': 343,\n",
       "  'target': 344,\n",
       "  'P@@': 345,\n",
       "  'input': 346,\n",
       "  'but': 347,\n",
       "  'function': 348,\n",
       "  'w': 349,\n",
       "  '2@@': 350,\n",
       "  'D@@': 351,\n",
       "  'buffer': 352,\n",
       "  'ing': 353,\n",
       "  'which': 354,\n",
       "  'l@@': 355,\n",
       "  'endif': 356,\n",
       "  'first': 357,\n",
       "  'more': 358,\n",
       "  'L': 359,\n",
       "  'E@@': 360,\n",
       "  'byte': 361,\n",
       "  'only': 362,\n",
       "  'B@@': 363,\n",
       "  '~': 364,\n",
       "  'buf': 365,\n",
       "  'raise': 366,\n",
       "  'in@@': 367,\n",
       "  'WITHOUT': 368,\n",
       "  'Path': 369,\n",
       "  'Test@@': 370,\n",
       "  'Count': 371,\n",
       "  'super': 372,\n",
       "  'my@@': 373,\n",
       "  're@@': 374,\n",
       "  'create': 375,\n",
       "  'when': 376,\n",
       "  'z': 377,\n",
       "  'un@@': 378,\n",
       "  'G@@': 379,\n",
       "  'X@@': 380,\n",
       "  'log': 381,\n",
       "  'B': 382,\n",
       "  'pos': 383,\n",
       "  'implied': 384,\n",
       "  'j@@': 385,\n",
       "  'F@@': 386,\n",
       "  'I': 387,\n",
       "  'group': 388,\n",
       "  '__@@': 389,\n",
       "  'R@@': 390,\n",
       "  'protected': 391,\n",
       "  'M@@': 392,\n",
       "  'S': 393,\n",
       "  'w@@': 394,\n",
       "  'width': 395,\n",
       "  'io': 396,\n",
       "  'IS': 397,\n",
       "  'on@@': 398,\n",
       "  'Manager': 399,\n",
       "  'table': 400,\n",
       "  'res': 401,\n",
       "  '9': 402,\n",
       "  'options': 403,\n",
       "  'N@@': 404,\n",
       "  'Class': 405,\n",
       "  'so': 406,\n",
       "  'to@@': 407,\n",
       "  'V@@': 408,\n",
       "  'see': 409,\n",
       "  'parent': 410,\n",
       "  'LICENSE': 411,\n",
       "  'using': 412,\n",
       "  'must': 413,\n",
       "  'H@@': 414,\n",
       "  '>=': 415,\n",
       "  'np': 416,\n",
       "  'models': 417,\n",
       "  'core': 418,\n",
       "  'L@@': 419,\n",
       "  'A@@': 420,\n",
       "  'R': 421,\n",
       "  'In@@': 422,\n",
       "  'has': 423,\n",
       "  'u@@': 424,\n",
       "  'catch': 425,\n",
       "  'read': 426,\n",
       "  'next': 427,\n",
       "  'mode': 428,\n",
       "  'elif': 429,\n",
       "  'offset': 430,\n",
       "  'val': 431,\n",
       "  'extends': 432,\n",
       "  'specific': 433,\n",
       "  'o@@': 434,\n",
       "  'check': 435,\n",
       "  'y@@': 436,\n",
       "  'ing@@': 437,\n",
       "  'server': 438,\n",
       "  'Event': 439,\n",
       "  'entry': 440,\n",
       "  'IOException': 441,\n",
       "  'AS': 442,\n",
       "  '/tree/master/@@': 443,\n",
       "  'Apache': 444,\n",
       "  'base': 445,\n",
       "  'description': 446,\n",
       "  'max': 447,\n",
       "  'K@@': 448,\n",
       "  'q@@': 449,\n",
       "  'namespace': 450,\n",
       "  'current': 451,\n",
       "  'put': 452,\n",
       "  'WARRANTIES': 453,\n",
       "  'Foundation': 454,\n",
       "  'Key': 455,\n",
       "  're': 456,\n",
       "  '**': 457,\n",
       "  'do': 458,\n",
       "  'action': 459,\n",
       "  'block': 460,\n",
       "  'delete': 461,\n",
       "  'stream': 462,\n",
       "  'language': 463,\n",
       "  'filename': 464,\n",
       "  'Y': 465,\n",
       "  'without': 466,\n",
       "  'exception': 467,\n",
       "  '16': 468,\n",
       "  'element': 469,\n",
       "  'z@@': 470,\n",
       "  'Returns': 471,\n",
       "  'Is@@': 472,\n",
       "  'files': 473,\n",
       "  'is_@@': 474,\n",
       "  'sys': 475,\n",
       "  'P': 476,\n",
       "  'height': 477,\n",
       "  'View': 478,\n",
       "  'join': 479,\n",
       "  'Element': 480,\n",
       "  'content': 481,\n",
       "  'File@@': 482,\n",
       "  'J@@': 483,\n",
       "  'common': 484,\n",
       "  'address': 485,\n",
       "  'Item': 486,\n",
       "  'update': 487,\n",
       "  'api': 488,\n",
       "  'token': 489,\n",
       "  'W@@': 490,\n",
       "  'Integer': 491,\n",
       "  'command': 492,\n",
       "  'django': 493,\n",
       "  'Result': 494,\n",
       "  'option': 495,\n",
       "  'Service': 496,\n",
       "  'Text': 497,\n",
       "  'Data@@': 498,\n",
       "  'E': 499,\n",
       "  'range': 500,\n",
       "  'ret': 501,\n",
       "  'vector': 502,\n",
       "  'Time': 503,\n",
       "  '4@@': 504,\n",
       "  'wx@@': 505,\n",
       "  'equals': 506,\n",
       "  'run': 507,\n",
       "  'port': 508,\n",
       "  'QString': 509,\n",
       "  'sizeof': 510,\n",
       "  'Type@@': 511,\n",
       "  'D': 512,\n",
       "  'dir': 513,\n",
       "  'view': 514,\n",
       "  '__init__': 515,\n",
       "  'permissions': 516,\n",
       "  '<=': 517,\n",
       "  'row': 518,\n",
       "  'O@@': 519,\n",
       "  'close': 520,\n",
       "  'set_@@': 521,\n",
       "  'sub@@': 522,\n",
       "  'image': 523,\n",
       "  'toString': 524,\n",
       "  '32': 525,\n",
       "  'query': 526,\n",
       "  'template': 527,\n",
       "  'define': 528,\n",
       "  'System': 529,\n",
       "  'N': 530,\n",
       "  'terms': 531,\n",
       "  'continue': 532,\n",
       "  's/@@': 533,\n",
       "  'call': 534,\n",
       "  'match': 535,\n",
       "  'Builder': 536,\n",
       "  'Message': 537,\n",
       "  'foo': 538,\n",
       "  'begin': 539,\n",
       "  'given': 540,\n",
       "  'empty': 541,\n",
       "  'M': 542,\n",
       "  'U@@': 543,\n",
       "  'KIND': 544,\n",
       "  'tag': 545,\n",
       "  'writing': 546,\n",
       "  'objects': 547,\n",
       "  'program': 548,\n",
       "  '3@@': 549,\n",
       "  'main': 550,\n",
       "  'Request': 551,\n",
       "  'kwargs': 552,\n",
       "  'filter': 553,\n",
       "  '^': 554,\n",
       "  'names': 555,\n",
       "  'settings': 556,\n",
       "  'date': 557,\n",
       "  'information': 558,\n",
       "  'Free': 559,\n",
       "  'THE': 560,\n",
       "  'src': 561,\n",
       "  'de@@': 562,\n",
       "  'header': 563,\n",
       "  'free': 564,\n",
       "  '9@@': 565,\n",
       "  '.java\">': 566,\n",
       "  'google': 567,\n",
       "  'position': 568,\n",
       "  'root': 569,\n",
       "  '1@@': 570,\n",
       "  'expected': 571,\n",
       "  'property': 572,\n",
       "  'max@@': 573,\n",
       "  'bytes': 574,\n",
       "  'pass': 575,\n",
       "  'Entry': 576,\n",
       "  'cache': 577,\n",
       "  'On@@': 578,\n",
       "  'FOR': 579,\n",
       "  'obtain': 580,\n",
       "  'android': 581,\n",
       "  'All': 582,\n",
       "  'express': 583,\n",
       "  'num@@': 584,\n",
       "  'struct': 585,\n",
       "  'Licensed': 586,\n",
       "  'al@@': 587,\n",
       "  'Model': 588,\n",
       "  'compliance': 589,\n",
       "  'F': 590,\n",
       "  'Mode': 591,\n",
       "  'applicable': 592,\n",
       "  'found': 593,\n",
       "  'q': 594,\n",
       "  'For@@': 595,\n",
       "  'limitations': 596,\n",
       "  'flags': 597,\n",
       "  'Factory': 598,\n",
       "  '8@@': 599,\n",
       "  'switch': 600,\n",
       "  'governing': 601,\n",
       "  'id@@': 602,\n",
       "  'CONDITIONS': 603,\n",
       "  'parser': 604,\n",
       "  'BASIS': 605,\n",
       "  'Config': 606,\n",
       "  '7@@': 607,\n",
       "  '5@@': 608,\n",
       "  'open': 609,\n",
       "  'host': 610,\n",
       "  'up': 611,\n",
       "  'Unless': 612,\n",
       "  'law': 613,\n",
       "  '0x00': 614,\n",
       "  'doc': 615,\n",
       "  'arg': 616,\n",
       "  'color': 617,\n",
       "  'Array': 618,\n",
       "  'agreed': 619,\n",
       "  'level': 620,\n",
       "  'form': 621,\n",
       "  'boost': 622,\n",
       "  'Handler': 623,\n",
       "  'was': 624,\n",
       "  'auto': 625,\n",
       "  'Field': 626,\n",
       "  'p_@@': 627,\n",
       "  'assertTrue': 628,\n",
       "  'find': 629,\n",
       "  'able': 630,\n",
       "  'json': 631,\n",
       "  'order': 632,\n",
       "  '6@@': 633,\n",
       "  'er@@': 634,\n",
       "  'IN': 635,\n",
       "  'g_@@': 636,\n",
       "  'items': 637,\n",
       "  'its': 638,\n",
       "  'label': 639,\n",
       "  \"'''\": 640,\n",
       "  'size_t': 641,\n",
       "  'str@@': 642,\n",
       "  'left': 643,\n",
       "  'javax': 644,\n",
       "  'Status': 645,\n",
       "  'Buffer': 646,\n",
       "  'defined': 647,\n",
       "  'Base': 648,\n",
       "  'V': 649,\n",
       "  'details': 650,\n",
       "  'session': 651,\n",
       "  'd_@@': 652,\n",
       "  '100': 653,\n",
       "  'Action': 654,\n",
       "  'remove': 655,\n",
       "  'title': 656,\n",
       "  'With@@': 657,\n",
       "  'service': 658,\n",
       "  'body': 659,\n",
       "  'point': 660,\n",
       "  'connection': 661,\n",
       "  'into': 662,\n",
       "  'utils': 663,\n",
       "  'debug': 664,\n",
       "  'handler': 665,\n",
       "  'Y@@': 666,\n",
       "  '12': 667,\n",
       "  'frame': 668,\n",
       "  'env': 669,\n",
       "  'keys': 670,\n",
       "  'm_p@@': 671,\n",
       "  'xml': 672,\n",
       "  'Table': 673,\n",
       "  'work': 674,\n",
       "  'html': 675,\n",
       "  'project': 676,\n",
       "  'Length': 677,\n",
       "  '0x00@@': 678,\n",
       "  'me': 679,\n",
       "  'specified': 680,\n",
       "  'Ptr': 681,\n",
       "  'your': 682,\n",
       "  'then': 683,\n",
       "  'read@@': 684,\n",
       "  'cmd': 685,\n",
       "  'From@@': 686,\n",
       "  'second': 687,\n",
       "  'iterator': 688,\n",
       "  'List@@': 689,\n",
       "  'as@@': 690,\n",
       "  'license': 691,\n",
       "  'AND': 692,\n",
       "  'copyright': 693,\n",
       "  'types': 694,\n",
       "  'results': 695,\n",
       "  'has@@': 696,\n",
       "  'do@@': 697,\n",
       "  'Group': 698,\n",
       "  'Z@@': 699,\n",
       "  'Base@@': 700,\n",
       "  'new_@@': 701,\n",
       "  'shape': 702,\n",
       "  'Number': 703,\n",
       "  '1.0': 704,\n",
       "  'check@@': 705,\n",
       "  'modify': 706,\n",
       "  'Re@@': 707,\n",
       "  'author': 708,\n",
       "  't_@@': 709,\n",
       "  'Color': 710,\n",
       "  'right': 711,\n",
       "  'following': 712,\n",
       "  'style': 713,\n",
       "  'file@@': 714,\n",
       "  'ed': 715,\n",
       "  'build': 716,\n",
       "  'need': 717,\n",
       "  'tr': 718,\n",
       "  'split': 719,\n",
       "  'logger': 720,\n",
       "  'app': 721,\n",
       "  'Point': 722,\n",
       "  'Offset': 723,\n",
       "  '20': 724,\n",
       "  'location': 725,\n",
       "  'cls': 726,\n",
       "  'ArrayList': 727,\n",
       "  'ed@@': 728,\n",
       "  'net': 729,\n",
       "  'builder': 730,\n",
       "  'op': 731,\n",
       "  'current@@': 732,\n",
       "  'prefix': 733,\n",
       "  'handle': 734,\n",
       "  'Get': 735,\n",
       "  'Inc': 736,\n",
       "  'interface': 737,\n",
       "  'lang': 738,\n",
       "  'And@@': 739,\n",
       "  '.cpp\">': 740,\n",
       "  'child': 741,\n",
       "  'Key@@': 742,\n",
       "  '\\\\x@@': 743,\n",
       "  'ref': 744,\n",
       "  'min': 745,\n",
       "  'ui': 746,\n",
       "  'Add@@': 747,\n",
       "  'page': 748,\n",
       "  'contains': 749,\n",
       "  'idx': 750,\n",
       "  'part': 751,\n",
       "  'isinstance': 752,\n",
       "  '11': 753,\n",
       "  'Assert': 754,\n",
       "  'Un@@': 755,\n",
       "  '_id': 756,\n",
       "  'st@@': 757,\n",
       "  'URL': 758,\n",
       "  '_name': 759,\n",
       "  'clear': 760,\n",
       "  'last': 761,\n",
       "  'push_back': 762,\n",
       "  'Node@@': 763,\n",
       "  'same': 764,\n",
       "  'PURPOSE': 765,\n",
       "  'FITNESS': 766,\n",
       "  'Source': 767,\n",
       "  'ids': 768,\n",
       "  '0.0': 769,\n",
       "  '>>': 770,\n",
       "  'PARTICULAR': 771,\n",
       "  'MERCHANTABILITY': 772,\n",
       "  'thread': 773,\n",
       "  'Text@@': 774,\n",
       "  'even': 775,\n",
       "  'K': 776,\n",
       "  'device': 777,\n",
       "  'hash': 778,\n",
       "  'no@@': 779,\n",
       "  'library': 780,\n",
       "  'attribute': 781,\n",
       "  'each': 782,\n",
       "  'getName': 783,\n",
       "  'tree': 784,\n",
       "  'c_str': 785,\n",
       "  'uint32': 786,\n",
       "  'num': 787,\n",
       "  'column': 788,\n",
       "  'er': 789,\n",
       "  '_S@@': 790,\n",
       "  'Check': 791,\n",
       "  'after': 792,\n",
       "  'Impl': 793,\n",
       "  'now': 794,\n",
       "  'search': 795,\n",
       "  'parameters': 796,\n",
       "  'ts': 797,\n",
       "  'there': 798,\n",
       "  '64': 799,\n",
       "  'For': 800,\n",
       "  'Log': 801,\n",
       "  'func': 802,\n",
       "  'U': 803,\n",
       "  '1\"': 804,\n",
       "  'Utils': 805,\n",
       "  'Date': 806,\n",
       "  'Event@@': 807,\n",
       "  'Filter': 808,\n",
       "  'directory': 809,\n",
       "  'ctx': 810,\n",
       "  'ptr': 811,\n",
       "  'lines': 812,\n",
       "  'tests': 813,\n",
       "  'Create@@': 814,\n",
       "  'to_@@': 815,\n",
       "  'write@@': 816,\n",
       "  'Value@@': 817,\n",
       "  'In': 818,\n",
       "  'Sub@@': 819,\n",
       "  'mock': 820,\n",
       "  'received': 821,\n",
       "  'err': 822,\n",
       "  'Response': 823,\n",
       "  'nodes': 824,\n",
       "  'init': 825,\n",
       "  'Client': 826,\n",
       "  'task': 827,\n",
       "  'resource': 828,\n",
       "  'User': 829,\n",
       "  '0@@': 830,\n",
       "  'TYPE_@@': 831,\n",
       "  'store': 832,\n",
       "  'ar@@': 833,\n",
       "  'before': 834,\n",
       "  'key@@': 835,\n",
       "  'Function': 836,\n",
       "  'does': 837,\n",
       "  'update@@': 838,\n",
       "  'player': 839,\n",
       "  'We': 840,\n",
       "  'Width': 841,\n",
       "  'Start': 842,\n",
       "  '.py\">': 843,\n",
       "  'Block': 844,\n",
       "  'headers': 845,\n",
       "  'Object@@': 846,\n",
       "  'an@@': 847,\n",
       "  'last@@': 848,\n",
       "  'Create': 849,\n",
       "  'Pos': 850,\n",
       "  'Code': 851,\n",
       "  'S_@@': 852,\n",
       "  'Format': 853,\n",
       "  'Command': 854,\n",
       "  'en@@': 855,\n",
       "  'able@@': 856,\n",
       "  'add_@@': 857,\n",
       "  'failed': 858,\n",
       "  'String@@': 859,\n",
       "  'exists': 860,\n",
       "  '\"@@': 861,\n",
       "  'system': 862,\n",
       "  'NAME': 863,\n",
       "  'tmp': 864,\n",
       "  'Token': 865,\n",
       "  'Method': 866,\n",
       "  'start@@': 867,\n",
       "  'Image': 868,\n",
       "  'c_@@': 869,\n",
       "  'published': 870,\n",
       "  'static_cast': 871,\n",
       "  'stack': 872,\n",
       "  '.@@': 873,\n",
       "  'useful': 874,\n",
       "  'timeout': 875,\n",
       "  'conf': 876,\n",
       "  'Configuration': 877,\n",
       "  'Util': 878,\n",
       "  'Map@@': 879,\n",
       "  'domain': 880,\n",
       "  'data@@': 881,\n",
       "  'User@@': 882,\n",
       "  '32@@': 883,\n",
       "  'load': 884,\n",
       "  'here': 885,\n",
       "  'Thread': 886,\n",
       "  'addr': 887,\n",
       "  'Z': 888,\n",
       "  'Qt': 889,\n",
       "  'endl': 890,\n",
       "  'Cache': 891,\n",
       "  'WARRANTY': 892,\n",
       "  'top': 893,\n",
       "  'Ref': 894,\n",
       "  'es': 895,\n",
       "  'process': 896,\n",
       "  'non': 897,\n",
       "  'Address': 898,\n",
       "  'bar': 899,\n",
       "  'than': 900,\n",
       "  'password': 901,\n",
       "  'provided': 902,\n",
       "  'returns': 903,\n",
       "  'Listener': 904,\n",
       "  'lib': 905,\n",
       "  '_t': 906,\n",
       "  'G': 907,\n",
       "  'Rect': 908,\n",
       "  'later': 909,\n",
       "  'Settings': 910,\n",
       "  'Position': 911,\n",
       "  'conditions': 912,\n",
       "  'min@@': 913,\n",
       "  'ch@@': 914,\n",
       "  'where': 915,\n",
       "  'Frame': 916,\n",
       "  'var': 917,\n",
       "  'ifdef': 918,\n",
       "  'Return': 919,\n",
       "  'out@@': 920,\n",
       "  'end@@': 921,\n",
       "  'connect': 922,\n",
       "  'returned': 923,\n",
       "  'called': 924,\n",
       "  'python': 925,\n",
       "  'hpp': 926,\n",
       "  'Timer': 927,\n",
       "  'example': 928,\n",
       "  'Button': 929,\n",
       "  'cr': 930,\n",
       "  'changed': 931,\n",
       "  'It': 932,\n",
       "  'make': 933,\n",
       "  'nullptr': 934,\n",
       "  'available': 935,\n",
       "  'se@@': 936,\n",
       "  'instanceof': 937,\n",
       "  'insert': 938,\n",
       "  'iter': 939,\n",
       "  'errors': 940,\n",
       "  'No@@': 941,\n",
       "  'some': 942,\n",
       "  'NOT': 943,\n",
       "  'Iterator': 944,\n",
       "  'parameter': 945,\n",
       "  'along': 946,\n",
       "  'co@@': 947,\n",
       "  'additional': 948,\n",
       "  'assertThat': 949,\n",
       "  'internal': 950,\n",
       "  '15': 951,\n",
       "  'st': 952,\n",
       "  '_p@@': 953,\n",
       "  'log@@': 954,\n",
       "  'W': 955,\n",
       "  '\\\\@@': 956,\n",
       "  'Window': 957,\n",
       "  'Add': 958,\n",
       "  'ch': 959,\n",
       "  'intellij': 960,\n",
       "  'lock': 961,\n",
       "  'H': 962,\n",
       "  '16@@': 963,\n",
       "  'been': 964,\n",
       "  'uid': 965,\n",
       "  'Image@@': 966,\n",
       "  'Property': 967,\n",
       "  'Vector': 968,\n",
       "  'Line': 969,\n",
       "  'al': 970,\n",
       "  'implements': 971,\n",
       "  'ASF': 972,\n",
       "  'redistribute': 973,\n",
       "  'Item@@': 974,\n",
       "  'println': 975,\n",
       "  'valid': 976,\n",
       "  'Default@@': 977,\n",
       "  'parse': 978,\n",
       "  'flag': 979,\n",
       "  'Name@@': 980,\n",
       "  'O': 981,\n",
       "  'assert@@': 982,\n",
       "  'Field@@': 983,\n",
       "  'datetime': 984,\n",
       "  'sp@@': 985,\n",
       "  '1.@@': 986,\n",
       "  'replace': 987,\n",
       "  'window': 988,\n",
       "  'db@@': 989,\n",
       "  'configuration': 990,\n",
       "  'support': 991,\n",
       "  'LOG': 992,\n",
       "  'properties': 993,\n",
       "  'Query': 994,\n",
       "  'Message@@': 995,\n",
       "  'Stream': 996,\n",
       "  'No': 997,\n",
       "  'attr': 998,\n",
       "  'operator': 999,\n",
       "  ...},\n",
       " 'dico_counts': {'<s>': 0,\n",
       "  '</s>': 0,\n",
       "  '<pad>': 0,\n",
       "  '<unk>': 0,\n",
       "  '<special0>': 0,\n",
       "  '<special1>': 0,\n",
       "  '<special2>': 0,\n",
       "  '<special3>': 0,\n",
       "  '<special4>': 0,\n",
       "  '<special5>': 0,\n",
       "  '<special6>': 0,\n",
       "  '<special7>': 0,\n",
       "  '<special8>': 0,\n",
       "  '<special9>': 0,\n",
       "  '': 2028961000,\n",
       "  ')': 559657537,\n",
       "  '(': 559382251,\n",
       "  '.': 521649764,\n",
       "  ',': 395622738,\n",
       "  ';': 307651765,\n",
       "  '=': 256222605,\n",
       "  '*': 229983419,\n",
       "  '-': 221843305,\n",
       "  '\"': 206400990,\n",
       "  'NEW_LINE': 175748366,\n",
       "  \"'\": 157159513,\n",
       "  'STRNEWLINE': 149368137,\n",
       "  ':': 135629080,\n",
       "  '}': 116947975,\n",
       "  '{': 116810164,\n",
       "  'ENDCOM': 80746634,\n",
       "  'the': 79452398,\n",
       "  '#': 75510188,\n",
       "  '//': 74220193,\n",
       "  ']': 71124489,\n",
       "  '[': 70958352,\n",
       "  '_': 70117171,\n",
       "  'if': 66912341,\n",
       "  'self': 59446868,\n",
       "  '>': 52565077,\n",
       "  'INDENT': 51290590,\n",
       "  'DEDENT': 51274779,\n",
       "  '<': 50801249,\n",
       "  'return': 49681894,\n",
       "  '0': 49153155,\n",
       "  '/': 47549649,\n",
       "  '::': 45455406,\n",
       "  '->': 44758057,\n",
       "  '1': 38066228,\n",
       "  '+': 31932119,\n",
       "  'to': 31240578,\n",
       "  'a': 30285793,\n",
       "  '@': 29441673,\n",
       "  'import': 29428965,\n",
       "  'for': 29118256,\n",
       "  'of': 27432710,\n",
       "  'in': 27186373,\n",
       "  'i': 25446317,\n",
       "  'int': 25155495,\n",
       "  'is': 25080629,\n",
       "  'this': 24807028,\n",
       "  'public': 24508667,\n",
       "  '==': 21861303,\n",
       "  '%': 21293406,\n",
       "  '&': 21014192,\n",
       "  'void': 20213326,\n",
       "  'new': 20032504,\n",
       "  '2': 19562560,\n",
       "  '/*': 19144922,\n",
       "  '*/': 19115063,\n",
       "  'and': 18888891,\n",
       "  'def': 18419569,\n",
       "  's': 18338369,\n",
       "  'String': 18189293,\n",
       "  'name': 16111668,\n",
       "  'const': 16040229,\n",
       "  '_@@': 15996970,\n",
       "  'TABSYMBOL': 15745123,\n",
       "  'not': 14860042,\n",
       "  'or': 14665173,\n",
       "  'else': 14310513,\n",
       "  'org': 14060487,\n",
       "  'License': 14053481,\n",
       "  '!': 13424668,\n",
       "  '\"\"\"': 13362480,\n",
       "  'class': 12996021,\n",
       "  'value': 12658991,\n",
       "  'get@@': 11824244,\n",
       "  'from': 11255666,\n",
       "  'null': 11099423,\n",
       "  'file': 11045919,\n",
       "  'x': 11015922,\n",
       "  'data': 10776273,\n",
       "  '3': 10736507,\n",
       "  'be': 10582297,\n",
       "  'with': 10486468,\n",
       "  'm_@@': 10464793,\n",
       "  'static': 10420315,\n",
       "  '!=': 10419803,\n",
       "  'final': 10098922,\n",
       "  'type': 10030350,\n",
       "  'it': 9934553,\n",
       "  'false': 9550190,\n",
       "  'None': 9539105,\n",
       "  '`': 9331167,\n",
       "  'include': 9240456,\n",
       "  'true': 9212173,\n",
       "  'case': 9099466,\n",
       "  'private': 9085852,\n",
       "  '\\\\n': 8920829,\n",
       "  'h': 8902368,\n",
       "  'that': 8808753,\n",
       "  'id': 8789455,\n",
       "  'get': 8458054,\n",
       "  'p': 8210602,\n",
       "  'size': 8137409,\n",
       "  'c': 8029387,\n",
       "  't': 8009201,\n",
       "  '<<': 8000352,\n",
       "  'set@@': 7816490,\n",
       "  'code': 7778810,\n",
       "  'e': 7638584,\n",
       "  'The': 7611022,\n",
       "  '++': 7603516,\n",
       "  'as': 7535011,\n",
       "  'd': 7517252,\n",
       "  'by': 7359023,\n",
       "  '4': 7328579,\n",
       "  'com': 7299782,\n",
       "  'm@@': 7299612,\n",
       "  'path': 7215245,\n",
       "  '?': 7158679,\n",
       "  '&&': 7145484,\n",
       "  'result': 7132606,\n",
       "  'on': 7017504,\n",
       "  'p@@': 7008296,\n",
       "  'an': 6841120,\n",
       "  'string': 6747298,\n",
       "  'param': 6536912,\n",
       "  'under': 6536813,\n",
       "  'b': 6524281,\n",
       "  'list': 6436288,\n",
       "  'y': 6425189,\n",
       "  's@@': 6399160,\n",
       "  'key': 6394454,\n",
       "  'java': 6368137,\n",
       "  'A': 6258015,\n",
       "  '|': 6168628,\n",
       "  'break': 6122941,\n",
       "  'Type': 6104041,\n",
       "  'std': 6051990,\n",
       "  'r': 5996150,\n",
       "  'True': 5995708,\n",
       "  'char': 5928621,\n",
       "  'f': 5908354,\n",
       "  'List': 5851897,\n",
       "  'f@@': 5805304,\n",
       "  'This': 5755602,\n",
       "  'is@@': 5701785,\n",
       "  '/@@': 5638592,\n",
       "  'at': 5552496,\n",
       "  'bool': 5535769,\n",
       "  'set': 5491531,\n",
       "  'Get@@': 5423427,\n",
       "  '</DOCUMENT>': 5368946,\n",
       "  '+=': 5238017,\n",
       "  'index': 5203812,\n",
       "  'test': 5180094,\n",
       "  'n': 5167081,\n",
       "  'are': 5160995,\n",
       "  'Exception': 5134338,\n",
       "  '\\\\': 5106045,\n",
       "  'Override': 5093155,\n",
       "  'apache': 5076054,\n",
       "  'context': 5008980,\n",
       "  'we': 4941298,\n",
       "  'n@@': 4930930,\n",
       "  'version': 4928792,\n",
       "  'Name': 4785309,\n",
       "  'throws': 4774769,\n",
       "  'append': 4756331,\n",
       "  '5': 4755472,\n",
       "  'NULL': 4722747,\n",
       "  'length': 4678756,\n",
       "  'http': 4659509,\n",
       "  'm': 4613140,\n",
       "  'object': 4570306,\n",
       "  'util': 4569807,\n",
       "  'u': 4509930,\n",
       "  'try': 4506835,\n",
       "  'use': 4487242,\n",
       "  'node': 4463257,\n",
       "  'you': 4434231,\n",
       "  'C@@': 4419676,\n",
       "  'str': 4417208,\n",
       "  '||': 4415018,\n",
       "  'Object': 4407611,\n",
       "  'distributed': 4407119,\n",
       "  'out': 4352422,\n",
       "  'will': 4349780,\n",
       "  'default': 4346949,\n",
       "  'Test': 4327340,\n",
       "  'add': 4327197,\n",
       "  'may': 4310403,\n",
       "  'args': 4307380,\n",
       "  'get_@@': 4267116,\n",
       "  'len': 4262382,\n",
       "  'False': 4234020,\n",
       "  'OR': 4220489,\n",
       "  'state': 4182454,\n",
       "  '8': 4149552,\n",
       "  'boolean': 4147974,\n",
       "  'error': 4119385,\n",
       "  'Id': 4114330,\n",
       "  'C': 4113050,\n",
       "  'can': 4106726,\n",
       "  'float': 4102028,\n",
       "  'end': 4092944,\n",
       "  'j': 4089304,\n",
       "  'copy': 4070000,\n",
       "  'v': 3984003,\n",
       "  'text': 3983528,\n",
       "  'all': 3945276,\n",
       "  'os': 3895357,\n",
       "  'Data': 3835794,\n",
       "  'test_@@': 3819001,\n",
       "  'i@@': 3807270,\n",
       "  'k@@': 3784492,\n",
       "  'user': 3779234,\n",
       "  'line': 3772876,\n",
       "  'If': 3767323,\n",
       "  'b@@': 3754089,\n",
       "  'request': 3714417,\n",
       "  'c@@': 3709832,\n",
       "  'info': 3705958,\n",
       "  'double': 3658267,\n",
       "  'd@@': 3641484,\n",
       "  'except': 3624965,\n",
       "  'OF': 3611905,\n",
       "  'time': 3598087,\n",
       "  'test@@': 3589982,\n",
       "  'See': 3571081,\n",
       "  'Value': 3538048,\n",
       "  'T': 3509366,\n",
       "  'ID': 3499815,\n",
       "  'count': 3494005,\n",
       "  'module': 3448137,\n",
       "  'Map': 3443762,\n",
       "  'Info': 3426050,\n",
       "  'should': 3399456,\n",
       "  'ANY': 3395121,\n",
       "  '2.0': 3389170,\n",
       "  'message': 3383911,\n",
       "  'have': 3376627,\n",
       "  '6': 3324271,\n",
       "  'v@@': 3313622,\n",
       "  'method': 3301018,\n",
       "  'File': 3253992,\n",
       "  'long': 3248184,\n",
       "  'k': 3230777,\n",
       "  '<DOCUMENT_ID=\"@@': 3214211,\n",
       "  'start': 3204392,\n",
       "  's_@@': 3175856,\n",
       "  'www': 3167519,\n",
       "  'status': 3157137,\n",
       "  '10': 3155114,\n",
       "  'Set@@': 3139566,\n",
       "  'assert': 3138218,\n",
       "  't@@': 3137410,\n",
       "  'Node': 3131399,\n",
       "  'item': 3121509,\n",
       "  'To@@': 3114199,\n",
       "  'package': 3097549,\n",
       "  'x@@': 3080335,\n",
       "  'assertEqual': 3076699,\n",
       "  'X': 3034518,\n",
       "  'GNU': 3018278,\n",
       "  'one': 3011312,\n",
       "  'values': 3006536,\n",
       "  'format': 3001096,\n",
       "  'unsigned': 2995439,\n",
       "  'Public': 2995160,\n",
       "  'Copyright': 2980149,\n",
       "  'model': 2978792,\n",
       "  'e@@': 2959608,\n",
       "  'g': 2958182,\n",
       "  'add@@': 2949308,\n",
       "  'software': 2949268,\n",
       "  'I@@': 2945812,\n",
       "  'a@@': 2939687,\n",
       "  'link': 2938618,\n",
       "  'url': 2888174,\n",
       "  'You': 2886686,\n",
       "  'fields': 2882504,\n",
       "  'Error': 2874827,\n",
       "  'source': 2864254,\n",
       "  'other': 2855907,\n",
       "  'config': 2839493,\n",
       "  '$': 2838921,\n",
       "  'new@@': 2831850,\n",
       "  'Set': 2831741,\n",
       "  'General': 2827538,\n",
       "  'any': 2810157,\n",
       "  'T@@': 2794043,\n",
       "  'while': 2792740,\n",
       "  'event': 2790880,\n",
       "  '-@@': 2786597,\n",
       "  '7': 2781750,\n",
       "  'no': 2772521,\n",
       "  'Size': 2764189,\n",
       "  'response': 2763604,\n",
       "  'db': 2751590,\n",
       "  'g@@': 2750985,\n",
       "  'r@@': 2750506,\n",
       "  'map': 2743805,\n",
       "  'required': 2740331,\n",
       "  'field': 2731565,\n",
       "  'write': 2726463,\n",
       "  'params': 2715473,\n",
       "  'o': 2710663,\n",
       "  'l': 2691185,\n",
       "  'licenses': 2672293,\n",
       "  'Context': 2664271,\n",
       "  'print': 2658356,\n",
       "  'client': 2656763,\n",
       "  'assertEquals': 2648189,\n",
       "  'S@@': 2647031,\n",
       "  'used': 2644528,\n",
       "  'Index': 2633784,\n",
       "  'output': 2628608,\n",
       "  'number': 2615999,\n",
       "  'obj': 2606452,\n",
       "  'State': 2598794,\n",
       "  'either': 2591003,\n",
       "  'Software': 2585739,\n",
       "  'h@@': 2569621,\n",
       "  'Version': 2567238,\n",
       "  'msg': 2566876,\n",
       "  'dict': 2562694,\n",
       "  'create@@': 2561490,\n",
       "  'Q@@': 2546266,\n",
       "  'throw': 2540742,\n",
       "  'instance': 2537862,\n",
       "  'array': 2529282,\n",
       "  'target': 2527005,\n",
       "  'P@@': 2525699,\n",
       "  'input': 2524818,\n",
       "  'but': 2519689,\n",
       "  'function': 2517055,\n",
       "  'w': 2517031,\n",
       "  '2@@': 2516983,\n",
       "  'D@@': 2511407,\n",
       "  'buffer': 2495118,\n",
       "  'ing': 2475566,\n",
       "  'which': 2472281,\n",
       "  'l@@': 2466755,\n",
       "  'endif': 2462673,\n",
       "  'first': 2458521,\n",
       "  'more': 2457358,\n",
       "  'L': 2451878,\n",
       "  'E@@': 2447880,\n",
       "  'byte': 2444094,\n",
       "  'only': 2433712,\n",
       "  'B@@': 2431549,\n",
       "  '~': 2429087,\n",
       "  'buf': 2424639,\n",
       "  'raise': 2420175,\n",
       "  'in@@': 2415714,\n",
       "  'WITHOUT': 2411054,\n",
       "  'Path': 2407071,\n",
       "  'Test@@': 2405906,\n",
       "  'Count': 2405153,\n",
       "  'super': 2384005,\n",
       "  'my@@': 2380861,\n",
       "  're@@': 2369559,\n",
       "  'create': 2368103,\n",
       "  'when': 2367284,\n",
       "  'z': 2364390,\n",
       "  'un@@': 2363281,\n",
       "  'G@@': 2360728,\n",
       "  'X@@': 2360503,\n",
       "  'log': 2338286,\n",
       "  'B': 2328801,\n",
       "  'pos': 2327813,\n",
       "  'implied': 2327011,\n",
       "  'j@@': 2326211,\n",
       "  'F@@': 2311899,\n",
       "  'I': 2300835,\n",
       "  'group': 2285398,\n",
       "  '__@@': 2285037,\n",
       "  'R@@': 2283239,\n",
       "  'protected': 2275403,\n",
       "  'M@@': 2272449,\n",
       "  'S': 2268728,\n",
       "  'w@@': 2252614,\n",
       "  'width': 2250573,\n",
       "  'io': 2249531,\n",
       "  'IS': 2242765,\n",
       "  'on@@': 2234199,\n",
       "  'Manager': 2209436,\n",
       "  'table': 2194739,\n",
       "  'res': 2192378,\n",
       "  '9': 2191702,\n",
       "  'options': 2191636,\n",
       "  'N@@': 2185663,\n",
       "  'Class': 2184158,\n",
       "  'so': 2181175,\n",
       "  'to@@': 2180965,\n",
       "  'V@@': 2173343,\n",
       "  'see': 2154442,\n",
       "  'parent': 2151829,\n",
       "  'LICENSE': 2149548,\n",
       "  'using': 2136559,\n",
       "  'must': 2133560,\n",
       "  'H@@': 2132279,\n",
       "  '>=': 2132056,\n",
       "  'np': 2118403,\n",
       "  'models': 2114209,\n",
       "  'core': 2101506,\n",
       "  'L@@': 2091169,\n",
       "  'A@@': 2090839,\n",
       "  'R': 2088888,\n",
       "  'In@@': 2087375,\n",
       "  'has': 2082959,\n",
       "  'u@@': 2079827,\n",
       "  'catch': 2073434,\n",
       "  'read': 2063787,\n",
       "  'next': 2056026,\n",
       "  'mode': 2046546,\n",
       "  'elif': 2040435,\n",
       "  'offset': 2034806,\n",
       "  'val': 2032554,\n",
       "  'extends': 2031726,\n",
       "  'specific': 2030162,\n",
       "  'o@@': 2028836,\n",
       "  'check': 2024943,\n",
       "  'y@@': 2023453,\n",
       "  'ing@@': 2022046,\n",
       "  'server': 2017073,\n",
       "  'Event': 2007602,\n",
       "  'entry': 2005216,\n",
       "  'IOException': 1997766,\n",
       "  'AS': 1994570,\n",
       "  '/tree/master/@@': 1992151,\n",
       "  'Apache': 1989258,\n",
       "  'base': 1985473,\n",
       "  'description': 1981574,\n",
       "  'max': 1977472,\n",
       "  'K@@': 1974891,\n",
       "  'q@@': 1971883,\n",
       "  'namespace': 1961471,\n",
       "  'current': 1960025,\n",
       "  'put': 1953402,\n",
       "  'WARRANTIES': 1952256,\n",
       "  'Foundation': 1939324,\n",
       "  'Key': 1935175,\n",
       "  're': 1925406,\n",
       "  '**': 1906953,\n",
       "  'do': 1897988,\n",
       "  'action': 1897179,\n",
       "  'block': 1891850,\n",
       "  'delete': 1891423,\n",
       "  'stream': 1889841,\n",
       "  'language': 1889813,\n",
       "  'filename': 1889579,\n",
       "  'Y': 1888217,\n",
       "  'without': 1870333,\n",
       "  'exception': 1866750,\n",
       "  '16': 1859418,\n",
       "  'element': 1846521,\n",
       "  'z@@': 1842095,\n",
       "  'Returns': 1826421,\n",
       "  'Is@@': 1824832,\n",
       "  'files': 1819503,\n",
       "  'is_@@': 1817230,\n",
       "  'sys': 1814148,\n",
       "  'P': 1810986,\n",
       "  'height': 1807983,\n",
       "  'View': 1805913,\n",
       "  'join': 1805625,\n",
       "  'Element': 1802012,\n",
       "  'content': 1800998,\n",
       "  'File@@': 1799440,\n",
       "  'J@@': 1795926,\n",
       "  'common': 1794761,\n",
       "  'address': 1794221,\n",
       "  'Item': 1791880,\n",
       "  'update': 1775558,\n",
       "  'api': 1770682,\n",
       "  'token': 1769542,\n",
       "  'W@@': 1768921,\n",
       "  'Integer': 1758011,\n",
       "  'command': 1751763,\n",
       "  'django': 1751491,\n",
       "  'Result': 1744305,\n",
       "  'option': 1738153,\n",
       "  'Service': 1735995,\n",
       "  'Text': 1726714,\n",
       "  'Data@@': 1723228,\n",
       "  'E': 1723139,\n",
       "  'range': 1721676,\n",
       "  'ret': 1721040,\n",
       "  'vector': 1713305,\n",
       "  'Time': 1711469,\n",
       "  '4@@': 1706686,\n",
       "  'wx@@': 1701196,\n",
       "  'equals': 1698590,\n",
       "  'run': 1697438,\n",
       "  'port': 1695218,\n",
       "  'QString': 1692709,\n",
       "  'sizeof': 1686670,\n",
       "  'Type@@': 1684125,\n",
       "  'D': 1681432,\n",
       "  'dir': 1681061,\n",
       "  'view': 1677332,\n",
       "  '__init__': 1675263,\n",
       "  'permissions': 1670749,\n",
       "  '<=': 1669223,\n",
       "  'row': 1668187,\n",
       "  'O@@': 1664568,\n",
       "  'close': 1662180,\n",
       "  'set_@@': 1661477,\n",
       "  'sub@@': 1656191,\n",
       "  'image': 1655804,\n",
       "  'toString': 1652392,\n",
       "  '32': 1652157,\n",
       "  'query': 1651531,\n",
       "  'template': 1650760,\n",
       "  'define': 1648703,\n",
       "  'System': 1647753,\n",
       "  'N': 1640795,\n",
       "  'terms': 1634498,\n",
       "  'continue': 1632290,\n",
       "  's/@@': 1624295,\n",
       "  'call': 1623830,\n",
       "  'match': 1623740,\n",
       "  'Builder': 1620675,\n",
       "  'Message': 1617149,\n",
       "  'foo': 1615908,\n",
       "  'begin': 1611100,\n",
       "  'given': 1608804,\n",
       "  'empty': 1608364,\n",
       "  'M': 1602114,\n",
       "  'U@@': 1590606,\n",
       "  'KIND': 1588772,\n",
       "  'tag': 1582688,\n",
       "  'writing': 1577323,\n",
       "  'objects': 1575176,\n",
       "  'program': 1571312,\n",
       "  '3@@': 1568779,\n",
       "  'main': 1566189,\n",
       "  'Request': 1563599,\n",
       "  'kwargs': 1563538,\n",
       "  'filter': 1563357,\n",
       "  '^': 1561923,\n",
       "  'names': 1559214,\n",
       "  'settings': 1556045,\n",
       "  'date': 1554511,\n",
       "  'information': 1550692,\n",
       "  'Free': 1547252,\n",
       "  'THE': 1544520,\n",
       "  'src': 1536195,\n",
       "  'de@@': 1533975,\n",
       "  'header': 1528739,\n",
       "  'free': 1528302,\n",
       "  '9@@': 1526791,\n",
       "  '.java\">': 1524983,\n",
       "  'google': 1524911,\n",
       "  'position': 1524384,\n",
       "  'root': 1521801,\n",
       "  '1@@': 1520975,\n",
       "  'expected': 1519124,\n",
       "  'property': 1514733,\n",
       "  'max@@': 1513828,\n",
       "  'bytes': 1513118,\n",
       "  'pass': 1512169,\n",
       "  'Entry': 1510923,\n",
       "  'cache': 1508317,\n",
       "  'On@@': 1507986,\n",
       "  'FOR': 1503948,\n",
       "  'obtain': 1503170,\n",
       "  'android': 1502890,\n",
       "  'All': 1497374,\n",
       "  'express': 1497248,\n",
       "  'num@@': 1494531,\n",
       "  'struct': 1483510,\n",
       "  'Licensed': 1481704,\n",
       "  'al@@': 1481534,\n",
       "  'Model': 1478009,\n",
       "  'compliance': 1468537,\n",
       "  'F': 1466692,\n",
       "  'Mode': 1466537,\n",
       "  'applicable': 1466095,\n",
       "  'found': 1463935,\n",
       "  'q': 1462509,\n",
       "  'For@@': 1460976,\n",
       "  'limitations': 1460056,\n",
       "  'flags': 1458107,\n",
       "  'Factory': 1456874,\n",
       "  '8@@': 1455483,\n",
       "  'switch': 1454363,\n",
       "  'governing': 1452785,\n",
       "  'id@@': 1451777,\n",
       "  'CONDITIONS': 1450681,\n",
       "  'parser': 1449953,\n",
       "  'BASIS': 1446761,\n",
       "  'Config': 1440095,\n",
       "  '7@@': 1427262,\n",
       "  '5@@': 1426599,\n",
       "  'open': 1426436,\n",
       "  'host': 1426211,\n",
       "  'up': 1425404,\n",
       "  'Unless': 1419759,\n",
       "  'law': 1418321,\n",
       "  '0x00': 1417966,\n",
       "  'doc': 1413832,\n",
       "  'arg': 1412905,\n",
       "  'color': 1411731,\n",
       "  'Array': 1409149,\n",
       "  'agreed': 1405948,\n",
       "  'level': 1401926,\n",
       "  'form': 1400096,\n",
       "  'boost': 1396547,\n",
       "  'Handler': 1393758,\n",
       "  'was': 1392638,\n",
       "  'auto': 1390561,\n",
       "  'Field': 1390094,\n",
       "  'p_@@': 1383694,\n",
       "  'assertTrue': 1382241,\n",
       "  'find': 1381969,\n",
       "  'able': 1381697,\n",
       "  'json': 1380637,\n",
       "  'order': 1379092,\n",
       "  '6@@': 1377767,\n",
       "  'er@@': 1376032,\n",
       "  'IN': 1363853,\n",
       "  'g_@@': 1362282,\n",
       "  'items': 1361543,\n",
       "  'its': 1357119,\n",
       "  'label': 1357087,\n",
       "  \"'''\": 1355361,\n",
       "  'size_t': 1354341,\n",
       "  'str@@': 1352637,\n",
       "  'left': 1352526,\n",
       "  'javax': 1350241,\n",
       "  'Status': 1346422,\n",
       "  'Buffer': 1342952,\n",
       "  'defined': 1342112,\n",
       "  'Base': 1340791,\n",
       "  'V': 1340076,\n",
       "  'details': 1339122,\n",
       "  'session': 1338758,\n",
       "  'd_@@': 1336206,\n",
       "  '100': 1333986,\n",
       "  'Action': 1333645,\n",
       "  'remove': 1332432,\n",
       "  'title': 1330742,\n",
       "  'With@@': 1327336,\n",
       "  'service': 1327273,\n",
       "  'body': 1327125,\n",
       "  'point': 1326850,\n",
       "  'connection': 1325910,\n",
       "  'into': 1325737,\n",
       "  'utils': 1324010,\n",
       "  'debug': 1323485,\n",
       "  'handler': 1322048,\n",
       "  'Y@@': 1320743,\n",
       "  '12': 1313396,\n",
       "  'frame': 1311011,\n",
       "  'env': 1310360,\n",
       "  'keys': 1308022,\n",
       "  'm_p@@': 1307959,\n",
       "  'xml': 1306993,\n",
       "  'Table': 1301852,\n",
       "  'work': 1300947,\n",
       "  'html': 1298556,\n",
       "  'project': 1298299,\n",
       "  'Length': 1295219,\n",
       "  '0x00@@': 1293976,\n",
       "  'me': 1289835,\n",
       "  'specified': 1289827,\n",
       "  'Ptr': 1289100,\n",
       "  'your': 1287034,\n",
       "  'then': 1284252,\n",
       "  'read@@': 1279684,\n",
       "  'cmd': 1278556,\n",
       "  'From@@': 1277724,\n",
       "  'second': 1275446,\n",
       "  'iterator': 1275396,\n",
       "  'List@@': 1272590,\n",
       "  'as@@': 1272082,\n",
       "  'license': 1268249,\n",
       "  'AND': 1267306,\n",
       "  'copyright': 1264398,\n",
       "  'types': 1260902,\n",
       "  'results': 1247686,\n",
       "  'has@@': 1247444,\n",
       "  'do@@': 1241688,\n",
       "  'Group': 1239100,\n",
       "  'Z@@': 1237324,\n",
       "  'Base@@': 1233727,\n",
       "  'new_@@': 1233156,\n",
       "  'shape': 1233086,\n",
       "  'Number': 1232445,\n",
       "  '1.0': 1231324,\n",
       "  'check@@': 1230090,\n",
       "  'modify': 1227510,\n",
       "  'Re@@': 1225582,\n",
       "  'author': 1224920,\n",
       "  't_@@': 1224155,\n",
       "  'Color': 1222604,\n",
       "  'right': 1221872,\n",
       "  'following': 1220580,\n",
       "  'style': 1219094,\n",
       "  'file@@': 1214986,\n",
       "  'ed': 1212512,\n",
       "  'build': 1211743,\n",
       "  'need': 1209558,\n",
       "  'tr': 1208675,\n",
       "  'split': 1207254,\n",
       "  'logger': 1204385,\n",
       "  'app': 1204068,\n",
       "  'Point': 1202558,\n",
       "  'Offset': 1202143,\n",
       "  '20': 1202032,\n",
       "  'location': 1201719,\n",
       "  'cls': 1201601,\n",
       "  'ArrayList': 1201250,\n",
       "  'ed@@': 1200241,\n",
       "  'net': 1199895,\n",
       "  'builder': 1193641,\n",
       "  'op': 1193485,\n",
       "  'current@@': 1192404,\n",
       "  'prefix': 1191183,\n",
       "  'handle': 1188026,\n",
       "  'Get': 1187707,\n",
       "  'Inc': 1187211,\n",
       "  'interface': 1186905,\n",
       "  'lang': 1183525,\n",
       "  'And@@': 1182922,\n",
       "  '.cpp\">': 1182052,\n",
       "  'child': 1180552,\n",
       "  'Key@@': 1179021,\n",
       "  '\\\\x@@': 1175506,\n",
       "  'ref': 1174183,\n",
       "  'min': 1172584,\n",
       "  'ui': 1172514,\n",
       "  'Add@@': 1172146,\n",
       "  'page': 1172087,\n",
       "  'contains': 1169622,\n",
       "  'idx': 1166063,\n",
       "  'part': 1165224,\n",
       "  'isinstance': 1164001,\n",
       "  '11': 1163781,\n",
       "  'Assert': 1162908,\n",
       "  'Un@@': 1162414,\n",
       "  '_id': 1161713,\n",
       "  'st@@': 1157849,\n",
       "  'URL': 1157478,\n",
       "  '_name': 1154545,\n",
       "  'clear': 1152848,\n",
       "  'last': 1152454,\n",
       "  'push_back': 1151026,\n",
       "  'Node@@': 1147064,\n",
       "  'same': 1146447,\n",
       "  'PURPOSE': 1146080,\n",
       "  'FITNESS': 1144969,\n",
       "  'Source': 1143636,\n",
       "  'ids': 1142505,\n",
       "  '0.0': 1141393,\n",
       "  '>>': 1139954,\n",
       "  'PARTICULAR': 1139160,\n",
       "  'MERCHANTABILITY': 1137674,\n",
       "  'thread': 1136659,\n",
       "  'Text@@': 1135752,\n",
       "  'even': 1134690,\n",
       "  'K': 1133743,\n",
       "  'device': 1129938,\n",
       "  'hash': 1124389,\n",
       "  'no@@': 1124221,\n",
       "  'library': 1122865,\n",
       "  'attribute': 1122837,\n",
       "  'each': 1121762,\n",
       "  'getName': 1120426,\n",
       "  'tree': 1120344,\n",
       "  'c_str': 1118226,\n",
       "  'uint32': 1116749,\n",
       "  'num': 1116390,\n",
       "  'column': 1106342,\n",
       "  'er': 1101815,\n",
       "  '_S@@': 1101751,\n",
       "  'Check': 1100604,\n",
       "  'after': 1100377,\n",
       "  'Impl': 1098871,\n",
       "  'now': 1097707,\n",
       "  'search': 1097151,\n",
       "  'parameters': 1095243,\n",
       "  'ts': 1095203,\n",
       "  'there': 1094148,\n",
       "  '64': 1093959,\n",
       "  'For': 1092765,\n",
       "  'Log': 1092620,\n",
       "  'func': 1090924,\n",
       "  'U': 1088429,\n",
       "  '1\"': 1087657,\n",
       "  'Utils': 1085853,\n",
       "  'Date': 1082137,\n",
       "  'Event@@': 1081561,\n",
       "  'Filter': 1081151,\n",
       "  'directory': 1079282,\n",
       "  'ctx': 1079118,\n",
       "  'ptr': 1077295,\n",
       "  'lines': 1075885,\n",
       "  'tests': 1075631,\n",
       "  'Create@@': 1071295,\n",
       "  'to_@@': 1071129,\n",
       "  'write@@': 1070822,\n",
       "  'Value@@': 1069317,\n",
       "  'In': 1068937,\n",
       "  'Sub@@': 1067053,\n",
       "  'mock': 1065975,\n",
       "  'received': 1065033,\n",
       "  'err': 1062865,\n",
       "  'Response': 1058260,\n",
       "  'nodes': 1055223,\n",
       "  'init': 1054437,\n",
       "  'Client': 1050358,\n",
       "  'task': 1049371,\n",
       "  'resource': 1048615,\n",
       "  'User': 1048134,\n",
       "  '0@@': 1047623,\n",
       "  'TYPE_@@': 1045728,\n",
       "  'store': 1044084,\n",
       "  'ar@@': 1043596,\n",
       "  'before': 1042906,\n",
       "  'key@@': 1042583,\n",
       "  'Function': 1042396,\n",
       "  'does': 1042262,\n",
       "  'update@@': 1040534,\n",
       "  'player': 1039744,\n",
       "  'We': 1036666,\n",
       "  'Width': 1034037,\n",
       "  'Start': 1033719,\n",
       "  '.py\">': 1032422,\n",
       "  'Block': 1029928,\n",
       "  'headers': 1029588,\n",
       "  'Object@@': 1028976,\n",
       "  'an@@': 1028021,\n",
       "  'last@@': 1025819,\n",
       "  'Create': 1024450,\n",
       "  'Pos': 1024363,\n",
       "  'Code': 1023962,\n",
       "  'S_@@': 1022063,\n",
       "  'Format': 1021733,\n",
       "  'Command': 1018670,\n",
       "  'en@@': 1018469,\n",
       "  'able@@': 1015551,\n",
       "  'add_@@': 1014718,\n",
       "  'failed': 1009394,\n",
       "  'String@@': 1008080,\n",
       "  'exists': 1006572,\n",
       "  '\"@@': 1002569,\n",
       "  'system': 1002060,\n",
       "  'NAME': 1001336,\n",
       "  'tmp': 1001147,\n",
       "  'Token': 999103,\n",
       "  'Method': 998526,\n",
       "  'start@@': 998418,\n",
       "  'Image': 998212,\n",
       "  'c_@@': 997920,\n",
       "  'published': 996957,\n",
       "  'static_cast': 996674,\n",
       "  'stack': 995670,\n",
       "  '.@@': 995320,\n",
       "  'useful': 992797,\n",
       "  'timeout': 992358,\n",
       "  'conf': 991548,\n",
       "  'Configuration': 989347,\n",
       "  'Util': 988188,\n",
       "  'Map@@': 987467,\n",
       "  'domain': 987430,\n",
       "  'data@@': 986857,\n",
       "  'User@@': 986795,\n",
       "  '32@@': 986257,\n",
       "  'load': 986074,\n",
       "  'here': 986026,\n",
       "  'Thread': 985954,\n",
       "  'addr': 985924,\n",
       "  'Z': 984327,\n",
       "  'Qt': 982528,\n",
       "  'endl': 982077,\n",
       "  'Cache': 981285,\n",
       "  'WARRANTY': 979716,\n",
       "  'top': 974259,\n",
       "  'Ref': 973281,\n",
       "  'es': 972492,\n",
       "  'process': 971127,\n",
       "  'non': 971002,\n",
       "  'Address': 969257,\n",
       "  'bar': 967105,\n",
       "  'than': 965015,\n",
       "  'password': 964004,\n",
       "  'provided': 963649,\n",
       "  'returns': 962532,\n",
       "  'Listener': 962471,\n",
       "  'lib': 961342,\n",
       "  '_t': 959587,\n",
       "  'G': 959491,\n",
       "  'Rect': 958137,\n",
       "  'later': 958058,\n",
       "  'Settings': 957442,\n",
       "  'Position': 956914,\n",
       "  'conditions': 956436,\n",
       "  'min@@': 953496,\n",
       "  'ch@@': 950520,\n",
       "  'where': 949945,\n",
       "  'Frame': 949050,\n",
       "  'var': 947938,\n",
       "  'ifdef': 947378,\n",
       "  'Return': 946734,\n",
       "  'out@@': 946148,\n",
       "  'end@@': 945170,\n",
       "  'connect': 944927,\n",
       "  'returned': 944621,\n",
       "  'called': 942571,\n",
       "  'python': 942353,\n",
       "  'hpp': 940759,\n",
       "  'Timer': 940418,\n",
       "  'example': 936827,\n",
       "  'Button': 935872,\n",
       "  'cr': 934035,\n",
       "  'changed': 931459,\n",
       "  'It': 930723,\n",
       "  'make': 929437,\n",
       "  'nullptr': 929020,\n",
       "  'available': 926709,\n",
       "  'se@@': 925990,\n",
       "  'instanceof': 924359,\n",
       "  'insert': 922481,\n",
       "  'iter': 921518,\n",
       "  'errors': 919081,\n",
       "  'No@@': 918758,\n",
       "  'some': 917997,\n",
       "  'NOT': 917907,\n",
       "  'Iterator': 916978,\n",
       "  'parameter': 915504,\n",
       "  'along': 914670,\n",
       "  'co@@': 913782,\n",
       "  'additional': 913255,\n",
       "  'assertThat': 912949,\n",
       "  'internal': 912927,\n",
       "  '15': 912417,\n",
       "  'st': 911989,\n",
       "  '_p@@': 911596,\n",
       "  'log@@': 909431,\n",
       "  'W': 909395,\n",
       "  '\\\\@@': 908254,\n",
       "  'Window': 907548,\n",
       "  'Add': 906077,\n",
       "  'ch': 903409,\n",
       "  'intellij': 903211,\n",
       "  'lock': 902833,\n",
       "  'H': 901730,\n",
       "  '16@@': 901669,\n",
       "  'been': 901118,\n",
       "  'uid': 901016,\n",
       "  'Image@@': 900209,\n",
       "  'Property': 899912,\n",
       "  'Vector': 899275,\n",
       "  'Line': 899167,\n",
       "  'al': 899092,\n",
       "  'implements': 899082,\n",
       "  'ASF': 898672,\n",
       "  'redistribute': 897340,\n",
       "  'Item@@': 896156,\n",
       "  'println': 895974,\n",
       "  'valid': 895306,\n",
       "  'Default@@': 895229,\n",
       "  'parse': 893673,\n",
       "  'flag': 892636,\n",
       "  'Name@@': 892631,\n",
       "  'O': 891046,\n",
       "  'assert@@': 890242,\n",
       "  'Field@@': 889563,\n",
       "  'datetime': 888736,\n",
       "  'sp@@': 888517,\n",
       "  '1.@@': 887742,\n",
       "  'replace': 883594,\n",
       "  'window': 882888,\n",
       "  'db@@': 880161,\n",
       "  'configuration': 879968,\n",
       "  'support': 878328,\n",
       "  'LOG': 878267,\n",
       "  'properties': 878230,\n",
       "  'Query': 877685,\n",
       "  'Message@@': 877208,\n",
       "  'Stream': 877152,\n",
       "  'No': 876403,\n",
       "  'attr': 875692,\n",
       "  'operator': 874914,\n",
       "  ...},\n",
       " 'params': {'dump_path': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283',\n",
       "  'exp_name': 'bt_with_comments_sa_final_modif_test',\n",
       "  'save_periodic': 1,\n",
       "  'exp_id': '26703283',\n",
       "  'fp16': True,\n",
       "  'amp': 2,\n",
       "  'encoder_only': False,\n",
       "  'emb_dim': 1024,\n",
       "  'emb_dim_encoder': 1024,\n",
       "  'emb_dim_decoder': 1024,\n",
       "  'n_layers': 6,\n",
       "  'n_layers_encoder': 6,\n",
       "  'n_layers_decoder': 6,\n",
       "  'n_heads': 8,\n",
       "  'dropout': 0.1,\n",
       "  'attention_dropout': 0.0,\n",
       "  'gelu_activation': False,\n",
       "  'share_inout_emb': True,\n",
       "  'sinusoidal_embeddings': False,\n",
       "  'use_lang_emb': True,\n",
       "  'context_size': 0,\n",
       "  'word_pred': 0.15,\n",
       "  'sample_alpha': 0.0,\n",
       "  'word_mask_keep_rand': '0.8,0.1,0.1',\n",
       "  'word_shuffle': 3.0,\n",
       "  'word_dropout': 0.1,\n",
       "  'word_blank': 0.1,\n",
       "  'data_path': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test',\n",
       "  'lgs': 'cpp_sa-java_sa-python_sa',\n",
       "  'max_vocab': -1,\n",
       "  'min_count': 0,\n",
       "  'lg_sampling_factor': -1.0,\n",
       "  'has_sentences_ids': True,\n",
       "  'bptt': 256,\n",
       "  'max_len': 512,\n",
       "  'group_by_size': True,\n",
       "  'batch_size': 32,\n",
       "  'max_batch_size': 128,\n",
       "  'tokens_per_batch': 6000,\n",
       "  'gen_tpb_multiplier': 1,\n",
       "  'split_data': False,\n",
       "  'split_data_accross_gpu': 'global',\n",
       "  'optimizer': 'adam_inverse_sqrt,warmup_updates=10000,lr=0.0001,weight_decay=0.01',\n",
       "  'clip_grad_norm': 5.0,\n",
       "  'epoch_size': 30000,\n",
       "  'max_epoch': 10000000,\n",
       "  'stopping_criterion': '',\n",
       "  'validation_metrics': '',\n",
       "  'accumulate_gradients': 1,\n",
       "  'lambda_mlm': 1.0,\n",
       "  'lambda_clm': 1.0,\n",
       "  'lambda_ae': 0.970705,\n",
       "  'lambda_mt': 1.0,\n",
       "  'lambda_bt': 1.0,\n",
       "  'clm_steps': [],\n",
       "  'mlm_steps': [],\n",
       "  'mt_steps': [],\n",
       "  'ae_steps': ['cpp_sa', 'python_sa', 'java_sa'],\n",
       "  'bt_steps': [('python_sa', 'cpp_sa', 'python_sa'),\n",
       "   ('cpp_sa', 'python_sa', 'cpp_sa'),\n",
       "   ('java_sa', 'cpp_sa', 'java_sa'),\n",
       "   ('cpp_sa', 'java_sa', 'cpp_sa'),\n",
       "   ('python_sa', 'java_sa', 'python_sa'),\n",
       "   ('java_sa', 'python_sa', 'java_sa')],\n",
       "  'reload_emb': '',\n",
       "  'reload_model': '/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth,/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth',\n",
       "  'reload_checkpoint': '',\n",
       "  'beam_size': 1,\n",
       "  'length_penalty': 1.0,\n",
       "  'early_stopping': False,\n",
       "  'number_samples': 1,\n",
       "  'eval_temperature': None,\n",
       "  'bt_sample_temperature': 0.0,\n",
       "  'eval_bleu': True,\n",
       "  'eval_bleu_test_only': False,\n",
       "  'eval_computation': True,\n",
       "  'generate_hypothesis': True,\n",
       "  'eval_only': False,\n",
       "  'retry_mistmatching_types': False,\n",
       "  'debug_train': False,\n",
       "  'debug_slurm': False,\n",
       "  'debug': False,\n",
       "  'local_rank': 0,\n",
       "  'master_port': 14083,\n",
       "  'separate_decoders': False,\n",
       "  'n_share_dec': 0,\n",
       "  'langs': ['cpp_sa', 'java_sa', 'python_sa'],\n",
       "  'id2lang': {0: 'cpp_sa', 1: 'java_sa', 2: 'python_sa'},\n",
       "  'lang2id': {'cpp_sa': 0, 'java_sa': 1, 'python_sa': 2},\n",
       "  'n_langs': 3,\n",
       "  'bt_src_langs': ['python_sa',\n",
       "   'cpp_sa',\n",
       "   'java_sa',\n",
       "   'cpp_sa',\n",
       "   'python_sa',\n",
       "   'java_sa'],\n",
       "  'mono_dataset': {'cpp_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.cpp_sa.pth',\n",
       "    'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa.pth',\n",
       "    'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa.pth'},\n",
       "   'java_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.java_sa.pth',\n",
       "    'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa.pth',\n",
       "    'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa.pth'},\n",
       "   'python_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.python_sa.pth',\n",
       "    'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.python_sa.pth',\n",
       "    'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.python_sa.pth'}},\n",
       "  'para_dataset': {('cpp_sa',\n",
       "    'java_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-java_sa.cpp_sa.pth',\n",
       "     '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-java_sa.java_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-java_sa.cpp_sa.pth',\n",
       "     '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-java_sa.java_sa.pth')},\n",
       "   ('cpp_sa',\n",
       "    'python_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-python_sa.cpp_sa.pth',\n",
       "     '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-python_sa.python_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-python_sa.cpp_sa.pth',\n",
       "     '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-python_sa.python_sa.pth')},\n",
       "   ('java_sa',\n",
       "    'python_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa-python_sa.java_sa.pth',\n",
       "     '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa-python_sa.python_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa-python_sa.java_sa.pth',\n",
       "     '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa-python_sa.python_sa.pth')}},\n",
       "  'word_mask': 0.8,\n",
       "  'word_keep': 0.1,\n",
       "  'word_rand': 0.1,\n",
       "  'is_slurm_job': True,\n",
       "  'n_nodes': 4,\n",
       "  'node_id': 0,\n",
       "  'global_rank': 0,\n",
       "  'world_size': 32,\n",
       "  'n_gpu_per_node': 8,\n",
       "  'master_addr': 'learnfair1506',\n",
       "  'is_master': True,\n",
       "  'multi_node': True,\n",
       "  'multi_gpu': True,\n",
       "  'command': 'python /private/home/malachaux/workdir/bt_with_comments_sa_final_modif_test/2020_05_22_06_57_35/XLM/train.py --n_heads 8 --bt_steps \\'python_sa-cpp_sa-python_sa,cpp_sa-python_sa-cpp_sa,java_sa-cpp_sa-java_sa,cpp_sa-java_sa-cpp_sa,python_sa-java_sa-python_sa,java_sa-python_sa-java_sa\\' --max_vocab \\'-1\\' --word_mask_keep_rand \\'0.8,0.1,0.1\\' --gen_tpb_multiplier 1 --word_blank \\'0.1\\' --n_layers 6 --save_periodic 1 --dump_path \\'/checkpoint/malachaux/dumped/\\' --max_len 512 --bptt 256 --lambda_clm 1 --ae_steps \\'cpp_sa,python_sa,java_sa\\' --fp16 true --share_inout_emb true --lambda_mlm 1 --sinusoidal_embeddings false --mlm_steps \\'\\' --word_shuffle 3 --tokens_per_batch 6000 --has_sentences_ids true --attention_dropout 0 --split_data false --length_penalty 1 --max_epoch 10000000 --stopping_criterion \\'\\' --lambda_bt 1 --generate_hypothesis true --lambda_mt 1 --epoch_size 30000 --data_path \\'/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test\\' --gelu_activation false --split_data_accross_gpu global --optimizer \\'adam_inverse_sqrt,warmup_updates=10000,lr=0.0001,weight_decay=0.01\\' --eval_computation true --validation_metrics \\'\\' --eval_bleu true --dropout \\'0.1\\' --mt_steps \\'\\' --reload_emb \\'\\' --batch_size 32 --context_size 0 --word_dropout \\'0.1\\' --reload_model \\'/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth,/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth\\' --min_count 0 --eval_bleu_test_only false --group_by_size true --early_stopping false --sample_alpha 0 --word_pred \\'0.15\\' --amp 2 --max_batch_size 128 --clip_grad_norm 5 --emb_dim 1024 --encoder_only false --lgs \\'cpp_sa-java_sa-python_sa\\' --clm_steps \\'\\' --exp_name bt_with_comments_sa_final_modif_test --beam_size 1 --lambda_ae \\'0:1,100000:0.1,300000:0\\' --lg_sampling_factor \\'-1\\' --eval_only false --exp_id 26703283 --master_port 14083 --exp_id \"26703283\"',\n",
       "  'n_words': 63961,\n",
       "  'bos_index': 0,\n",
       "  'eos_index': 1,\n",
       "  'pad_index': 2,\n",
       "  'unk_index': 3,\n",
       "  'mask_index': 5,\n",
       "  'sep_index': 147,\n",
       "  'pred_probs': tensor([0.8000, 0.1000, 0.1000]),\n",
       "  'mask_scores': array([0., 0., 0., ..., 1., 1., 1.]),\n",
       "  'lambda_clm_config': None,\n",
       "  'lambda_mlm_config': None,\n",
       "  'lambda_ae_config': [(0, 1.0), (100000, 0.1), (300000, 0.0)],\n",
       "  'lambda_mt_config': None,\n",
       "  'lambda_bt_config': None,\n",
       "  'bt_sample_temperature_config': None,\n",
       "  'hyp_path': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses',\n",
       "  'eval_scripts_root': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts',\n",
       "  'ref_paths': {('java_sa',\n",
       "    'cpp_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-cpp_sa.valid.txt',\n",
       "   ('cpp_sa',\n",
       "    'java_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-java_sa.valid.txt',\n",
       "   ('java_sa',\n",
       "    'cpp_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-cpp_sa.test.txt',\n",
       "   ('cpp_sa',\n",
       "    'java_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-java_sa.test.txt',\n",
       "   ('python_sa',\n",
       "    'cpp_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-cpp_sa.valid.txt',\n",
       "   ('cpp_sa',\n",
       "    'python_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-python_sa.valid.txt',\n",
       "   ('python_sa',\n",
       "    'cpp_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-cpp_sa.test.txt',\n",
       "   ('cpp_sa',\n",
       "    'python_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-python_sa.test.txt',\n",
       "   ('python_sa',\n",
       "    'java_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-java_sa.valid.txt',\n",
       "   ('java_sa',\n",
       "    'python_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-python_sa.valid.txt',\n",
       "   ('python_sa',\n",
       "    'java_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-java_sa.test.txt',\n",
       "   ('java_sa',\n",
       "    'python_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-python_sa.test.txt'},\n",
       "  'id_paths': {('cpp_sa',\n",
       "    'java_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.valid.txt',\n",
       "   ('java_sa',\n",
       "    'cpp_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.valid.txt',\n",
       "   ('cpp_sa',\n",
       "    'java_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.test.txt',\n",
       "   ('java_sa',\n",
       "    'cpp_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.test.txt',\n",
       "   ('cpp_sa',\n",
       "    'python_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.valid.txt',\n",
       "   ('python_sa',\n",
       "    'cpp_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.valid.txt',\n",
       "   ('cpp_sa',\n",
       "    'python_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.test.txt',\n",
       "   ('python_sa',\n",
       "    'cpp_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.test.txt',\n",
       "   ('java_sa',\n",
       "    'python_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.valid.txt',\n",
       "   ('python_sa',\n",
       "    'java_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.valid.txt',\n",
       "   ('java_sa',\n",
       "    'python_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.test.txt',\n",
       "   ('python_sa',\n",
       "    'java_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.test.txt'},\n",
       "  'eval_scripts_folders': {('cpp_sa',\n",
       "    'java_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-java_sa.valid',\n",
       "   ('java_sa',\n",
       "    'cpp_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-cpp_sa.valid',\n",
       "   ('cpp_sa',\n",
       "    'java_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-java_sa.test',\n",
       "   ('java_sa',\n",
       "    'cpp_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-cpp_sa.test',\n",
       "   ('cpp_sa',\n",
       "    'python_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-python_sa.valid',\n",
       "   ('python_sa',\n",
       "    'cpp_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-cpp_sa.valid',\n",
       "   ('cpp_sa',\n",
       "    'python_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-python_sa.test',\n",
       "   ('python_sa',\n",
       "    'cpp_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-cpp_sa.test',\n",
       "   ('java_sa',\n",
       "    'python_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-python_sa.valid',\n",
       "   ('python_sa',\n",
       "    'java_sa',\n",
       "    'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-java_sa.valid',\n",
       "   ('java_sa',\n",
       "    'python_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-python_sa.test',\n",
       "   ('python_sa',\n",
       "    'java_sa',\n",
       "    'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-java_sa.test'}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### splitting the model params\n",
    "\n",
    "model['encoder'] = {(k[len('module.'):] if k.startswith('module.') else k):v for k, v in model['encoder'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'decoder' in model:\n",
    "    decoders_names = ['decoder']\n",
    "else:\n",
    "    decoders_names = ['decoder_0','decoder_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for decoder_name in decoders_names:\n",
    "    model[decoder_name] = {(k[len('module.'):] if k.startswith('module.') else k):v for k, v in model[decoder_name].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'decoder' in model or ('decoder_0' in model and 'decoder_1' in model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position_embeddings.weight': tensor([[ 0.0169,  0.0241, -0.0060,  ...,  0.0101, -0.0061, -0.0215],\n",
       "         [-0.0008,  0.0224, -0.0236,  ..., -0.0059,  0.0085, -0.0200],\n",
       "         [ 0.0017,  0.0092, -0.0068,  ..., -0.0009, -0.0055, -0.0101],\n",
       "         ...,\n",
       "         [ 0.0151, -0.0050,  0.0265,  ..., -0.0256,  0.0176, -0.0139],\n",
       "         [ 0.0186, -0.0235, -0.0098,  ..., -0.0160,  0.0303,  0.0023],\n",
       "         [-0.0230,  0.0086,  0.0015,  ...,  0.0154, -0.0029,  0.0096]],\n",
       "        dtype=torch.float16),\n",
       " 'lang_embeddings.weight': tensor([[ 0.0026,  0.0028,  0.0092,  ..., -0.0212,  0.0106,  0.0093],\n",
       "         [ 0.0001, -0.0105,  0.0124,  ...,  0.0010,  0.0093,  0.0107],\n",
       "         [ 0.0053, -0.0068,  0.0115,  ...,  0.0285, -0.0015,  0.0062]],\n",
       "        dtype=torch.float16),\n",
       " 'embeddings.weight': tensor([[-0.0026,  0.0328, -0.0086,  ..., -0.0876,  0.0523,  0.0307],\n",
       "         [-0.0312, -0.0044,  0.0104,  ...,  0.0131, -0.0293,  0.0129],\n",
       "         [-0.0401,  0.0246,  0.0135,  ..., -0.0760, -0.0206, -0.0047],\n",
       "         ...,\n",
       "         [-0.0231, -0.0485, -0.0335,  ..., -0.0450,  0.0485,  0.0441],\n",
       "         [-0.0276,  0.0656,  0.0337,  ..., -0.0289,  0.0030, -0.0454],\n",
       "         [ 0.0289, -0.0684, -0.0053,  ..., -0.0873,  0.0255, -0.0303]],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm_emb.weight': tensor([0.5498, 0.5029, 0.5142,  ..., 0.3647, 0.4312, 0.5176],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm_emb.bias': tensor([-0.0169, -0.0587, -0.0549,  ..., -0.0388,  0.0223, -0.0176],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.q_lin.weight': tensor([[-0.0043, -0.0729,  0.0070,  ..., -0.0604,  0.0269,  0.0612],\n",
       "         [-0.1085,  0.0158, -0.0091,  ..., -0.0595, -0.0339, -0.0075],\n",
       "         [ 0.0622, -0.1025,  0.0161,  ...,  0.0095, -0.0420, -0.0350],\n",
       "         ...,\n",
       "         [-0.0133, -0.0447,  0.0023,  ..., -0.0583, -0.0375,  0.0749],\n",
       "         [ 0.0382,  0.0060, -0.0842,  ...,  0.0512, -0.0005,  0.0809],\n",
       "         [ 0.0687,  0.1794, -0.0467,  ..., -0.0248,  0.0008, -0.0285]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.q_lin.bias': tensor([-0.2025,  0.1639,  0.1984,  ...,  0.1594, -0.2856,  0.1133],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.k_lin.weight': tensor([[ 0.0479,  0.0311,  0.0366,  ..., -0.0161,  0.0282, -0.0157],\n",
       "         [-0.0728,  0.0075, -0.0539,  ...,  0.0124,  0.0340, -0.0237],\n",
       "         [-0.1002,  0.0902, -0.0173,  ..., -0.0428,  0.0588, -0.0083],\n",
       "         ...,\n",
       "         [ 0.0459,  0.0380,  0.0378,  ...,  0.0071,  0.0002, -0.0406],\n",
       "         [ 0.0086, -0.0291,  0.0411,  ..., -0.0108, -0.0641,  0.0215],\n",
       "         [ 0.0139,  0.0242,  0.0092,  ...,  0.0569, -0.0153, -0.0244]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.k_lin.bias': tensor([ 0.0202, -0.0085, -0.0071,  ..., -0.0100,  0.0629,  0.0086],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.v_lin.weight': tensor([[-0.0279, -0.0247, -0.0394,  ...,  0.0485, -0.0208,  0.0070],\n",
       "         [-0.0435,  0.0191,  0.0127,  ..., -0.0835, -0.0028, -0.0161],\n",
       "         [-0.0741,  0.0283, -0.0427,  ...,  0.0254,  0.0217, -0.0373],\n",
       "         ...,\n",
       "         [-0.0062,  0.0125,  0.0538,  ..., -0.0334,  0.0087, -0.0485],\n",
       "         [-0.0198, -0.0053, -0.0225,  ...,  0.0387, -0.0032, -0.0055],\n",
       "         [-0.0499,  0.0803, -0.0130,  ..., -0.0090, -0.0219,  0.0441]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.v_lin.bias': tensor([ 0.0024, -0.0310,  0.0071,  ..., -0.0263,  0.0051, -0.0223],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.out_lin.weight': tensor([[ 0.0004, -0.0238,  0.0440,  ..., -0.0275,  0.0071, -0.0008],\n",
       "         [ 0.0305, -0.0435, -0.0258,  ...,  0.0079,  0.0416, -0.0004],\n",
       "         [ 0.0330, -0.0141,  0.0393,  ...,  0.0448,  0.0118,  0.0019],\n",
       "         ...,\n",
       "         [ 0.0760,  0.0312, -0.0205,  ...,  0.0163, -0.0065, -0.0256],\n",
       "         [-0.0452, -0.0448, -0.0447,  ...,  0.0287, -0.0105,  0.0093],\n",
       "         [-0.0242,  0.0554, -0.0307,  ..., -0.0168, -0.0230,  0.0121]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.out_lin.bias': tensor([-0.0182,  0.0042,  0.0304,  ..., -0.0137,  0.0234, -0.0019],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.q_lin.weight': tensor([[ 0.0053,  0.0266, -0.0297,  ..., -0.0122,  0.0093, -0.0558],\n",
       "         [-0.0234, -0.0466, -0.0363,  ...,  0.0195,  0.0640,  0.0158],\n",
       "         [-0.0048, -0.0143,  0.0695,  ...,  0.0267, -0.0708, -0.0504],\n",
       "         ...,\n",
       "         [ 0.0177,  0.0451, -0.0178,  ...,  0.0773,  0.0126,  0.0102],\n",
       "         [ 0.0299,  0.0116, -0.0033,  ...,  0.0288, -0.0435, -0.0249],\n",
       "         [-0.0168, -0.0255,  0.0155,  ...,  0.0726, -0.0038,  0.0454]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.q_lin.bias': tensor([ 0.0563, -0.0114, -0.0822,  ...,  0.2834, -0.2988, -0.1582],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.k_lin.weight': tensor([[ 0.0173, -0.0038,  0.0294,  ...,  0.0548,  0.0297, -0.0260],\n",
       "         [-0.0654,  0.0186, -0.0394,  ..., -0.0403,  0.0367,  0.0309],\n",
       "         [-0.0057, -0.0308, -0.0003,  ..., -0.0290,  0.0091,  0.0198],\n",
       "         ...,\n",
       "         [ 0.0829,  0.0178,  0.0185,  ...,  0.0566, -0.0164, -0.0333],\n",
       "         [ 0.0131,  0.0528,  0.0478,  ..., -0.0007,  0.0010, -0.0765],\n",
       "         [-0.0593,  0.0420,  0.0434,  ...,  0.0012,  0.1042, -0.0172]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.k_lin.bias': tensor([ 0.0158,  0.0432,  0.0420,  ...,  0.0515, -0.1752, -0.0056],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.v_lin.weight': tensor([[-0.0126, -0.0242,  0.0257,  ...,  0.0390, -0.0143, -0.0688],\n",
       "         [-0.0300, -0.0135, -0.0692,  ..., -0.0046,  0.0271, -0.0214],\n",
       "         [-0.0389, -0.0229,  0.0114,  ..., -0.0298,  0.0132,  0.0150],\n",
       "         ...,\n",
       "         [ 0.0116,  0.0064,  0.0255,  ..., -0.0256, -0.0098,  0.0347],\n",
       "         [ 0.0101,  0.0155,  0.0202,  ...,  0.0410,  0.0107,  0.0211],\n",
       "         [ 0.0430,  0.0066, -0.0103,  ...,  0.0394,  0.0195, -0.0594]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.v_lin.bias': tensor([ 0.0071,  0.0188, -0.0065,  ..., -0.0233,  0.0008, -0.0129],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.out_lin.weight': tensor([[ 0.0181, -0.0060,  0.0070,  ...,  0.0130, -0.0222, -0.0111],\n",
       "         [ 0.0407, -0.0177,  0.0442,  ..., -0.0122,  0.0438, -0.0116],\n",
       "         [-0.0328,  0.0282,  0.0403,  ...,  0.0024,  0.0401, -0.0273],\n",
       "         ...,\n",
       "         [ 0.0662,  0.0037,  0.0857,  ...,  0.0352, -0.1829,  0.0194],\n",
       "         [-0.0499, -0.0127, -0.0430,  ..., -0.0016,  0.0779, -0.0214],\n",
       "         [ 0.0453, -0.0242,  0.0194,  ..., -0.0646,  0.0268, -0.0188]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.out_lin.bias': tensor([-0.0070,  0.0046,  0.0010,  ..., -0.0148,  0.0072, -0.0115],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.q_lin.weight': tensor([[ 0.0267,  0.0294, -0.0184,  ...,  0.0393, -0.0230, -0.0384],\n",
       "         [-0.0911, -0.0426, -0.0960,  ..., -0.0198, -0.0576,  0.0310],\n",
       "         [ 0.1108, -0.0692, -0.0945,  ..., -0.0174,  0.1122, -0.0460],\n",
       "         ...,\n",
       "         [ 0.0325,  0.0313, -0.0009,  ..., -0.0204, -0.1429,  0.0504],\n",
       "         [ 0.0334,  0.0920, -0.0553,  ...,  0.0224, -0.0040, -0.0745],\n",
       "         [ 0.0434, -0.0139,  0.0173,  ..., -0.0091, -0.0447, -0.0451]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.q_lin.bias': tensor([ 0.3914, -0.0019,  0.0880,  ..., -0.0479, -0.0942,  0.0611],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.k_lin.weight': tensor([[-7.2479e-03,  4.4220e-02,  3.0609e-02,  ...,  8.9844e-02,\n",
       "          -8.7830e-02, -6.7825e-03],\n",
       "         [-1.8143e-02,  3.5370e-02, -1.4549e-02,  ..., -1.7969e-01,\n",
       "          -6.8703e-03, -3.8239e-02],\n",
       "         [-5.1514e-02,  9.4116e-02,  3.6316e-02,  ..., -5.8014e-02,\n",
       "          -4.4159e-02, -1.3153e-02],\n",
       "         ...,\n",
       "         [-3.1412e-05, -8.8379e-02,  5.0873e-02,  ..., -4.3762e-02,\n",
       "          -9.6607e-04, -6.8054e-03],\n",
       "         [-7.2449e-02, -1.1490e-02,  3.6469e-02,  ..., -2.8091e-02,\n",
       "           8.4000e-03,  3.2401e-04],\n",
       "         [-3.1082e-02, -3.8147e-02,  9.4986e-03,  ...,  3.7445e-02,\n",
       "           9.9182e-03, -3.7689e-02]], dtype=torch.float16),\n",
       " 'attentions.2.k_lin.bias': tensor([-0.1434,  0.0362,  0.0589,  ..., -0.0784,  0.0018,  0.0213],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.v_lin.weight': tensor([[-0.0439,  0.0933,  0.0386,  ...,  0.0391,  0.0202,  0.0432],\n",
       "         [ 0.0735,  0.0101, -0.0274,  ..., -0.0017,  0.0382,  0.0117],\n",
       "         [-0.0158, -0.0080, -0.0196,  ...,  0.0014, -0.0242,  0.0054],\n",
       "         ...,\n",
       "         [ 0.0214, -0.0228,  0.0650,  ..., -0.0106, -0.0736,  0.0395],\n",
       "         [ 0.0005, -0.0108, -0.0226,  ...,  0.0237, -0.0484, -0.0049],\n",
       "         [-0.0588,  0.0681, -0.0263,  ..., -0.0410,  0.0104, -0.0114]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.v_lin.bias': tensor([-0.0169,  0.0031, -0.0011,  ...,  0.0018, -0.0169, -0.0022],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.out_lin.weight': tensor([[-0.0176,  0.0222,  0.0245,  ...,  0.0262, -0.0013, -0.0046],\n",
       "         [ 0.0071, -0.0213,  0.0294,  ...,  0.0596,  0.0868,  0.0118],\n",
       "         [-0.1110,  0.0413, -0.0158,  ..., -0.0172,  0.0201,  0.0041],\n",
       "         ...,\n",
       "         [-0.0251,  0.0579,  0.0374,  ..., -0.0290,  0.0209,  0.1043],\n",
       "         [ 0.0136, -0.0317, -0.0289,  ...,  0.0272,  0.0955,  0.0442],\n",
       "         [ 0.0461, -0.0077, -0.0143,  ..., -0.0015, -0.0581,  0.0541]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.out_lin.bias': tensor([-0.0019, -0.0030,  0.0083,  ..., -0.0156, -0.0054, -0.0080],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.q_lin.weight': tensor([[-0.0437, -0.0318,  0.0687,  ..., -0.0018, -0.0308, -0.0028],\n",
       "         [-0.0443, -0.0256,  0.0007,  ...,  0.0670,  0.0379, -0.0993],\n",
       "         [ 0.0336, -0.0477, -0.0236,  ..., -0.0286, -0.0033,  0.0184],\n",
       "         ...,\n",
       "         [ 0.0333, -0.0394, -0.1803,  ...,  0.0793,  0.0743,  0.0076],\n",
       "         [ 0.0622,  0.0037, -0.0454,  ...,  0.0629,  0.0887, -0.0440],\n",
       "         [-0.0089, -0.0105, -0.0463,  ...,  0.0999,  0.0369,  0.1378]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.q_lin.bias': tensor([-0.0401,  0.1438, -0.0385,  ..., -0.1106,  0.1564,  0.1642],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.k_lin.weight': tensor([[-0.0089, -0.0113, -0.0468,  ...,  0.0158,  0.0071,  0.0091],\n",
       "         [ 0.0339, -0.0971,  0.0461,  ...,  0.0589,  0.0176, -0.0330],\n",
       "         [-0.0699, -0.0306, -0.0803,  ...,  0.1022, -0.0597, -0.0564],\n",
       "         ...,\n",
       "         [-0.0717, -0.0049,  0.0654,  ..., -0.0099, -0.0762, -0.0661],\n",
       "         [ 0.0359, -0.0930,  0.0182,  ..., -0.0942, -0.1132, -0.0389],\n",
       "         [-0.0750, -0.0406, -0.0811,  ..., -0.0624,  0.0540,  0.0132]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.k_lin.bias': tensor([ 0.0595,  0.1484,  0.0822,  ..., -0.3538,  0.2563,  0.4055],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.v_lin.weight': tensor([[-0.0426,  0.0713,  0.0256,  ..., -0.0038, -0.0739, -0.0043],\n",
       "         [-0.0133,  0.0279, -0.0675,  ...,  0.0524,  0.0303,  0.0208],\n",
       "         [ 0.0614, -0.0576, -0.0627,  ..., -0.0679, -0.0173,  0.0283],\n",
       "         ...,\n",
       "         [ 0.0206, -0.0275, -0.0056,  ...,  0.0048, -0.0276, -0.0093],\n",
       "         [-0.0340,  0.0428,  0.0120,  ..., -0.0428,  0.0313, -0.0415],\n",
       "         [-0.0115, -0.0214,  0.0282,  ..., -0.1031, -0.0457, -0.0007]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.v_lin.bias': tensor([-0.0124, -0.0127, -0.0002,  ...,  0.0131, -0.0091,  0.0046],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.out_lin.weight': tensor([[-0.0154,  0.0176,  0.0097,  ...,  0.0276, -0.0131, -0.0201],\n",
       "         [-0.0484, -0.0124, -0.0100,  ..., -0.0098, -0.0043, -0.0400],\n",
       "         [-0.0574, -0.0160,  0.0063,  ..., -0.0325, -0.0172,  0.0134],\n",
       "         ...,\n",
       "         [ 0.0446, -0.0113, -0.0161,  ...,  0.0532,  0.0723,  0.0326],\n",
       "         [ 0.0285,  0.0688,  0.0612,  ..., -0.0648,  0.1399, -0.0521],\n",
       "         [ 0.0464,  0.0538, -0.0357,  ...,  0.0007, -0.0655, -0.0172]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.out_lin.bias': tensor([-7.9513e-05,  1.7147e-03,  3.5152e-03,  ..., -3.3512e-03,\n",
       "          2.7122e-03, -1.1055e-02], dtype=torch.float16),\n",
       " 'attentions.4.q_lin.weight': tensor([[-0.0768, -0.0859, -0.0081,  ...,  0.0459, -0.0064,  0.0063],\n",
       "         [ 0.0338, -0.0207, -0.0061,  ..., -0.0358, -0.0027, -0.0474],\n",
       "         [ 0.0192, -0.0024, -0.0321,  ...,  0.0154,  0.0111, -0.0280],\n",
       "         ...,\n",
       "         [-0.0234,  0.0063,  0.0596,  ...,  0.1387, -0.0035,  0.1093],\n",
       "         [ 0.0451,  0.0087,  0.0492,  ..., -0.0793, -0.0057, -0.0173],\n",
       "         [ 0.0035, -0.0416,  0.0917,  ..., -0.0295,  0.0230, -0.0055]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.q_lin.bias': tensor([-0.0097,  0.1564, -0.0774,  ...,  0.2532,  0.1469, -0.3921],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.k_lin.weight': tensor([[-0.0035,  0.0604, -0.0149,  ...,  0.1118, -0.0576, -0.0138],\n",
       "         [-0.0270,  0.0627, -0.0443,  ...,  0.0195,  0.0113,  0.0050],\n",
       "         [ 0.0545,  0.0119,  0.0008,  ...,  0.0079,  0.0373, -0.0565],\n",
       "         ...,\n",
       "         [-0.0431,  0.0623,  0.0901,  ..., -0.0215, -0.0908,  0.0480],\n",
       "         [ 0.0696,  0.0371,  0.0318,  ...,  0.0635,  0.0421, -0.0577],\n",
       "         [ 0.0425, -0.0455, -0.0744,  ..., -0.1096, -0.0046, -0.0120]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.k_lin.bias': tensor([-0.8740, -0.9863,  0.4763,  ...,  3.3633,  2.6602, -3.6270],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.v_lin.weight': tensor([[ 0.0009,  0.0343, -0.0281,  ...,  0.0300, -0.0071,  0.0831],\n",
       "         [-0.1259,  0.0029,  0.0212,  ..., -0.0983,  0.0259,  0.0238],\n",
       "         [ 0.0161,  0.1008, -0.0624,  ..., -0.0837,  0.0424,  0.0107],\n",
       "         ...,\n",
       "         [ 0.0623, -0.0114, -0.0339,  ...,  0.0167,  0.0645, -0.0671],\n",
       "         [-0.0007,  0.0299,  0.0007,  ..., -0.0168,  0.0137, -0.0013],\n",
       "         [ 0.0120, -0.0375, -0.0798,  ..., -0.0443,  0.0429, -0.0204]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.v_lin.bias': tensor([ 0.0363,  0.0111,  0.0014,  ...,  0.0290,  0.0269, -0.0399],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.out_lin.weight': tensor([[ 0.0031,  0.0902, -0.0256,  ...,  0.0080, -0.0081,  0.0010],\n",
       "         [ 0.0286,  0.0235, -0.0779,  ...,  0.0255, -0.0071,  0.0461],\n",
       "         [ 0.0339,  0.0282, -0.0197,  ...,  0.0150, -0.0605,  0.0026],\n",
       "         ...,\n",
       "         [-0.0292,  0.0674,  0.0641,  ..., -0.0616,  0.0869, -0.0434],\n",
       "         [-0.0052,  0.0090,  0.0329,  ...,  0.0828, -0.0631,  0.0629],\n",
       "         [-0.0200, -0.0223, -0.0185,  ..., -0.0068, -0.0553,  0.0658]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.out_lin.bias': tensor([ 0.0006,  0.0025,  0.0045,  ..., -0.0044,  0.0001, -0.0082],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.q_lin.weight': tensor([[-0.0481,  0.0115, -0.0793,  ..., -0.0409, -0.0302,  0.0596],\n",
       "         [-0.0180, -0.0493,  0.0148,  ...,  0.1443,  0.0234,  0.0047],\n",
       "         [-0.0615, -0.0373,  0.0298,  ..., -0.0769,  0.0114,  0.0572],\n",
       "         ...,\n",
       "         [ 0.0097, -0.0750, -0.0284,  ..., -0.0072, -0.0565, -0.0234],\n",
       "         [-0.0479, -0.0382, -0.0438,  ..., -0.0702,  0.0371,  0.0330],\n",
       "         [ 0.0585, -0.0688, -0.0097,  ..., -0.0352, -0.0202,  0.0487]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.q_lin.bias': tensor([-0.1088,  0.1940, -0.0720,  ..., -0.1114, -0.0144,  0.2751],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.k_lin.weight': tensor([[ 0.0362, -0.1041, -0.0922,  ...,  0.0563,  0.0562,  0.0347],\n",
       "         [ 0.0234, -0.0155, -0.0113,  ...,  0.0410, -0.0269, -0.0474],\n",
       "         [ 0.0586, -0.0470, -0.0215,  ...,  0.0417, -0.0301, -0.0015],\n",
       "         ...,\n",
       "         [-0.0455,  0.0467, -0.0510,  ..., -0.1193, -0.0488,  0.0047],\n",
       "         [-0.0658,  0.0326, -0.0063,  ..., -0.0195,  0.0502,  0.0352],\n",
       "         [ 0.0037, -0.0090, -0.0455,  ...,  0.0751, -0.0598, -0.0387]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.k_lin.bias': tensor([-0.3066,  0.6680, -0.2798,  ..., -0.4404,  0.3975,  0.2445],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.v_lin.weight': tensor([[ 0.0024,  0.0089,  0.0248,  ..., -0.0161, -0.0038,  0.0039],\n",
       "         [ 0.0965, -0.0063,  0.0718,  ..., -0.0328, -0.0514, -0.0617],\n",
       "         [-0.0652,  0.0271,  0.0274,  ..., -0.0714,  0.0446,  0.0225],\n",
       "         ...,\n",
       "         [-0.0546,  0.0199, -0.0602,  ..., -0.0051,  0.0083, -0.0450],\n",
       "         [ 0.0529,  0.0351, -0.0341,  ...,  0.0054,  0.0280, -0.0197],\n",
       "         [-0.0217, -0.0485,  0.0039,  ..., -0.0531,  0.0249, -0.0432]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.v_lin.bias': tensor([-9.5725e-05,  4.9934e-03, -1.6739e-02,  ...,  4.9629e-03,\n",
       "          2.6413e-02,  1.5160e-02], dtype=torch.float16),\n",
       " 'attentions.5.out_lin.weight': tensor([[-0.0045, -0.0420, -0.0112,  ..., -0.0230,  0.0352, -0.0358],\n",
       "         [ 0.0228,  0.0529,  0.0025,  ...,  0.0205, -0.0223,  0.0493],\n",
       "         [-0.0285, -0.0188,  0.0067,  ..., -0.0230,  0.0076, -0.0072],\n",
       "         ...,\n",
       "         [-0.1318, -0.0543,  0.0020,  ...,  0.0169,  0.0001,  0.0162],\n",
       "         [ 0.0305,  0.0203,  0.0722,  ...,  0.0331, -0.0155,  0.0476],\n",
       "         [ 0.0052,  0.0072, -0.0370,  ..., -0.0474, -0.0356, -0.0217]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.out_lin.bias': tensor([-0.0012, -0.0107,  0.0136,  ...,  0.0031, -0.0117,  0.0165],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.0.weight': tensor([0.4771, 0.4324, 0.4082,  ..., 0.3828, 0.3962, 0.4077],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.0.bias': tensor([-0.0116, -0.0559,  0.0009,  ...,  0.2216, -0.1543,  0.0580],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.1.weight': tensor([0.4519, 0.4087, 0.3955,  ..., 0.3677, 0.3760, 0.4023],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.1.bias': tensor([-0.0217, -0.0818,  0.0562,  ...,  0.0906, -0.0440,  0.0921],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.2.weight': tensor([0.4844, 0.3989, 0.3936,  ..., 0.3545, 0.3567, 0.3977],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.2.bias': tensor([ 0.0224, -0.1289, -0.0190,  ...,  0.0580,  0.0618,  0.0776],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.3.weight': tensor([0.5220, 0.4221, 0.4097,  ..., 0.3643, 0.3679, 0.4192],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.3.bias': tensor([ 0.0439, -0.0983,  0.0282,  ...,  0.0829,  0.0564,  0.0471],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.4.weight': tensor([0.5005, 0.4321, 0.4062,  ..., 0.3882, 0.4019, 0.4404],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.4.bias': tensor([ 0.0378, -0.0317,  0.0154,  ...,  0.0796,  0.0571,  0.0237],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.5.weight': tensor([0.4067, 0.4434, 0.4287,  ..., 0.4167, 0.4004, 0.4785],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.5.bias': tensor([ 0.0358, -0.0662,  0.0774,  ...,  0.1306,  0.1550, -0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.0.lin1.weight': tensor([[-1.2672e-02, -3.8788e-02,  3.2306e-05,  ..., -8.1482e-02,\n",
       "          -3.4790e-02,  2.1866e-02],\n",
       "         [-6.6261e-03,  9.7580e-03, -1.5320e-02,  ...,  1.8555e-02,\n",
       "           3.8696e-02,  3.7170e-02],\n",
       "         [ 1.1742e-02,  4.8340e-02,  1.3351e-02,  ..., -8.4778e-02,\n",
       "           6.3904e-02,  6.1218e-02],\n",
       "         ...,\n",
       "         [ 3.6011e-02, -3.1525e-02,  1.8738e-02,  ..., -1.7105e-02,\n",
       "           1.3329e-02, -1.1017e-01],\n",
       "         [-1.8951e-02, -2.9190e-02,  3.0548e-02,  ...,  2.7420e-02,\n",
       "           6.9946e-02,  2.0924e-03],\n",
       "         [ 3.3813e-02, -2.0172e-02,  3.8116e-02,  ...,  5.7312e-02,\n",
       "           9.3994e-02,  1.2379e-03]], dtype=torch.float16),\n",
       " 'ffns.0.lin1.bias': tensor([-0.0131, -0.0759, -0.0362,  ..., -0.0826, -0.0804, -0.0515],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.0.lin2.weight': tensor([[ 0.0046,  0.0079,  0.0529,  ...,  0.0258, -0.0221,  0.0339],\n",
       "         [-0.0076,  0.0289,  0.0086,  ...,  0.0246,  0.0062,  0.0142],\n",
       "         [-0.0093,  0.0363,  0.0158,  ..., -0.0796, -0.0113, -0.0455],\n",
       "         ...,\n",
       "         [ 0.0407,  0.0439,  0.0706,  ...,  0.0773, -0.0735, -0.0439],\n",
       "         [-0.0270,  0.0094, -0.0075,  ..., -0.0200,  0.0424, -0.0061],\n",
       "         [ 0.0181,  0.0336, -0.0385,  ..., -0.0266, -0.0147, -0.0220]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.0.lin2.bias': tensor([-0.0343,  0.0078, -0.0060,  ..., -0.0272, -0.0274,  0.0338],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin1.weight': tensor([[ 0.0227,  0.0876, -0.0132,  ..., -0.0718,  0.0081, -0.0114],\n",
       "         [ 0.0071,  0.0038,  0.0141,  ..., -0.0280,  0.0219,  0.0181],\n",
       "         [-0.0223, -0.0004,  0.0231,  ..., -0.0387,  0.0682,  0.0191],\n",
       "         ...,\n",
       "         [-0.0041,  0.0643, -0.0310,  ...,  0.0630,  0.0699,  0.0247],\n",
       "         [ 0.0149, -0.0413, -0.0088,  ...,  0.1096,  0.0022,  0.1032],\n",
       "         [-0.0101, -0.0541,  0.0403,  ..., -0.0012,  0.0643,  0.0296]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin1.bias': tensor([-0.0133, -0.2512, -0.0746,  ..., -0.0648, -0.1320, -0.0579],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin2.weight': tensor([[-0.0138, -0.0021, -0.0194,  ..., -0.0113,  0.0578,  0.0502],\n",
       "         [-0.0067,  0.0012,  0.0370,  ...,  0.0709,  0.0808, -0.1228],\n",
       "         [-0.0168, -0.0160, -0.0573,  ...,  0.0444,  0.1133,  0.0057],\n",
       "         ...,\n",
       "         [-0.0868,  0.0316,  0.0164,  ...,  0.0447, -0.0241,  0.0619],\n",
       "         [ 0.0534, -0.0126,  0.0133,  ...,  0.1046,  0.1536, -0.0081],\n",
       "         [-0.0398, -0.0207, -0.0770,  ..., -0.1133, -0.0060,  0.0650]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin2.bias': tensor([-8.2474e-03,  1.2993e-02, -6.5002e-02,  ...,  1.6815e-02,\n",
       "         -7.9632e-05,  5.3940e-03], dtype=torch.float16),\n",
       " 'ffns.2.lin1.weight': tensor([[-0.0262,  0.0486, -0.0066,  ...,  0.0448, -0.0556,  0.0503],\n",
       "         [-0.0012,  0.0766, -0.0321,  ..., -0.0068,  0.0307, -0.0942],\n",
       "         [-0.0112,  0.0356, -0.0873,  ...,  0.0812, -0.0235, -0.0278],\n",
       "         ...,\n",
       "         [ 0.0489,  0.0567, -0.0620,  ..., -0.0385,  0.0042,  0.0978],\n",
       "         [ 0.0258,  0.0103, -0.0751,  ..., -0.0847,  0.0089, -0.0850],\n",
       "         [-0.0068,  0.0457,  0.0385,  ..., -0.0710,  0.0565,  0.0436]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.2.lin1.bias': tensor([-0.0541, -0.0539,  0.0065,  ..., -0.0884, -0.0382, -0.0329],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.2.lin2.weight': tensor([[ 0.0011, -0.0010, -0.0041,  ...,  0.0072,  0.0250, -0.0147],\n",
       "         [ 0.0252, -0.0105,  0.0042,  ..., -0.0570,  0.0276,  0.0704],\n",
       "         [ 0.0375,  0.0313,  0.0132,  ..., -0.0443, -0.0424,  0.0126],\n",
       "         ...,\n",
       "         [ 0.0312, -0.0418, -0.0685,  ..., -0.0935,  0.0022, -0.0210],\n",
       "         [-0.0708, -0.0626,  0.0083,  ..., -0.0435,  0.0522, -0.0146],\n",
       "         [ 0.0221, -0.0071,  0.0397,  ...,  0.0045, -0.0598,  0.0453]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.2.lin2.bias': tensor([-0.0127,  0.0516, -0.0605,  ..., -0.0313, -0.0528, -0.0266],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.3.lin1.weight': tensor([[-0.0157, -0.0170, -0.0318,  ..., -0.0128, -0.0076,  0.0305],\n",
       "         [ 0.0141, -0.0147,  0.0178,  ...,  0.0695, -0.0634,  0.0175],\n",
       "         [-0.0073,  0.0404,  0.0450,  ..., -0.0242, -0.0070,  0.0155],\n",
       "         ...,\n",
       "         [ 0.0166, -0.0082, -0.0556,  ...,  0.0216, -0.0241,  0.0147],\n",
       "         [ 0.0530, -0.0104, -0.0126,  ...,  0.0005, -0.0279,  0.0038],\n",
       "         [ 0.0338,  0.0043,  0.0775,  ..., -0.0059,  0.0440,  0.0228]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.3.lin1.bias': tensor([-0.0148, -0.0742,  0.0119,  ..., -0.0707, -0.0592, -0.0018],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.3.lin2.weight': tensor([[ 2.0004e-02, -1.0902e-02,  4.1771e-03,  ..., -2.0004e-02,\n",
       "          -9.8114e-03,  6.7711e-05],\n",
       "         [-3.1311e-02,  4.5532e-02,  2.9892e-02,  ..., -2.5082e-03,\n",
       "           8.6517e-03, -6.9923e-03],\n",
       "         [ 2.7847e-02,  1.3794e-01, -3.1616e-02,  ...,  2.7588e-02,\n",
       "          -7.2510e-02, -4.5319e-02],\n",
       "         ...,\n",
       "         [-5.6091e-02, -7.2021e-02,  5.9479e-02,  ...,  2.2919e-02,\n",
       "           2.4780e-02,  2.7771e-02],\n",
       "         [ 4.1290e-02,  2.2797e-02, -2.3254e-02,  ..., -8.3740e-02,\n",
       "          -5.9357e-02, -1.4275e-02],\n",
       "         [-2.1103e-02, -7.8308e-02,  3.3112e-02,  ...,  3.4119e-02,\n",
       "          -6.9656e-03, -2.0081e-02]], dtype=torch.float16),\n",
       " 'ffns.3.lin2.bias': tensor([-0.0090,  0.0278, -0.0587,  ..., -0.0312, -0.0074, -0.0637],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin1.weight': tensor([[-0.0677,  0.0052, -0.1005,  ...,  0.0771, -0.1050, -0.0384],\n",
       "         [-0.0512,  0.0034, -0.0509,  ..., -0.0155,  0.0776, -0.0857],\n",
       "         [-0.0600,  0.0778,  0.0810,  ...,  0.0157, -0.0954, -0.0230],\n",
       "         ...,\n",
       "         [ 0.0418, -0.0148, -0.0379,  ..., -0.0205,  0.0207, -0.0225],\n",
       "         [ 0.0346,  0.0348,  0.0593,  ..., -0.0584,  0.0012,  0.0373],\n",
       "         [ 0.0545,  0.0556, -0.0768,  ...,  0.0014, -0.0168,  0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin1.bias': tensor([-0.0869, -0.0952, -0.0798,  ..., -0.0242, -0.0565, -0.0575],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin2.weight': tensor([[ 0.0040, -0.0289, -0.0290,  ...,  0.0137,  0.0110,  0.1158],\n",
       "         [ 0.0149,  0.0246, -0.0155,  ..., -0.0367,  0.0259, -0.0410],\n",
       "         [ 0.0186,  0.0055, -0.0522,  ...,  0.0167, -0.1021, -0.0504],\n",
       "         ...,\n",
       "         [-0.0483,  0.0542, -0.0554,  ...,  0.0244,  0.0205,  0.0349],\n",
       "         [-0.0431,  0.0266,  0.0493,  ..., -0.0117,  0.0237, -0.0996],\n",
       "         [ 0.0181, -0.0209,  0.0030,  ..., -0.0360,  0.0212,  0.0717]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin2.bias': tensor([-0.0346,  0.0327, -0.0313,  ...,  0.0316,  0.0242, -0.0279],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin1.weight': tensor([[ 0.0108,  0.0593, -0.0305,  ..., -0.1803,  0.0803, -0.1282],\n",
       "         [ 0.0214,  0.0107,  0.0014,  ...,  0.0175, -0.0432, -0.0064],\n",
       "         [ 0.0007, -0.0363,  0.0270,  ..., -0.0061,  0.0106,  0.0102],\n",
       "         ...,\n",
       "         [ 0.0056, -0.0023,  0.0199,  ..., -0.0339, -0.0433, -0.0308],\n",
       "         [ 0.0441,  0.0565, -0.0056,  ...,  0.0247, -0.0573, -0.0717],\n",
       "         [-0.0349, -0.0391, -0.0258,  ...,  0.0273, -0.0069,  0.0550]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin1.bias': tensor([-0.0715, -0.0273, -0.1344,  ..., -0.0511, -0.0499, -0.0345],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin2.weight': tensor([[-0.0015, -0.0022,  0.0561,  ...,  0.0202, -0.0457, -0.0123],\n",
       "         [ 0.0644,  0.0430, -0.0257,  ..., -0.0504, -0.0732,  0.0125],\n",
       "         [ 0.0464, -0.0112,  0.0099,  ...,  0.0137,  0.0497,  0.0237],\n",
       "         ...,\n",
       "         [-0.0373, -0.0254, -0.0321,  ...,  0.0042,  0.0180,  0.0110],\n",
       "         [ 0.0528, -0.0042, -0.0142,  ..., -0.0712,  0.0045,  0.0144],\n",
       "         [-0.0551, -0.0016, -0.0011,  ..., -0.0149,  0.0220,  0.0027]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin2.bias': tensor([-0.0070,  0.0261, -0.0081,  ...,  0.0008,  0.0010,  0.0005],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.0.weight': tensor([0.5762, 0.5234, 0.5015,  ..., 0.4077, 0.4795, 0.5229],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.0.bias': tensor([-0.0064,  0.0586,  0.0102,  ..., -0.1186,  0.0911, -0.0417],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.1.weight': tensor([0.5996, 0.5444, 0.5117,  ..., 0.4646, 0.4966, 0.5342],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.1.bias': tensor([ 0.0169,  0.0590, -0.0360,  ..., -0.0582,  0.0399, -0.0467],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.2.weight': tensor([0.6504, 0.5767, 0.5435,  ..., 0.5156, 0.5376, 0.5723],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.2.bias': tensor([-0.0163,  0.0878, -0.0190,  ..., -0.0497, -0.0433, -0.0519],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.3.weight': tensor([0.6050, 0.5459, 0.5356,  ..., 0.5298, 0.5205, 0.5537],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.3.bias': tensor([-0.0227,  0.0378, -0.0240,  ..., -0.0473, -0.0534, -0.0234],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.4.weight': tensor([0.6416, 0.5654, 0.5488,  ..., 0.5430, 0.5352, 0.5723],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.4.bias': tensor([-0.0452,  0.0023, -0.0241,  ..., -0.0692, -0.0674,  0.0176],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.5.weight': tensor([2.4316, 2.4395, 2.6172,  ..., 2.7090, 2.5801, 2.7852],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.5.bias': tensor([-0.0137, -0.0698, -0.1873,  ..., -0.0140, -0.0352,  0.1290],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.0.weight': tensor([0.9834, 0.9771, 0.9771,  ..., 0.9790, 0.9844, 0.9766],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.0.bias': tensor([-0.0090,  0.0011, -0.0072,  ...,  0.0047, -0.0094, -0.0048],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.1.weight': tensor([0.9790, 0.9746, 0.9688,  ..., 0.9746, 0.9746, 0.9712],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.1.bias': tensor([ 0.0006, -0.0021, -0.0020,  ..., -0.0026, -0.0066, -0.0065],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.2.weight': tensor([0.9780, 0.9766, 0.9805,  ..., 0.9736, 0.9722, 0.9849],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.2.bias': tensor([-0.0017,  0.0021,  0.0053,  ...,  0.0020, -0.0029, -0.0007],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.3.weight': tensor([0.9629, 0.9795, 0.9707,  ..., 0.9673, 0.9736, 0.9780],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.3.bias': tensor([-0.0017,  0.0026,  0.0002,  ...,  0.0014, -0.0027, -0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.4.weight': tensor([0.9746, 0.9780, 0.9575,  ..., 0.9639, 0.9634, 0.9746],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.4.bias': tensor([-0.0072, -0.0010,  0.0022,  ...,  0.0084,  0.0062, -0.0062],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.5.weight': tensor([0.9810, 0.9746, 0.9634,  ..., 0.9707, 0.9600, 0.9805],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm15.5.bias': tensor([ 0.0163,  0.0045,  0.0228,  ...,  0.0189, -0.0037,  0.0126],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.0.q_lin.weight': tensor([[ 0.0164,  0.0308,  0.0518,  ..., -0.0311,  0.0111, -0.0059],\n",
       "         [-0.0075,  0.0033,  0.0101,  ..., -0.0020, -0.0101, -0.0029],\n",
       "         [ 0.0324,  0.0136,  0.0188,  ...,  0.0181, -0.0217, -0.0249],\n",
       "         ...,\n",
       "         [ 0.0107, -0.0217, -0.0229,  ...,  0.0354, -0.0202,  0.0420],\n",
       "         [-0.0061, -0.0128, -0.0047,  ..., -0.0179,  0.0064, -0.0171],\n",
       "         [-0.0095,  0.0062, -0.0494,  ..., -0.0125, -0.0032, -0.0164]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.0.q_lin.bias': tensor([-0.0225, -0.0379,  0.0187,  ...,  0.0264,  0.0071, -0.0247],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.0.k_lin.weight': tensor([[ 2.8572e-03,  3.1952e-02,  3.4088e-02,  ..., -7.3509e-03,\n",
       "           2.0081e-02,  3.3417e-02],\n",
       "         [-1.8492e-03,  2.2316e-03,  9.2773e-03,  ...,  2.4261e-02,\n",
       "           4.0619e-02, -4.1366e-05],\n",
       "         [ 3.4149e-02, -1.2970e-03, -2.8343e-03,  ...,  1.0468e-02,\n",
       "          -6.8169e-03, -1.0010e-02],\n",
       "         ...,\n",
       "         [-8.5220e-03,  3.4180e-02, -2.8717e-02,  ..., -1.0674e-02,\n",
       "          -1.4473e-02, -2.6657e-02],\n",
       "         [ 1.6617e-02, -1.9741e-03, -1.6388e-02,  ..., -2.3041e-02,\n",
       "           2.0294e-02, -4.2053e-02],\n",
       "         [-4.3579e-02,  1.3977e-02,  4.4174e-03,  ..., -1.1154e-02,\n",
       "          -5.6028e-04,  1.5091e-02]], dtype=torch.float16),\n",
       " 'encoder_attn.0.k_lin.bias': tensor([-0.0140, -0.0288,  0.0210,  ..., -0.0076,  0.0244,  0.0043],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.0.v_lin.weight': tensor([[ 0.0113, -0.0058, -0.0080,  ...,  0.0298,  0.0231,  0.0166],\n",
       "         [-0.0257, -0.0104, -0.0416,  ...,  0.0216, -0.0304,  0.0100],\n",
       "         [ 0.0238,  0.0001,  0.0289,  ...,  0.0073, -0.0228, -0.0145],\n",
       "         ...,\n",
       "         [ 0.0187,  0.0370, -0.0218,  ..., -0.0012, -0.0201,  0.0201],\n",
       "         [ 0.0169, -0.0114, -0.0286,  ...,  0.0137,  0.0161, -0.0247],\n",
       "         [-0.0155, -0.0278, -0.0107,  ..., -0.0450, -0.0192,  0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.0.v_lin.bias': tensor([-0.0005,  0.0070,  0.0117,  ...,  0.0017, -0.0085, -0.0157],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.0.out_lin.weight': tensor([[ 0.0044, -0.0038, -0.0193,  ..., -0.0091,  0.0374, -0.0304],\n",
       "         [-0.0086, -0.0187,  0.0193,  ...,  0.0109, -0.0038,  0.0230],\n",
       "         [ 0.0166,  0.0071,  0.0010,  ...,  0.0082,  0.0079,  0.0371],\n",
       "         ...,\n",
       "         [-0.0009,  0.0097,  0.0147,  ..., -0.0178, -0.0005,  0.0055],\n",
       "         [-0.0034, -0.0280, -0.0188,  ..., -0.0157, -0.0159,  0.0083],\n",
       "         [-0.0324,  0.0076, -0.0265,  ...,  0.0440,  0.0119,  0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.0.out_lin.bias': tensor([-0.0184,  0.0186,  0.0087,  ..., -0.0038,  0.0106,  0.0066],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.q_lin.weight': tensor([[-0.0164, -0.0345, -0.0269,  ...,  0.0255, -0.0297,  0.0016],\n",
       "         [-0.0018, -0.0036,  0.0195,  ..., -0.0250, -0.0199,  0.0102],\n",
       "         [-0.0066, -0.0629, -0.0019,  ...,  0.0254,  0.0356,  0.0268],\n",
       "         ...,\n",
       "         [ 0.0096,  0.0519,  0.0172,  ..., -0.0445,  0.0519,  0.0086],\n",
       "         [ 0.0112,  0.0225, -0.0233,  ...,  0.0010,  0.0106, -0.0304],\n",
       "         [-0.0099, -0.0239, -0.0472,  ..., -0.0106, -0.0237,  0.0122]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.q_lin.bias': tensor([ 0.0093, -0.0022,  0.0051,  ..., -0.0119, -0.0138, -0.0093],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.k_lin.weight': tensor([[ 0.0278, -0.0126,  0.0149,  ..., -0.0121, -0.0450, -0.0329],\n",
       "         [ 0.0170,  0.0064,  0.0023,  ..., -0.0340, -0.0085, -0.0176],\n",
       "         [-0.0035,  0.0009,  0.0122,  ...,  0.0414,  0.0206,  0.0355],\n",
       "         ...,\n",
       "         [ 0.0042,  0.0174, -0.0121,  ...,  0.0498,  0.0006, -0.0078],\n",
       "         [ 0.0080,  0.0082, -0.0217,  ..., -0.0178, -0.0379, -0.0184],\n",
       "         [ 0.0022, -0.0091, -0.0108,  ..., -0.0438, -0.0316,  0.0008]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.k_lin.bias': tensor([ 0.0316, -0.0262,  0.0284,  ..., -0.0101,  0.0186, -0.0077],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.v_lin.weight': tensor([[-0.0017,  0.0128,  0.0244,  ...,  0.0035, -0.0289, -0.0163],\n",
       "         [-0.0006, -0.0073,  0.0075,  ..., -0.0364, -0.0291, -0.0050],\n",
       "         [-0.0042, -0.0134, -0.0031,  ..., -0.0036,  0.0018,  0.0061],\n",
       "         ...,\n",
       "         [ 0.0169,  0.0150, -0.0268,  ..., -0.0056,  0.0253, -0.0209],\n",
       "         [-0.0074,  0.0120,  0.0197,  ..., -0.0145,  0.0176, -0.0029],\n",
       "         [ 0.0273, -0.0017, -0.0068,  ..., -0.0281,  0.0271,  0.0339]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.v_lin.bias': tensor([-0.0157, -0.0086,  0.0218,  ..., -0.0131, -0.0040, -0.0253],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.out_lin.weight': tensor([[ 0.0076, -0.0167,  0.0005,  ..., -0.0427,  0.0084, -0.0185],\n",
       "         [ 0.0053,  0.0308, -0.0035,  ...,  0.0198,  0.0293, -0.0113],\n",
       "         [-0.0189,  0.0108,  0.0241,  ..., -0.0227,  0.0103, -0.0304],\n",
       "         ...,\n",
       "         [ 0.0047, -0.0064,  0.0216,  ..., -0.0111, -0.0409, -0.0191],\n",
       "         [-0.0060, -0.0067,  0.0134,  ...,  0.0093, -0.0108, -0.0130],\n",
       "         [-0.0326,  0.0088, -0.0160,  ...,  0.0051,  0.0370,  0.0150]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.1.out_lin.bias': tensor([-0.0115, -0.0105, -0.0131,  ..., -0.0121,  0.0199,  0.0102],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.2.q_lin.weight': tensor([[-2.2888e-02,  4.4006e-02,  3.8208e-02,  ..., -2.4414e-02,\n",
       "           1.9653e-02,  2.3270e-03],\n",
       "         [-2.3087e-02,  4.1687e-02, -2.5826e-03,  ..., -3.6774e-02,\n",
       "          -1.4763e-02,  2.6917e-02],\n",
       "         [ 7.3254e-05,  2.7191e-02,  3.4485e-02,  ...,  2.9831e-02,\n",
       "           5.1231e-03, -6.2294e-03],\n",
       "         ...,\n",
       "         [-8.3618e-03, -1.2619e-02,  1.4091e-02,  ...,  2.1729e-02,\n",
       "          -2.3392e-02,  1.8356e-02],\n",
       "         [ 1.6327e-02,  8.7128e-03, -3.3752e-02,  ..., -1.5991e-02,\n",
       "           3.6621e-02, -2.2186e-02],\n",
       "         [-2.7252e-02,  1.3189e-03,  2.1225e-02,  ..., -1.5507e-03,\n",
       "          -7.7782e-03,  6.9122e-03]], dtype=torch.float16),\n",
       " 'encoder_attn.2.q_lin.bias': tensor([-0.0061,  0.0068, -0.0189,  ...,  0.0206,  0.0042, -0.0330],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.2.k_lin.weight': tensor([[ 0.0187,  0.0256, -0.0263,  ..., -0.0067,  0.0086, -0.0363],\n",
       "         [ 0.0326,  0.0173, -0.0128,  ..., -0.0196, -0.0090, -0.0098],\n",
       "         [-0.0160, -0.0124,  0.0399,  ...,  0.0163,  0.0072,  0.0071],\n",
       "         ...,\n",
       "         [-0.0252,  0.0114,  0.0105,  ..., -0.0002, -0.0021, -0.0393],\n",
       "         [ 0.0161, -0.0331,  0.0052,  ..., -0.0156,  0.0297, -0.0427],\n",
       "         [ 0.0009, -0.0320,  0.0344,  ...,  0.0158,  0.0137,  0.0025]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.2.k_lin.bias': tensor([-0.0516, -0.0485, -0.0151,  ...,  0.0021,  0.0146,  0.0302],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.2.v_lin.weight': tensor([[ 0.0075,  0.0027, -0.0115,  ..., -0.0119, -0.0291, -0.0243],\n",
       "         [-0.0094,  0.0194, -0.0049,  ..., -0.0045,  0.0326,  0.0132],\n",
       "         [-0.0102, -0.0183, -0.0282,  ...,  0.0093,  0.0064,  0.0009],\n",
       "         ...,\n",
       "         [-0.0465, -0.0222,  0.0399,  ..., -0.0275, -0.0048, -0.0037],\n",
       "         [ 0.0057,  0.0204,  0.0044,  ..., -0.0210, -0.0065,  0.0157],\n",
       "         [-0.0311,  0.0096,  0.0195,  ...,  0.0164,  0.0133, -0.0112]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.2.v_lin.bias': tensor([ 0.0155, -0.0134,  0.0168,  ..., -0.0027, -0.0037, -0.0041],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.2.out_lin.weight': tensor([[-0.0229,  0.0203,  0.0286,  ...,  0.0187, -0.0040, -0.0107],\n",
       "         [-0.0311,  0.0038, -0.0357,  ..., -0.0018,  0.0192, -0.0151],\n",
       "         [ 0.0010, -0.0086, -0.0320,  ..., -0.0021,  0.0122, -0.0174],\n",
       "         ...,\n",
       "         [-0.0148, -0.0189, -0.0184,  ..., -0.0149,  0.0082, -0.0198],\n",
       "         [ 0.0202, -0.0093, -0.0207,  ...,  0.0152, -0.0081,  0.0157],\n",
       "         [ 0.0015,  0.0185,  0.0205,  ...,  0.0109,  0.0060, -0.0277]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.2.out_lin.bias': tensor([ 0.0005,  0.0114, -0.0077,  ..., -0.0139, -0.0114, -0.0040],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.3.q_lin.weight': tensor([[ 0.0083,  0.0048,  0.0354,  ..., -0.0069, -0.0061,  0.0516],\n",
       "         [-0.0266,  0.0428, -0.0094,  ..., -0.0153,  0.0114,  0.0001],\n",
       "         [ 0.0226,  0.0194, -0.0440,  ...,  0.0261,  0.0285,  0.0228],\n",
       "         ...,\n",
       "         [ 0.0226,  0.0331,  0.0158,  ..., -0.0182, -0.0257, -0.0004],\n",
       "         [-0.0154,  0.0352, -0.0091,  ...,  0.0003, -0.0126, -0.0278],\n",
       "         [-0.0388,  0.0029,  0.0352,  ...,  0.0261,  0.0468, -0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.3.q_lin.bias': tensor([-0.0073,  0.0450, -0.0249,  ..., -0.0199, -0.0353, -0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.3.k_lin.weight': tensor([[-6.1584e-02,  2.0691e-02,  5.7648e-02,  ..., -1.5869e-02,\n",
       "          -1.0376e-02,  2.4307e-02],\n",
       "         [-9.8825e-05,  1.9699e-02,  7.7896e-03,  ...,  2.6608e-03,\n",
       "           1.7593e-02,  8.2245e-03],\n",
       "         [ 8.1711e-03, -1.9058e-02, -3.9917e-02,  ...,  4.7058e-02,\n",
       "          -4.4525e-02, -3.7262e-02],\n",
       "         ...,\n",
       "         [ 7.8659e-03,  3.8242e-03, -5.4245e-03,  ..., -4.9988e-02,\n",
       "          -2.9251e-02, -1.4824e-02],\n",
       "         [-3.1982e-02,  2.9861e-02,  5.8289e-03,  ..., -2.4929e-03,\n",
       "          -3.5034e-02,  6.7406e-03],\n",
       "         [-4.1351e-02, -3.4058e-02,  3.6407e-02,  ..., -1.7456e-02,\n",
       "          -5.7449e-03, -4.4434e-02]], dtype=torch.float16),\n",
       " 'encoder_attn.3.k_lin.bias': tensor([ 0.0232, -0.2113,  0.0778,  ..., -0.0478,  0.0316, -0.0240],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.3.v_lin.weight': tensor([[-0.0049,  0.0349, -0.0371,  ...,  0.0011,  0.0059,  0.0065],\n",
       "         [-0.0074,  0.0060, -0.0242,  ...,  0.0328,  0.0080, -0.0034],\n",
       "         [-0.0025,  0.0171,  0.0103,  ...,  0.0164, -0.0231, -0.0162],\n",
       "         ...,\n",
       "         [ 0.0021, -0.0066,  0.0044,  ...,  0.0178,  0.0146, -0.0224],\n",
       "         [ 0.0206, -0.0110,  0.0119,  ...,  0.0148, -0.0268,  0.0065],\n",
       "         [-0.0311, -0.0127, -0.0153,  ..., -0.0095, -0.0108,  0.0402]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.3.v_lin.bias': tensor([-0.0094,  0.0096, -0.0099,  ..., -0.0060,  0.0084,  0.0071],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.3.out_lin.weight': tensor([[ 0.0142,  0.0025, -0.0037,  ...,  0.0022,  0.0059, -0.0096],\n",
       "         [-0.0133, -0.0204,  0.0145,  ...,  0.0077, -0.0150,  0.0172],\n",
       "         [-0.0010, -0.0033, -0.0013,  ...,  0.0129,  0.0289,  0.0125],\n",
       "         ...,\n",
       "         [ 0.0114,  0.0275, -0.0099,  ..., -0.0067, -0.0263,  0.0160],\n",
       "         [-0.0186, -0.0236,  0.0155,  ...,  0.0093,  0.0192,  0.0027],\n",
       "         [-0.0224, -0.0154, -0.0078,  ..., -0.0159,  0.0038,  0.0106]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.3.out_lin.bias': tensor([ 0.0019,  0.0133,  0.0081,  ..., -0.0032, -0.0145, -0.0097],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.4.q_lin.weight': tensor([[-0.0150, -0.0229, -0.0005,  ..., -0.0162,  0.0262,  0.0452],\n",
       "         [-0.0182,  0.0263, -0.0275,  ..., -0.0012, -0.0123,  0.0051],\n",
       "         [-0.0326,  0.0172, -0.0178,  ..., -0.0385,  0.0220,  0.0158],\n",
       "         ...,\n",
       "         [ 0.0106, -0.0142,  0.0237,  ..., -0.0064, -0.0147,  0.0370],\n",
       "         [-0.0356,  0.0031,  0.0186,  ..., -0.0237, -0.0619, -0.0416],\n",
       "         [-0.0300,  0.0509, -0.0502,  ...,  0.0131,  0.0402, -0.0289]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.4.q_lin.bias': tensor([-0.0054, -0.0143,  0.0055,  ..., -0.0277,  0.0115, -0.0109],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.4.k_lin.weight': tensor([[-0.0097,  0.0383,  0.0359,  ...,  0.0257, -0.0125,  0.0093],\n",
       "         [ 0.0044,  0.0182, -0.0276,  ...,  0.0072,  0.0100, -0.0299],\n",
       "         [-0.0331, -0.0576, -0.0332,  ..., -0.0183, -0.0077,  0.0077],\n",
       "         ...,\n",
       "         [ 0.0330, -0.0518, -0.0044,  ...,  0.0229, -0.0129,  0.0058],\n",
       "         [-0.0124, -0.0325, -0.0066,  ...,  0.0240,  0.0205,  0.0245],\n",
       "         [ 0.0301, -0.0041, -0.0343,  ...,  0.0034, -0.0094, -0.0282]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.4.k_lin.bias': tensor([-0.0345,  0.1051, -0.0536,  ..., -0.1884, -0.1255,  0.0742],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.4.v_lin.weight': tensor([[ 2.2827e-02, -2.3941e-02, -4.3945e-02,  ..., -3.0136e-02,\n",
       "          -7.7705e-03, -1.8097e-02],\n",
       "         [-2.6703e-03,  2.2888e-02,  4.2114e-03,  ...,  2.4872e-02,\n",
       "           1.1452e-02, -2.0004e-02],\n",
       "         [-3.2135e-02,  1.4618e-02,  2.0721e-02,  ..., -8.8806e-03,\n",
       "          -2.6215e-02, -2.4460e-02],\n",
       "         ...,\n",
       "         [ 7.1144e-03, -2.7649e-02,  1.1894e-02,  ...,  1.5440e-03,\n",
       "          -2.3102e-02,  2.7237e-03],\n",
       "         [ 1.7633e-03,  1.5884e-02, -1.1650e-02,  ...,  1.6037e-02,\n",
       "           1.2924e-02, -1.1665e-02],\n",
       "         [-4.4286e-05, -9.0103e-03, -1.2428e-02,  ...,  1.4992e-02,\n",
       "          -4.7226e-03,  6.3553e-03]], dtype=torch.float16),\n",
       " 'encoder_attn.4.v_lin.bias': tensor([ 0.0090, -0.0102, -0.0250,  ..., -0.0100, -0.0058,  0.0164],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.4.out_lin.weight': tensor([[ 0.0089, -0.0007, -0.0273,  ...,  0.0024,  0.0021,  0.0211],\n",
       "         [-0.0010,  0.0103,  0.0240,  ..., -0.0362, -0.0237,  0.0319],\n",
       "         [-0.0135,  0.0041, -0.0253,  ...,  0.0104, -0.0084,  0.0178],\n",
       "         ...,\n",
       "         [ 0.0055, -0.0088,  0.0134,  ..., -0.0066, -0.0142, -0.0122],\n",
       "         [-0.0022, -0.0150, -0.0187,  ..., -0.0083,  0.0085, -0.0249],\n",
       "         [-0.0100, -0.0244,  0.0082,  ..., -0.0069, -0.0065,  0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.4.out_lin.bias': tensor([ 0.0135, -0.0009,  0.0178,  ..., -0.0086, -0.0131, -0.0152],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.q_lin.weight': tensor([[ 0.0045,  0.0400,  0.0250,  ..., -0.0507, -0.0172, -0.0699],\n",
       "         [ 0.0104,  0.0077, -0.0351,  ..., -0.0365, -0.0215,  0.0273],\n",
       "         [-0.0253,  0.0064, -0.0235,  ...,  0.0100, -0.0077, -0.0109],\n",
       "         ...,\n",
       "         [ 0.0221,  0.0023,  0.0629,  ...,  0.0512, -0.0072, -0.0051],\n",
       "         [-0.0186, -0.0114,  0.0185,  ...,  0.0051, -0.0046, -0.0305],\n",
       "         [-0.0143,  0.0208,  0.0135,  ..., -0.0596, -0.0375,  0.0126]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.q_lin.bias': tensor([ 0.0156, -0.0152, -0.0185,  ...,  0.0112, -0.0016,  0.0052],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.k_lin.weight': tensor([[-0.0485, -0.0308,  0.0188,  ...,  0.0098,  0.0137,  0.0038],\n",
       "         [-0.0566,  0.0186, -0.0167,  ...,  0.0082, -0.0131,  0.0256],\n",
       "         [-0.0008,  0.0271,  0.0265,  ..., -0.0289, -0.0056,  0.0504],\n",
       "         ...,\n",
       "         [-0.0047, -0.0163,  0.0310,  ...,  0.0072,  0.0494, -0.0442],\n",
       "         [ 0.0309, -0.0046,  0.0499,  ...,  0.0198,  0.0844, -0.0351],\n",
       "         [ 0.0175, -0.0252,  0.0158,  ..., -0.0475, -0.0208,  0.0504]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.k_lin.bias': tensor([ 0.2891, -0.1833,  0.0045,  ...,  0.6196,  0.1527, -0.3357],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.v_lin.weight': tensor([[ 0.0314, -0.0233, -0.0279,  ..., -0.0146,  0.0153, -0.0135],\n",
       "         [ 0.0156, -0.0220, -0.0176,  ..., -0.0115,  0.0243,  0.0170],\n",
       "         [ 0.0249, -0.0171,  0.0405,  ..., -0.0211,  0.0049,  0.0061],\n",
       "         ...,\n",
       "         [ 0.0073, -0.0184,  0.0068,  ...,  0.0090,  0.0170,  0.0233],\n",
       "         [-0.0062, -0.0233,  0.0080,  ...,  0.0136,  0.0130,  0.0341],\n",
       "         [ 0.0135,  0.0044,  0.0328,  ..., -0.0054,  0.0045, -0.0010]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.v_lin.bias': tensor([-0.0151,  0.0076, -0.0020,  ..., -0.0197, -0.0026, -0.0288],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.out_lin.weight': tensor([[-0.0186, -0.0019,  0.0323,  ...,  0.0019, -0.0088, -0.0157],\n",
       "         [-0.0107, -0.0197,  0.0131,  ...,  0.0075, -0.0117, -0.0156],\n",
       "         [-0.0162, -0.0208,  0.0166,  ..., -0.0018,  0.0008,  0.0325],\n",
       "         ...,\n",
       "         [ 0.0196, -0.0029, -0.0198,  ...,  0.0012,  0.0004, -0.0066],\n",
       "         [ 0.0253, -0.0099,  0.0022,  ..., -0.0079, -0.0101,  0.0193],\n",
       "         [-0.0005, -0.0136, -0.0199,  ...,  0.0229,  0.0106,  0.0053]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder_attn.5.out_lin.bias': tensor([ 0.0178,  0.0137,  0.0197,  ..., -0.0101, -0.0159, -0.0171],\n",
       "        dtype=torch.float16),\n",
       " 'pred_layer.proj.weight': tensor([[-0.0026,  0.0328, -0.0086,  ..., -0.0876,  0.0523,  0.0307],\n",
       "         [-0.0312, -0.0044,  0.0104,  ...,  0.0131, -0.0293,  0.0129],\n",
       "         [-0.0401,  0.0246,  0.0135,  ..., -0.0760, -0.0206, -0.0047],\n",
       "         ...,\n",
       "         [-0.0231, -0.0485, -0.0335,  ..., -0.0450,  0.0485,  0.0441],\n",
       "         [-0.0276,  0.0656,  0.0337,  ..., -0.0289,  0.0030, -0.0454],\n",
       "         [ 0.0289, -0.0684, -0.0053,  ..., -0.0873,  0.0255, -0.0303]],\n",
       "        dtype=torch.float16),\n",
       " 'pred_layer.proj.bias': tensor([-2.2031, -0.0828, -2.3945,  ..., -1.2891, -1.1865, -1.6445],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position_embeddings.weight': tensor([[-0.0095,  0.0503,  0.0038,  ...,  0.0156, -0.0090, -0.0427],\n",
       "         [ 0.0224,  0.0274, -0.0191,  ..., -0.0009, -0.0053, -0.0260],\n",
       "         [ 0.0108,  0.0206,  0.0008,  ...,  0.0028, -0.0196, -0.0109],\n",
       "         ...,\n",
       "         [ 0.0151, -0.0050,  0.0265,  ..., -0.0256,  0.0176, -0.0139],\n",
       "         [ 0.0186, -0.0235, -0.0098,  ..., -0.0160,  0.0303,  0.0023],\n",
       "         [-0.0230,  0.0086,  0.0015,  ...,  0.0154, -0.0029,  0.0096]],\n",
       "        dtype=torch.float16),\n",
       " 'lang_embeddings.weight': tensor([[ 0.0027,  0.0025,  0.0109,  ..., -0.0143,  0.0063,  0.0066],\n",
       "         [ 0.0016, -0.0080,  0.0105,  ..., -0.0008,  0.0116,  0.0109],\n",
       "         [ 0.0046, -0.0050,  0.0110,  ...,  0.0222,  0.0029,  0.0070]],\n",
       "        dtype=torch.float16),\n",
       " 'embeddings.weight': tensor([[-0.0027,  0.0350, -0.0067,  ..., -0.0880,  0.0496,  0.0398],\n",
       "         [-0.0480,  0.0035,  0.0121,  ...,  0.0016, -0.0303,  0.0152],\n",
       "         [-0.0391,  0.0273,  0.0157,  ..., -0.0782, -0.0212,  0.0021],\n",
       "         ...,\n",
       "         [-0.0252, -0.0506, -0.0354,  ..., -0.0431,  0.0506,  0.0500],\n",
       "         [-0.0274,  0.0699,  0.0352,  ..., -0.0271, -0.0021, -0.0391],\n",
       "         [ 0.0297, -0.0688, -0.0042,  ..., -0.0880,  0.0251, -0.0300]],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm_emb.weight': tensor([0.5601, 0.4932, 0.4907,  ..., 0.3596, 0.4226, 0.5029],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm_emb.bias': tensor([-0.0169, -0.0542, -0.0559,  ..., -0.0329,  0.0228, -0.0206],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.q_lin.weight': tensor([[-0.0002, -0.0928,  0.0327,  ..., -0.0751,  0.0234,  0.0571],\n",
       "         [-0.0903, -0.0177, -0.0189,  ..., -0.0553, -0.0143, -0.0099],\n",
       "         [ 0.0669, -0.0993,  0.0330,  ...,  0.0161, -0.0320, -0.0341],\n",
       "         ...,\n",
       "         [-0.0138, -0.0271, -0.0089,  ..., -0.0439, -0.0521,  0.0711],\n",
       "         [ 0.0374,  0.0258, -0.0851,  ...,  0.0525,  0.0072,  0.0685],\n",
       "         [ 0.0829,  0.1621, -0.0424,  ...,  0.0088,  0.0141, -0.0450]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.q_lin.bias': tensor([-0.1901,  0.1615,  0.1757,  ...,  0.1613, -0.2607,  0.1310],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.k_lin.weight': tensor([[ 0.0300,  0.0428,  0.0322,  ..., -0.0221,  0.0182, -0.0563],\n",
       "         [-0.0394,  0.0177, -0.0555,  ...,  0.0102,  0.0197,  0.0043],\n",
       "         [-0.1019,  0.0801,  0.0087,  ..., -0.0273,  0.0535,  0.0184],\n",
       "         ...,\n",
       "         [ 0.0354,  0.0318,  0.0123,  ..., -0.0131, -0.0063, -0.0378],\n",
       "         [ 0.0194, -0.0528,  0.0505,  ..., -0.0173, -0.0578,  0.0383],\n",
       "         [ 0.0053,  0.0151,  0.0151,  ...,  0.0604, -0.0360, -0.0142]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.k_lin.bias': tensor([ 0.0111, -0.0001, -0.0178,  ..., -0.0212,  0.0528,  0.0181],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.v_lin.weight': tensor([[-0.0320, -0.0184, -0.0451,  ...,  0.0589,  0.0177, -0.0008],\n",
       "         [-0.0392,  0.0094,  0.0145,  ..., -0.0828, -0.0083, -0.0208],\n",
       "         [-0.0576,  0.0473, -0.0302,  ...,  0.0293,  0.0500, -0.0223],\n",
       "         ...,\n",
       "         [-0.0263,  0.0237,  0.0413,  ..., -0.0270,  0.0013, -0.0373],\n",
       "         [-0.0179, -0.0203, -0.0350,  ...,  0.0303,  0.0090, -0.0045],\n",
       "         [-0.0432,  0.0806,  0.0044,  ..., -0.0026, -0.0193,  0.0249]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.v_lin.bias': tensor([ 0.0030, -0.0265,  0.0111,  ..., -0.0245,  0.0073, -0.0233],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.out_lin.weight': tensor([[ 0.0064, -0.0244,  0.0326,  ..., -0.0139,  0.0169,  0.0025],\n",
       "         [ 0.0378, -0.0291, -0.0259,  ...,  0.0065,  0.0332, -0.0193],\n",
       "         [ 0.0351, -0.0189,  0.0518,  ...,  0.0363, -0.0025,  0.0011],\n",
       "         ...,\n",
       "         [ 0.0742,  0.0276, -0.0202,  ...,  0.0162, -0.0029, -0.0204],\n",
       "         [-0.0510, -0.0577, -0.0445,  ...,  0.0403, -0.0041,  0.0245],\n",
       "         [-0.0279,  0.0540, -0.0317,  ...,  0.0056, -0.0108,  0.0189]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.0.out_lin.bias': tensor([-0.0124,  0.0069,  0.0312,  ..., -0.0095,  0.0230, -0.0049],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.q_lin.weight': tensor([[-0.0028,  0.0179, -0.0191,  ..., -0.0524, -0.0042, -0.0524],\n",
       "         [-0.0009, -0.0567, -0.0369,  ...,  0.0163,  0.0640,  0.0174],\n",
       "         [ 0.0043, -0.0142,  0.0571,  ...,  0.0301, -0.0587, -0.0476],\n",
       "         ...,\n",
       "         [ 0.0219,  0.0385,  0.0159,  ...,  0.0838,  0.0373, -0.0009],\n",
       "         [ 0.0223,  0.0156,  0.0057,  ...,  0.0069, -0.0258, -0.0513],\n",
       "         [-0.0052, -0.0086,  0.0649,  ...,  0.0953,  0.0144,  0.0701]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.q_lin.bias': tensor([ 0.0551, -0.0065, -0.0593,  ...,  0.3005, -0.3032, -0.1682],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.k_lin.weight': tensor([[ 0.0198, -0.0086,  0.0364,  ...,  0.0160,  0.0341, -0.0120],\n",
       "         [-0.0731,  0.0085, -0.0406,  ...,  0.0040,  0.0510,  0.0282],\n",
       "         [-0.0253, -0.0368,  0.0006,  ..., -0.0197, -0.0003,  0.0284],\n",
       "         ...,\n",
       "         [ 0.0862,  0.0092,  0.0069,  ...,  0.0620, -0.0040, -0.0325],\n",
       "         [ 0.0013, -0.0064,  0.0390,  ..., -0.0029, -0.0352, -0.0739],\n",
       "         [-0.0143,  0.0452,  0.0676,  ...,  0.0252,  0.1487, -0.0208]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.k_lin.bias': tensor([ 0.0150,  0.0450,  0.0295,  ...,  0.0539, -0.1843, -0.0031],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.v_lin.weight': tensor([[-0.0177, -0.0336,  0.0242,  ...,  0.0378, -0.0171, -0.0774],\n",
       "         [-0.0143, -0.0141, -0.0953,  ...,  0.0056,  0.0065, -0.0152],\n",
       "         [-0.0408, -0.0168, -0.0078,  ..., -0.0191,  0.0343,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0032, -0.0036,  0.0463,  ..., -0.0187, -0.0197,  0.0305],\n",
       "         [ 0.0143,  0.0255,  0.0441,  ...,  0.0300,  0.0248,  0.0107],\n",
       "         [ 0.0630, -0.0036, -0.0258,  ...,  0.0434,  0.0277, -0.0803]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.v_lin.bias': tensor([ 0.0060,  0.0144, -0.0057,  ..., -0.0203,  0.0001, -0.0097],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.out_lin.weight': tensor([[ 0.0029, -0.0006, -0.0013,  ...,  0.0144, -0.0140, -0.0247],\n",
       "         [ 0.0491, -0.0112,  0.0438,  ..., -0.0211,  0.0517, -0.0309],\n",
       "         [-0.0314,  0.0101,  0.0350,  ..., -0.0345,  0.0686, -0.0065],\n",
       "         ...,\n",
       "         [ 0.0621,  0.0025,  0.0962,  ...,  0.0405, -0.2051,  0.0036],\n",
       "         [-0.0520,  0.0010, -0.0526,  ...,  0.0267,  0.0806, -0.0306],\n",
       "         [ 0.0452, -0.0349,  0.0165,  ..., -0.0801,  0.0390, -0.0182]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.1.out_lin.bias': tensor([-0.0059,  0.0039,  0.0001,  ..., -0.0106,  0.0061, -0.0131],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.q_lin.weight': tensor([[ 0.0402,  0.0368, -0.0126,  ...,  0.0286, -0.0384, -0.0308],\n",
       "         [-0.0737, -0.0246, -0.1005,  ..., -0.0056, -0.0938,  0.0116],\n",
       "         [ 0.1061, -0.0526, -0.1038,  ..., -0.0176,  0.0779, -0.0242],\n",
       "         ...,\n",
       "         [ 0.0182,  0.0084, -0.0211,  ..., -0.0175, -0.0880,  0.0059],\n",
       "         [ 0.0451,  0.0326, -0.0325,  ...,  0.0398,  0.0236, -0.0475],\n",
       "         [-0.0153,  0.0044, -0.0194,  ..., -0.0167, -0.0471, -0.0410]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.q_lin.bias': tensor([ 0.3979, -0.0129,  0.0826,  ..., -0.0617, -0.0966,  0.0656],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.k_lin.weight': tensor([[ 0.0055,  0.0467,  0.0225,  ...,  0.0938, -0.1024, -0.0219],\n",
       "         [-0.0188,  0.0248, -0.0058,  ..., -0.2227, -0.0073, -0.0417],\n",
       "         [-0.0710,  0.1197,  0.0423,  ..., -0.0319, -0.0534, -0.0028],\n",
       "         ...,\n",
       "         [-0.0164, -0.0435,  0.0470,  ..., -0.0638, -0.0125, -0.0266],\n",
       "         [-0.0595,  0.0235,  0.0153,  ..., -0.0413,  0.0030,  0.0337],\n",
       "         [-0.0205, -0.0384,  0.0145,  ...,  0.0139,  0.0339, -0.0261]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.k_lin.bias': tensor([-0.1293,  0.0322,  0.0640,  ..., -0.0770,  0.0099,  0.0219],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.v_lin.weight': tensor([[-0.0768,  0.0840,  0.0336,  ...,  0.0534,  0.0300,  0.0362],\n",
       "         [ 0.0668,  0.0085,  0.0027,  ..., -0.0174,  0.0234,  0.0260],\n",
       "         [-0.0186,  0.0021, -0.0245,  ...,  0.0012, -0.0205, -0.0329],\n",
       "         ...,\n",
       "         [ 0.0236, -0.0043,  0.0736,  ..., -0.0105, -0.0732,  0.0489],\n",
       "         [-0.0126, -0.0323, -0.0109,  ...,  0.0359, -0.0509, -0.0013],\n",
       "         [-0.0616,  0.0628, -0.0333,  ..., -0.0367, -0.0078,  0.0045]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.v_lin.bias': tensor([-0.0159,  0.0046, -0.0006,  ...,  0.0019, -0.0158, -0.0016],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.out_lin.weight': tensor([[-0.0170,  0.0345,  0.0330,  ...,  0.0271, -0.0151, -0.0114],\n",
       "         [ 0.0317, -0.0509,  0.0146,  ...,  0.0522,  0.0878,  0.0468],\n",
       "         [-0.0975,  0.0401, -0.0169,  ..., -0.0090,  0.0340, -0.0034],\n",
       "         ...,\n",
       "         [-0.0273,  0.0890,  0.0139,  ..., -0.0178,  0.0077,  0.0688],\n",
       "         [-0.0023, -0.0113, -0.0268,  ...,  0.0253,  0.0643,  0.0478],\n",
       "         [ 0.0277, -0.0142, -0.0253,  ...,  0.0029, -0.0643,  0.0466]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.2.out_lin.bias': tensor([-0.0040,  0.0004,  0.0007,  ..., -0.0214, -0.0071, -0.0083],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.q_lin.weight': tensor([[-0.0477, -0.0248,  0.0435,  ...,  0.0011, -0.0369,  0.0167],\n",
       "         [-0.0665, -0.0251, -0.0437,  ...,  0.0767,  0.0412, -0.1169],\n",
       "         [ 0.0265, -0.0374, -0.0162,  ..., -0.0131, -0.0010, -0.0021],\n",
       "         ...,\n",
       "         [ 0.0262, -0.0312, -0.1578,  ...,  0.0844,  0.0616, -0.0328],\n",
       "         [ 0.0747,  0.0233, -0.0244,  ...,  0.0720,  0.0944, -0.0407],\n",
       "         [-0.0074,  0.0075, -0.0137,  ...,  0.1180,  0.0013,  0.1410]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.q_lin.bias': tensor([-0.0316,  0.1356, -0.0358,  ..., -0.1119,  0.1421,  0.1515],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.k_lin.weight': tensor([[-0.0047, -0.0127, -0.0429,  ..., -0.0031,  0.0204,  0.0027],\n",
       "         [ 0.0485, -0.0887,  0.0336,  ...,  0.0482,  0.0077, -0.0086],\n",
       "         [-0.0670, -0.0246, -0.0545,  ...,  0.1289, -0.0397, -0.0382],\n",
       "         ...,\n",
       "         [-0.0619, -0.0244,  0.0872,  ..., -0.0328, -0.0990, -0.0829],\n",
       "         [ 0.0227, -0.0465,  0.0147,  ..., -0.0802, -0.1226, -0.0598],\n",
       "         [-0.0739, -0.0132, -0.0905,  ..., -0.0454,  0.0459,  0.0190]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.k_lin.bias': tensor([ 0.0374,  0.1003,  0.0879,  ..., -0.2991,  0.3259,  0.3665],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.v_lin.weight': tensor([[-0.0172,  0.0559,  0.0200,  ...,  0.0096, -0.0989, -0.0117],\n",
       "         [-0.0279,  0.0076, -0.0551,  ...,  0.0513,  0.0144,  0.0150],\n",
       "         [ 0.0523, -0.0528, -0.0613,  ..., -0.0386, -0.0104,  0.0157],\n",
       "         ...,\n",
       "         [ 0.0192, -0.0045, -0.0023,  ...,  0.0197, -0.0243, -0.0232],\n",
       "         [-0.0260,  0.0276,  0.0021,  ..., -0.0432,  0.0251, -0.0545],\n",
       "         [ 0.0033, -0.0253,  0.0136,  ..., -0.0900, -0.0645, -0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.v_lin.bias': tensor([-0.0108, -0.0138,  0.0017,  ...,  0.0117, -0.0091,  0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.out_lin.weight': tensor([[-0.0036,  0.0098,  0.0107,  ...,  0.0284, -0.0263, -0.0210],\n",
       "         [-0.0257, -0.0029, -0.0077,  ..., -0.0082, -0.0072, -0.0323],\n",
       "         [-0.0520, -0.0257,  0.0284,  ..., -0.0239, -0.0168,  0.0344],\n",
       "         ...,\n",
       "         [ 0.0376, -0.0014, -0.0262,  ...,  0.0442,  0.1093,  0.0102],\n",
       "         [ 0.0478,  0.0622,  0.0797,  ..., -0.0311,  0.1453, -0.0765],\n",
       "         [ 0.0642,  0.0417, -0.0370,  ...,  0.0048, -0.0715, -0.0309]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.3.out_lin.bias': tensor([-0.0015,  0.0024,  0.0005,  ..., -0.0156,  0.0009, -0.0150],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.q_lin.weight': tensor([[-0.0584, -0.0447, -0.0182,  ...,  0.0171,  0.0061,  0.0104],\n",
       "         [ 0.0309, -0.0195, -0.0170,  ..., -0.0275,  0.0169, -0.0515],\n",
       "         [-0.0069,  0.0171, -0.0150,  ...,  0.0468,  0.0429, -0.0150],\n",
       "         ...,\n",
       "         [-0.0046,  0.0144,  0.0897,  ...,  0.1763, -0.0276,  0.1179],\n",
       "         [ 0.0410, -0.0154,  0.0063,  ..., -0.0611, -0.0475,  0.0127],\n",
       "         [ 0.0051, -0.0192,  0.0677,  ..., -0.0191,  0.0469,  0.0282]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.q_lin.bias': tensor([-0.0175,  0.1377, -0.0790,  ...,  0.2505,  0.1559, -0.3853],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.k_lin.weight': tensor([[-0.0276,  0.0535, -0.0023,  ...,  0.1101, -0.0703,  0.0051],\n",
       "         [-0.0172,  0.0762, -0.0359,  ...,  0.0157,  0.0238, -0.0010],\n",
       "         [ 0.0458,  0.0311, -0.0058,  ..., -0.0060,  0.0419, -0.0924],\n",
       "         ...,\n",
       "         [-0.0489,  0.0759,  0.0923,  ..., -0.0296, -0.0823,  0.0508],\n",
       "         [ 0.0807,  0.0574,  0.0544,  ...,  0.0358,  0.0541, -0.0645],\n",
       "         [ 0.0453, -0.0209, -0.0840,  ..., -0.1143, -0.0113, -0.0099]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.k_lin.bias': tensor([-0.8550, -0.9575,  0.4434,  ...,  3.2734,  2.6250, -3.4473],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.v_lin.weight': tensor([[ 0.0147,  0.0395, -0.0349,  ...,  0.0089,  0.0054,  0.0709],\n",
       "         [-0.1148,  0.0044,  0.0215,  ..., -0.0731,  0.0490,  0.0275],\n",
       "         [ 0.0214,  0.1035, -0.0464,  ..., -0.0443,  0.0454, -0.0004],\n",
       "         ...,\n",
       "         [ 0.0506, -0.0343, -0.0086,  ...,  0.0165,  0.0790, -0.0521],\n",
       "         [-0.0189,  0.0217,  0.0020,  ..., -0.0575, -0.0102,  0.0115],\n",
       "         [ 0.0190, -0.0331, -0.0972,  ..., -0.0690,  0.0441, -0.0471]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.v_lin.bias': tensor([ 0.0362,  0.0098,  0.0057,  ...,  0.0289,  0.0240, -0.0414],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.out_lin.weight': tensor([[-0.0041,  0.0811, -0.0045,  ...,  0.0187, -0.0185,  0.0095],\n",
       "         [ 0.0178,  0.0233, -0.0916,  ...,  0.0399,  0.0011,  0.0388],\n",
       "         [ 0.0156,  0.0382, -0.0121,  ...,  0.0069, -0.0313,  0.0237],\n",
       "         ...,\n",
       "         [-0.0107,  0.0635,  0.0764,  ..., -0.0250,  0.0937, -0.0369],\n",
       "         [-0.0045, -0.0231,  0.0089,  ...,  0.0616, -0.0612,  0.0663],\n",
       "         [-0.0394, -0.0218,  0.0052,  ..., -0.0108, -0.0547,  0.0573]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.4.out_lin.bias': tensor([-0.0014,  0.0017,  0.0007,  ..., -0.0096, -0.0039, -0.0081],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.q_lin.weight': tensor([[-0.0652, -0.0032, -0.1063,  ..., -0.0244, -0.0614,  0.0612],\n",
       "         [ 0.0180, -0.0564,  0.0019,  ...,  0.1289,  0.0436, -0.0083],\n",
       "         [-0.0444, -0.0141,  0.0049,  ..., -0.0644,  0.0157,  0.0701],\n",
       "         ...,\n",
       "         [-0.0007, -0.1107, -0.0499,  ...,  0.0476, -0.0714, -0.0472],\n",
       "         [-0.0295, -0.0382, -0.0248,  ..., -0.0374,  0.0054,  0.0707],\n",
       "         [ 0.0287, -0.0442, -0.0306,  ..., -0.0065, -0.0037,  0.0526]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.q_lin.bias': tensor([-0.0857,  0.1884, -0.0797,  ..., -0.1194, -0.0158,  0.2791],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.k_lin.weight': tensor([[ 0.0291, -0.0966, -0.0467,  ...,  0.0589,  0.0702,  0.0047],\n",
       "         [ 0.0369,  0.0034,  0.0159,  ...,  0.0684, -0.0358, -0.0467],\n",
       "         [ 0.0466, -0.0124, -0.0529,  ...,  0.0092,  0.0130,  0.0030],\n",
       "         ...,\n",
       "         [-0.0534,  0.0468, -0.0251,  ..., -0.1199, -0.0768, -0.0129],\n",
       "         [-0.0633,  0.0246, -0.0445,  ..., -0.0330,  0.0546,  0.0044],\n",
       "         [ 0.0275, -0.0037, -0.0208,  ...,  0.1007, -0.0388, -0.0194]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.k_lin.bias': tensor([-0.0364,  0.6230, -0.3999,  ..., -0.4846,  0.4460,  0.0729],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.v_lin.weight': tensor([[ 1.1368e-02,  1.5587e-02,  3.0777e-02,  ..., -3.4515e-02,\n",
       "          -1.4259e-02,  2.1957e-02],\n",
       "         [ 1.0406e-01,  4.0591e-05,  3.6591e-02,  ..., -2.3514e-02,\n",
       "          -5.9753e-02, -3.5736e-02],\n",
       "         [-5.6122e-02,  7.8201e-03,  2.6245e-03,  ..., -4.9103e-02,\n",
       "           2.7832e-02,  1.1681e-02],\n",
       "         ...,\n",
       "         [-5.1147e-02, -9.0103e-03, -7.1411e-02,  ..., -8.3313e-03,\n",
       "           2.6932e-02, -3.5797e-02],\n",
       "         [ 5.9967e-02,  2.8198e-02, -1.9028e-02,  ...,  2.3254e-02,\n",
       "           3.6560e-02, -9.3918e-03],\n",
       "         [-2.9129e-02, -4.6814e-02, -1.5821e-03,  ..., -4.0192e-02,\n",
       "           3.4515e-02, -3.6652e-02]], dtype=torch.float16),\n",
       " 'attentions.5.v_lin.bias': tensor([-0.0019,  0.0050, -0.0175,  ...,  0.0061,  0.0261,  0.0131],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.out_lin.weight': tensor([[ 0.0006, -0.0637,  0.0027,  ..., -0.0238,  0.0579, -0.0399],\n",
       "         [ 0.0154,  0.0568, -0.0033,  ...,  0.0185, -0.0366,  0.0253],\n",
       "         [-0.0320, -0.0348,  0.0147,  ..., -0.0371,  0.0132,  0.0064],\n",
       "         ...,\n",
       "         [-0.0861, -0.0598,  0.0033,  ...,  0.0009, -0.0272,  0.0029],\n",
       "         [ 0.0056,  0.0277,  0.0811,  ...,  0.0282,  0.0030,  0.0611],\n",
       "         [ 0.0205, -0.0101, -0.0248,  ..., -0.0356, -0.0320, -0.0183]],\n",
       "        dtype=torch.float16),\n",
       " 'attentions.5.out_lin.bias': tensor([-0.0010, -0.0147,  0.0208,  ...,  0.0020, -0.0163,  0.0132],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.0.weight': tensor([0.4712, 0.4229, 0.3940,  ..., 0.3726, 0.3804, 0.3962],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.0.bias': tensor([ 0.0020, -0.0575,  0.0043,  ...,  0.2175, -0.1443,  0.0602],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.1.weight': tensor([0.4480, 0.3967, 0.3914,  ..., 0.3599, 0.3635, 0.3904],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.1.bias': tensor([-0.0199, -0.0865,  0.0547,  ...,  0.0919, -0.0456,  0.0950],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.2.weight': tensor([0.4807, 0.3843, 0.3748,  ..., 0.3413, 0.3337, 0.3779],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.2.bias': tensor([ 0.0261, -0.1305, -0.0236,  ...,  0.0554,  0.0613,  0.0740],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.3.weight': tensor([0.4844, 0.3765, 0.3745,  ..., 0.3362, 0.3337, 0.3787],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.3.bias': tensor([ 0.0476, -0.1022,  0.0265,  ...,  0.0762,  0.0576,  0.0409],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.4.weight': tensor([0.4646, 0.3889, 0.3455,  ..., 0.3271, 0.3503, 0.3887],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.4.bias': tensor([ 0.0408, -0.0358,  0.0135,  ...,  0.0689,  0.0548,  0.0196],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.5.weight': tensor([0.4092, 0.4019, 0.3723,  ..., 0.3582, 0.3445, 0.4158],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm1.5.bias': tensor([ 0.0302, -0.0669,  0.0896,  ...,  0.1204,  0.1602,  0.0087],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.0.lin1.weight': tensor([[ 0.0007, -0.0422, -0.0061,  ..., -0.0985, -0.0322, -0.0010],\n",
       "         [ 0.0202,  0.0160, -0.0251,  ...,  0.0224,  0.0384,  0.0166],\n",
       "         [ 0.0310,  0.0129,  0.0010,  ..., -0.0720,  0.0677,  0.0501],\n",
       "         ...,\n",
       "         [ 0.0210, -0.0432,  0.0447,  ...,  0.0139,  0.0088, -0.0943],\n",
       "         [-0.0098, -0.0218,  0.0257,  ...,  0.0271,  0.0680,  0.0193],\n",
       "         [ 0.0338, -0.0103,  0.0428,  ...,  0.0626,  0.0759,  0.0077]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.0.lin1.bias': tensor([-0.0109, -0.0760, -0.0343,  ..., -0.0852, -0.0796, -0.0481],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.0.lin2.weight': tensor([[ 0.0088, -0.0275,  0.0637,  ...,  0.0074, -0.0379,  0.0243],\n",
       "         [-0.0121,  0.0244,  0.0258,  ...,  0.0368, -0.0152,  0.0274],\n",
       "         [-0.0024,  0.0300,  0.0003,  ..., -0.0744, -0.0080, -0.0366],\n",
       "         ...,\n",
       "         [ 0.0378,  0.0406,  0.0716,  ...,  0.0904, -0.0764, -0.0520],\n",
       "         [-0.0345, -0.0046, -0.0007,  ..., -0.0320, -0.0031,  0.0025],\n",
       "         [ 0.0010,  0.0051, -0.0495,  ..., -0.0055,  0.0056,  0.0134]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.0.lin2.bias': tensor([-0.0311,  0.0083, -0.0075,  ..., -0.0293, -0.0263,  0.0345],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin1.weight': tensor([[ 0.0007,  0.0620, -0.0337,  ..., -0.0637,  0.0470, -0.0246],\n",
       "         [-0.0092,  0.0086,  0.0195,  ..., -0.0276,  0.0393,  0.0104],\n",
       "         [-0.0403,  0.0284,  0.0389,  ..., -0.0580,  0.0966,  0.0159],\n",
       "         ...,\n",
       "         [ 0.0006,  0.0917, -0.0681,  ...,  0.0665,  0.1055,  0.0176],\n",
       "         [-0.0334, -0.0555,  0.0066,  ...,  0.0880,  0.0530,  0.1096],\n",
       "         [ 0.0309, -0.0598,  0.0203,  ..., -0.0037,  0.0774,  0.0291]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin1.bias': tensor([-0.0177, -0.2449, -0.0693,  ..., -0.0707, -0.1311, -0.0587],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin2.weight': tensor([[-0.0281, -0.0073, -0.0254,  ..., -0.0201,  0.0008,  0.0353],\n",
       "         [-0.0204, -0.0070,  0.0370,  ...,  0.1047,  0.0870, -0.0997],\n",
       "         [ 0.0193, -0.0085, -0.0489,  ...,  0.0591,  0.0648, -0.0010],\n",
       "         ...,\n",
       "         [-0.0635,  0.0362,  0.0112,  ...,  0.0592, -0.0180,  0.0460],\n",
       "         [ 0.0265, -0.0071,  0.0033,  ...,  0.1191,  0.1353, -0.0203],\n",
       "         [-0.0179, -0.0368, -0.0794,  ..., -0.1379, -0.0097,  0.0436]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.1.lin2.bias': tensor([-0.0060,  0.0115, -0.0646,  ...,  0.0149, -0.0020,  0.0096],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.2.lin1.weight': tensor([[-0.0139,  0.0313, -0.0180,  ...,  0.0679, -0.0549,  0.0288],\n",
       "         [-0.0106,  0.0690, -0.0363,  ..., -0.0415,  0.0344, -0.0978],\n",
       "         [-0.0063,  0.0479, -0.0700,  ...,  0.0824, -0.0221, -0.0417],\n",
       "         ...,\n",
       "         [ 0.0565,  0.0384, -0.0273,  ..., -0.0638, -0.0006,  0.0975],\n",
       "         [ 0.0184,  0.0108, -0.0679,  ..., -0.1029, -0.0191, -0.0641],\n",
       "         [-0.0005,  0.0721,  0.0406,  ..., -0.0679,  0.0453,  0.0370]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.2.lin1.bias': tensor([-0.0519, -0.0515,  0.0024,  ..., -0.0844, -0.0381, -0.0318],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.2.lin2.weight': tensor([[ 0.0070, -0.0068, -0.0003,  ...,  0.0480,  0.0171, -0.0159],\n",
       "         [ 0.0363, -0.0167,  0.0126,  ..., -0.0603,  0.0184,  0.0783],\n",
       "         [ 0.0036,  0.0230,  0.0336,  ..., -0.0554, -0.0089,  0.0223],\n",
       "         ...,\n",
       "         [ 0.0628, -0.0362, -0.0595,  ..., -0.0503, -0.0097, -0.0110],\n",
       "         [-0.0442, -0.0509, -0.0085,  ..., -0.0001,  0.0380, -0.0061],\n",
       "         [ 0.0043, -0.0093,  0.0198,  ..., -0.0134, -0.0250,  0.0525]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.2.lin2.bias': tensor([-0.0133,  0.0490, -0.0589,  ..., -0.0296, -0.0545, -0.0221],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.3.lin1.weight': tensor([[-0.0138, -0.0362, -0.0608,  ...,  0.0004, -0.0471,  0.0521],\n",
       "         [ 0.0202,  0.0316,  0.0145,  ...,  0.0738, -0.0511,  0.0267],\n",
       "         [-0.0072,  0.0684,  0.0477,  ..., -0.0596, -0.0135,  0.0644],\n",
       "         ...,\n",
       "         [-0.0080, -0.0089, -0.0329,  ...,  0.0011, -0.0356, -0.0132],\n",
       "         [ 0.0202,  0.0048, -0.0258,  ...,  0.0088, -0.0235,  0.0178],\n",
       "         [ 0.0233,  0.0261,  0.0778,  ..., -0.0297,  0.0468,  0.0266]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.3.lin1.bias': tensor([-0.0160, -0.0761,  0.0062,  ..., -0.0717, -0.0530, -0.0025],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.3.lin2.weight': tensor([[ 0.0268, -0.0094, -0.0058,  ..., -0.0035,  0.0051, -0.0198],\n",
       "         [-0.0173,  0.0476,  0.0087,  ..., -0.0147,  0.0105, -0.0047],\n",
       "         [ 0.0583,  0.1274, -0.0103,  ...,  0.0205, -0.0757, -0.0398],\n",
       "         ...,\n",
       "         [-0.0310, -0.0691,  0.0180,  ...,  0.0068, -0.0185,  0.0080],\n",
       "         [ 0.0273, -0.0080, -0.0120,  ..., -0.0470, -0.0533,  0.0035],\n",
       "         [-0.0215, -0.1024,  0.0116,  ...,  0.0353, -0.0309, -0.0076]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.3.lin2.bias': tensor([-0.0061,  0.0240, -0.0620,  ..., -0.0294, -0.0032, -0.0584],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin1.weight': tensor([[-0.0403,  0.0564, -0.0741,  ...,  0.0721, -0.1115, -0.0460],\n",
       "         [-0.0415,  0.0145, -0.0496,  ..., -0.0340,  0.0883, -0.1158],\n",
       "         [-0.0480,  0.0676,  0.0537,  ...,  0.0441, -0.0698, -0.0224],\n",
       "         ...,\n",
       "         [ 0.0542, -0.0162, -0.0431,  ..., -0.0077,  0.0360, -0.0208],\n",
       "         [ 0.0615,  0.0222,  0.0396,  ..., -0.0404,  0.0083,  0.0224],\n",
       "         [ 0.0729,  0.0449, -0.0033,  ...,  0.0079, -0.0576,  0.0162]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin1.bias': tensor([-0.0916, -0.0941, -0.0753,  ..., -0.0301, -0.0494, -0.0543],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin2.weight': tensor([[-0.0151, -0.0600, -0.0658,  ...,  0.0171,  0.0414,  0.1212],\n",
       "         [ 0.0057,  0.0150, -0.0118,  ..., -0.0213, -0.0140, -0.0477],\n",
       "         [-0.0526,  0.0341, -0.0359,  ...,  0.0231, -0.0930, -0.0945],\n",
       "         ...,\n",
       "         [-0.0266,  0.0607, -0.0302,  ...,  0.0003,  0.0215,  0.0321],\n",
       "         [-0.0468,  0.0363,  0.0282,  ..., -0.0090, -0.0459, -0.0569],\n",
       "         [-0.0242,  0.0309, -0.0355,  ..., -0.0215,  0.0445,  0.0622]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.4.lin2.bias': tensor([-0.0355,  0.0273, -0.0327,  ...,  0.0294,  0.0208, -0.0289],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin1.weight': tensor([[-0.0363,  0.0604, -0.0422,  ..., -0.1138,  0.1040, -0.1379],\n",
       "         [ 0.0359,  0.0100, -0.0083,  ...,  0.0510, -0.0461,  0.0044],\n",
       "         [ 0.0189, -0.0305, -0.0081,  ..., -0.0003,  0.0202, -0.0197],\n",
       "         ...,\n",
       "         [ 0.0022, -0.0038,  0.0044,  ..., -0.0020, -0.0805, -0.0123],\n",
       "         [ 0.0227,  0.0420,  0.0057,  ...,  0.0166, -0.0623, -0.0376],\n",
       "         [-0.0088, -0.0440, -0.0156,  ...,  0.0076,  0.0121,  0.0806]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin1.bias': tensor([-0.0724, -0.0308, -0.1382,  ..., -0.0644, -0.0447, -0.0426],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin2.weight': tensor([[ 0.0234, -0.0211,  0.0505,  ...,  0.0394, -0.0629, -0.0147],\n",
       "         [ 0.1150,  0.0366, -0.0087,  ..., -0.0290, -0.0562,  0.0009],\n",
       "         [ 0.0648, -0.0213,  0.0163,  ...,  0.0135,  0.0379,  0.0239],\n",
       "         ...,\n",
       "         [-0.0335, -0.0388, -0.0412,  ..., -0.0332,  0.0309,  0.0072],\n",
       "         [ 0.0776, -0.0124, -0.0125,  ..., -0.0635,  0.0110,  0.0064],\n",
       "         [-0.0765, -0.0048, -0.0095,  ..., -0.0129,  0.0225,  0.0006]],\n",
       "        dtype=torch.float16),\n",
       " 'ffns.5.lin2.bias': tensor([-0.0103,  0.0053, -0.0017,  ...,  0.0085, -0.0037,  0.0116],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.0.weight': tensor([0.5845, 0.5259, 0.5054,  ..., 0.4084, 0.4626, 0.5278],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.0.bias': tensor([-0.0050,  0.0632,  0.0094,  ..., -0.1214,  0.1025, -0.0444],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.1.weight': tensor([0.6011, 0.5366, 0.5083,  ..., 0.4585, 0.4807, 0.5254],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.1.bias': tensor([ 0.0194,  0.0606, -0.0400,  ..., -0.0543,  0.0469, -0.0469],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.2.weight': tensor([0.6509, 0.5659, 0.5303,  ..., 0.5127, 0.5410, 0.5640],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.2.bias': tensor([-0.0128,  0.0864, -0.0230,  ..., -0.0502, -0.0465, -0.0566],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.3.weight': tensor([0.6045, 0.5449, 0.5166,  ..., 0.5146, 0.5181, 0.5420],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.3.bias': tensor([-0.0200,  0.0376, -0.0291,  ..., -0.0511, -0.0533, -0.0215],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.4.weight': tensor([0.6465, 0.5459, 0.5317,  ..., 0.5293, 0.5322, 0.5527],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.4.bias': tensor([-0.0444,  0.0101, -0.0301,  ..., -0.0716, -0.0665,  0.0212],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.5.weight': tensor([2.3379, 2.3320, 2.5098,  ..., 2.6113, 2.4688, 2.6328],\n",
       "        dtype=torch.float16),\n",
       " 'layer_norm2.5.bias': tensor([ 0.0023, -0.0372, -0.1794,  ..., -0.0319, -0.0022,  0.1282],\n",
       "        dtype=torch.float16),\n",
       " 'pred_layer.proj.weight': tensor([[-0.0027,  0.0350, -0.0067,  ..., -0.0880,  0.0496,  0.0398],\n",
       "         [-0.0480,  0.0035,  0.0121,  ...,  0.0016, -0.0303,  0.0152],\n",
       "         [-0.0391,  0.0273,  0.0157,  ..., -0.0782, -0.0212,  0.0021],\n",
       "         ...,\n",
       "         [-0.0252, -0.0506, -0.0354,  ..., -0.0431,  0.0506,  0.0500],\n",
       "         [-0.0274,  0.0699,  0.0352,  ..., -0.0271, -0.0021, -0.0391],\n",
       "         [ 0.0297, -0.0688, -0.0042,  ..., -0.0880,  0.0251, -0.0300]],\n",
       "        dtype=torch.float16),\n",
       " 'pred_layer.proj.bias': tensor([-2.2363, -0.1102, -2.4336,  ..., -1.3066, -1.1992, -1.6650],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = AttrDict(model['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dump_path': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283',\n",
       " 'exp_name': 'bt_with_comments_sa_final_modif_test',\n",
       " 'save_periodic': 1,\n",
       " 'exp_id': '26703283',\n",
       " 'fp16': True,\n",
       " 'amp': 2,\n",
       " 'encoder_only': False,\n",
       " 'emb_dim': 1024,\n",
       " 'emb_dim_encoder': 1024,\n",
       " 'emb_dim_decoder': 1024,\n",
       " 'n_layers': 6,\n",
       " 'n_layers_encoder': 6,\n",
       " 'n_layers_decoder': 6,\n",
       " 'n_heads': 8,\n",
       " 'dropout': 0.1,\n",
       " 'attention_dropout': 0.0,\n",
       " 'gelu_activation': False,\n",
       " 'share_inout_emb': True,\n",
       " 'sinusoidal_embeddings': False,\n",
       " 'use_lang_emb': True,\n",
       " 'context_size': 0,\n",
       " 'word_pred': 0.15,\n",
       " 'sample_alpha': 0.0,\n",
       " 'word_mask_keep_rand': '0.8,0.1,0.1',\n",
       " 'word_shuffle': 3.0,\n",
       " 'word_dropout': 0.1,\n",
       " 'word_blank': 0.1,\n",
       " 'data_path': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test',\n",
       " 'lgs': 'cpp_sa-java_sa-python_sa',\n",
       " 'max_vocab': -1,\n",
       " 'min_count': 0,\n",
       " 'lg_sampling_factor': -1.0,\n",
       " 'has_sentences_ids': True,\n",
       " 'bptt': 256,\n",
       " 'max_len': 512,\n",
       " 'group_by_size': True,\n",
       " 'batch_size': 32,\n",
       " 'max_batch_size': 128,\n",
       " 'tokens_per_batch': 6000,\n",
       " 'gen_tpb_multiplier': 1,\n",
       " 'split_data': False,\n",
       " 'split_data_accross_gpu': 'global',\n",
       " 'optimizer': 'adam_inverse_sqrt,warmup_updates=10000,lr=0.0001,weight_decay=0.01',\n",
       " 'clip_grad_norm': 5.0,\n",
       " 'epoch_size': 30000,\n",
       " 'max_epoch': 10000000,\n",
       " 'stopping_criterion': '',\n",
       " 'validation_metrics': '',\n",
       " 'accumulate_gradients': 1,\n",
       " 'lambda_mlm': 1.0,\n",
       " 'lambda_clm': 1.0,\n",
       " 'lambda_ae': 0.970705,\n",
       " 'lambda_mt': 1.0,\n",
       " 'lambda_bt': 1.0,\n",
       " 'clm_steps': [],\n",
       " 'mlm_steps': [],\n",
       " 'mt_steps': [],\n",
       " 'ae_steps': ['cpp_sa', 'python_sa', 'java_sa'],\n",
       " 'bt_steps': [('python_sa', 'cpp_sa', 'python_sa'),\n",
       "  ('cpp_sa', 'python_sa', 'cpp_sa'),\n",
       "  ('java_sa', 'cpp_sa', 'java_sa'),\n",
       "  ('cpp_sa', 'java_sa', 'cpp_sa'),\n",
       "  ('python_sa', 'java_sa', 'python_sa'),\n",
       "  ('java_sa', 'python_sa', 'java_sa')],\n",
       " 'reload_emb': '',\n",
       " 'reload_model': '/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth,/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth',\n",
       " 'reload_checkpoint': '',\n",
       " 'beam_size': 1,\n",
       " 'length_penalty': 1.0,\n",
       " 'early_stopping': False,\n",
       " 'number_samples': 1,\n",
       " 'eval_temperature': None,\n",
       " 'bt_sample_temperature': 0.0,\n",
       " 'eval_bleu': True,\n",
       " 'eval_bleu_test_only': False,\n",
       " 'eval_computation': True,\n",
       " 'generate_hypothesis': True,\n",
       " 'eval_only': False,\n",
       " 'retry_mistmatching_types': False,\n",
       " 'debug_train': False,\n",
       " 'debug_slurm': False,\n",
       " 'debug': False,\n",
       " 'local_rank': 0,\n",
       " 'master_port': 14083,\n",
       " 'separate_decoders': False,\n",
       " 'n_share_dec': 0,\n",
       " 'langs': ['cpp_sa', 'java_sa', 'python_sa'],\n",
       " 'id2lang': {0: 'cpp_sa', 1: 'java_sa', 2: 'python_sa'},\n",
       " 'lang2id': {'cpp_sa': 0, 'java_sa': 1, 'python_sa': 2},\n",
       " 'n_langs': 3,\n",
       " 'bt_src_langs': ['python_sa',\n",
       "  'cpp_sa',\n",
       "  'java_sa',\n",
       "  'cpp_sa',\n",
       "  'python_sa',\n",
       "  'java_sa'],\n",
       " 'mono_dataset': {'cpp_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.cpp_sa.pth',\n",
       "   'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa.pth',\n",
       "   'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa.pth'},\n",
       "  'java_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.java_sa.pth',\n",
       "   'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa.pth',\n",
       "   'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa.pth'},\n",
       "  'python_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.python_sa.pth',\n",
       "   'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.python_sa.pth',\n",
       "   'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.python_sa.pth'}},\n",
       " 'para_dataset': {('cpp_sa',\n",
       "   'java_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-java_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-java_sa.java_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-java_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-java_sa.java_sa.pth')},\n",
       "  ('cpp_sa',\n",
       "   'python_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-python_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-python_sa.python_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-python_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-python_sa.python_sa.pth')},\n",
       "  ('java_sa',\n",
       "   'python_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa-python_sa.java_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa-python_sa.python_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa-python_sa.java_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa-python_sa.python_sa.pth')}},\n",
       " 'word_mask': 0.8,\n",
       " 'word_keep': 0.1,\n",
       " 'word_rand': 0.1,\n",
       " 'is_slurm_job': True,\n",
       " 'n_nodes': 4,\n",
       " 'node_id': 0,\n",
       " 'global_rank': 0,\n",
       " 'world_size': 32,\n",
       " 'n_gpu_per_node': 8,\n",
       " 'master_addr': 'learnfair1506',\n",
       " 'is_master': True,\n",
       " 'multi_node': True,\n",
       " 'multi_gpu': True,\n",
       " 'command': 'python /private/home/malachaux/workdir/bt_with_comments_sa_final_modif_test/2020_05_22_06_57_35/XLM/train.py --n_heads 8 --bt_steps \\'python_sa-cpp_sa-python_sa,cpp_sa-python_sa-cpp_sa,java_sa-cpp_sa-java_sa,cpp_sa-java_sa-cpp_sa,python_sa-java_sa-python_sa,java_sa-python_sa-java_sa\\' --max_vocab \\'-1\\' --word_mask_keep_rand \\'0.8,0.1,0.1\\' --gen_tpb_multiplier 1 --word_blank \\'0.1\\' --n_layers 6 --save_periodic 1 --dump_path \\'/checkpoint/malachaux/dumped/\\' --max_len 512 --bptt 256 --lambda_clm 1 --ae_steps \\'cpp_sa,python_sa,java_sa\\' --fp16 true --share_inout_emb true --lambda_mlm 1 --sinusoidal_embeddings false --mlm_steps \\'\\' --word_shuffle 3 --tokens_per_batch 6000 --has_sentences_ids true --attention_dropout 0 --split_data false --length_penalty 1 --max_epoch 10000000 --stopping_criterion \\'\\' --lambda_bt 1 --generate_hypothesis true --lambda_mt 1 --epoch_size 30000 --data_path \\'/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test\\' --gelu_activation false --split_data_accross_gpu global --optimizer \\'adam_inverse_sqrt,warmup_updates=10000,lr=0.0001,weight_decay=0.01\\' --eval_computation true --validation_metrics \\'\\' --eval_bleu true --dropout \\'0.1\\' --mt_steps \\'\\' --reload_emb \\'\\' --batch_size 32 --context_size 0 --word_dropout \\'0.1\\' --reload_model \\'/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth,/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth\\' --min_count 0 --eval_bleu_test_only false --group_by_size true --early_stopping false --sample_alpha 0 --word_pred \\'0.15\\' --amp 2 --max_batch_size 128 --clip_grad_norm 5 --emb_dim 1024 --encoder_only false --lgs \\'cpp_sa-java_sa-python_sa\\' --clm_steps \\'\\' --exp_name bt_with_comments_sa_final_modif_test --beam_size 1 --lambda_ae \\'0:1,100000:0.1,300000:0\\' --lg_sampling_factor \\'-1\\' --eval_only false --exp_id 26703283 --master_port 14083 --exp_id \"26703283\"',\n",
       " 'n_words': 63961,\n",
       " 'bos_index': 0,\n",
       " 'eos_index': 1,\n",
       " 'pad_index': 2,\n",
       " 'unk_index': 3,\n",
       " 'mask_index': 5,\n",
       " 'sep_index': 147,\n",
       " 'pred_probs': tensor([0.8000, 0.1000, 0.1000]),\n",
       " 'mask_scores': array([0., 0., 0., ..., 1., 1., 1.]),\n",
       " 'lambda_clm_config': None,\n",
       " 'lambda_mlm_config': None,\n",
       " 'lambda_ae_config': [(0, 1.0), (100000, 0.1), (300000, 0.0)],\n",
       " 'lambda_mt_config': None,\n",
       " 'lambda_bt_config': None,\n",
       " 'bt_sample_temperature_config': None,\n",
       " 'hyp_path': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses',\n",
       " 'eval_scripts_root': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts',\n",
       " 'ref_paths': {('java_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-cpp_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-java_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-cpp_sa.test.txt',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-java_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-cpp_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-cpp_sa.test.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-python_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-java_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-java_sa.test.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-python_sa.test.txt'},\n",
       " 'id_paths': {('cpp_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.test.txt',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.test.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.test.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.test.txt'},\n",
       " 'eval_scripts_folders': {('cpp_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-java_sa.valid',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-cpp_sa.valid',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-java_sa.test',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-cpp_sa.test',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-python_sa.valid',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-cpp_sa.valid',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-python_sa.test',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-cpp_sa.test',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-python_sa.valid',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-java_sa.valid',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-python_sa.test',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-java_sa.test'}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<XLM.src.data.dictionary.Dictionary at 0x7fad5da16910>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico = Dictionary(model['dico_id2word'], model['dico_word2id'], model['dico_counts'])\n",
    "\n",
    "dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63961 \t 63961\n",
      "0 \t 0 \t <s>\n",
      "1 \t 1 \t </s>\n",
      "2 \t 2 \t <pad>\n",
      "3 \t 3 \t <unk>\n",
      "5 \t 5 \t <special1>\n"
     ]
    }
   ],
   "source": [
    "print(model_params.n_words, '\\t', len(dico))\n",
    "print(model_params.bos_index, '\\t', dico.index(BOS_WORD), '\\t', dico.id2word[0]) ## start\n",
    "print(model_params.eos_index, '\\t', dico.index(EOS_WORD), '\\t', dico.id2word[1]) ## end of sentence\n",
    "print(model_params.pad_index, '\\t', dico.index(PAD_WORD), '\\t', dico.id2word[2])\n",
    "print(model_params.unk_index, '\\t', dico.index(UNK_WORD), '\\t', dico.id2word[3])\n",
    "print(model_params.mask_index, '\\t', dico.index(MASK_WORD), '\\t', dico.id2word[5]) # mask word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_getDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-a0f251e6749c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_getDevice'"
     ]
    }
   ],
   "source": [
    "torch._C._cuda_getDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params['reload_model'] = ','.join([MODEL_PATH] * 2)\n",
    "#model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_getDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-84505758f1f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdico\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Document/GitHub/cs-autograds-code-nmt/XLM/src/model/__init__.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(params, dico)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menc_path\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reloading encoder from %s ...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0menc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 enc_reload = torch.load(\n\u001b[0m\u001b[1;32m    181\u001b[0m                     enc_path, map_location=lambda storage, loc: storage.cuda(params.local_rank))\n\u001b[1;32m    182\u001b[0m                 \u001b[0menc_reload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_reload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'model'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menc_reload\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpdemo/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpdemo/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpdemo/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpdemo/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Document/GitHub/cs-autograds-code-nmt/XLM/src/model/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(storage, loc)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reloading encoder from %s ...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0menc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 enc_reload = torch.load(\n\u001b[0;32m--> 181\u001b[0;31m                     enc_path, map_location=lambda storage, loc: storage.cuda(params.local_rank))\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0menc_reload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_reload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'model'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menc_reload\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'module.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menc_reload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpdemo/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpdemo/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_getDevice'"
     ]
    }
   ],
   "source": [
    "encoder1, decoder1 = build_model(model_params, dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dump_path': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283',\n",
       " 'exp_name': 'bt_with_comments_sa_final_modif_test',\n",
       " 'save_periodic': 1,\n",
       " 'exp_id': '26703283',\n",
       " 'fp16': True,\n",
       " 'amp': 2,\n",
       " 'encoder_only': False,\n",
       " 'emb_dim': 1024,\n",
       " 'emb_dim_encoder': 1024,\n",
       " 'emb_dim_decoder': 1024,\n",
       " 'n_layers': 6,\n",
       " 'n_layers_encoder': 6,\n",
       " 'n_layers_decoder': 6,\n",
       " 'n_heads': 8,\n",
       " 'dropout': 0.1,\n",
       " 'attention_dropout': 0.0,\n",
       " 'gelu_activation': False,\n",
       " 'share_inout_emb': True,\n",
       " 'sinusoidal_embeddings': False,\n",
       " 'use_lang_emb': True,\n",
       " 'context_size': 0,\n",
       " 'word_pred': 0.15,\n",
       " 'sample_alpha': 0.0,\n",
       " 'word_mask_keep_rand': '0.8,0.1,0.1',\n",
       " 'word_shuffle': 3.0,\n",
       " 'word_dropout': 0.1,\n",
       " 'word_blank': 0.1,\n",
       " 'data_path': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test',\n",
       " 'lgs': 'cpp_sa-java_sa-python_sa',\n",
       " 'max_vocab': -1,\n",
       " 'min_count': 0,\n",
       " 'lg_sampling_factor': -1.0,\n",
       " 'has_sentences_ids': True,\n",
       " 'bptt': 256,\n",
       " 'max_len': 512,\n",
       " 'group_by_size': True,\n",
       " 'batch_size': 32,\n",
       " 'max_batch_size': 128,\n",
       " 'tokens_per_batch': 6000,\n",
       " 'gen_tpb_multiplier': 1,\n",
       " 'split_data': False,\n",
       " 'split_data_accross_gpu': 'global',\n",
       " 'optimizer': 'adam_inverse_sqrt,warmup_updates=10000,lr=0.0001,weight_decay=0.01',\n",
       " 'clip_grad_norm': 5.0,\n",
       " 'epoch_size': 30000,\n",
       " 'max_epoch': 10000000,\n",
       " 'stopping_criterion': '',\n",
       " 'validation_metrics': '',\n",
       " 'accumulate_gradients': 1,\n",
       " 'lambda_mlm': 1.0,\n",
       " 'lambda_clm': 1.0,\n",
       " 'lambda_ae': 0.970705,\n",
       " 'lambda_mt': 1.0,\n",
       " 'lambda_bt': 1.0,\n",
       " 'clm_steps': [],\n",
       " 'mlm_steps': [],\n",
       " 'mt_steps': [],\n",
       " 'ae_steps': ['cpp_sa', 'python_sa', 'java_sa'],\n",
       " 'bt_steps': [('python_sa', 'cpp_sa', 'python_sa'),\n",
       "  ('cpp_sa', 'python_sa', 'cpp_sa'),\n",
       "  ('java_sa', 'cpp_sa', 'java_sa'),\n",
       "  ('cpp_sa', 'java_sa', 'cpp_sa'),\n",
       "  ('python_sa', 'java_sa', 'python_sa'),\n",
       "  ('java_sa', 'python_sa', 'java_sa')],\n",
       " 'reload_emb': '',\n",
       " 'reload_model': 'model/model_1.pth,model/model_1.pth',\n",
       " 'reload_checkpoint': '',\n",
       " 'beam_size': 1,\n",
       " 'length_penalty': 1.0,\n",
       " 'early_stopping': False,\n",
       " 'number_samples': 1,\n",
       " 'eval_temperature': None,\n",
       " 'bt_sample_temperature': 0.0,\n",
       " 'eval_bleu': True,\n",
       " 'eval_bleu_test_only': False,\n",
       " 'eval_computation': True,\n",
       " 'generate_hypothesis': True,\n",
       " 'eval_only': False,\n",
       " 'retry_mistmatching_types': False,\n",
       " 'debug_train': False,\n",
       " 'debug_slurm': False,\n",
       " 'debug': False,\n",
       " 'local_rank': 0,\n",
       " 'master_port': 14083,\n",
       " 'separate_decoders': False,\n",
       " 'n_share_dec': 0,\n",
       " 'langs': ['cpp_sa', 'java_sa', 'python_sa'],\n",
       " 'id2lang': {0: 'cpp_sa', 1: 'java_sa', 2: 'python_sa'},\n",
       " 'lang2id': {'cpp_sa': 0, 'java_sa': 1, 'python_sa': 2},\n",
       " 'n_langs': 3,\n",
       " 'bt_src_langs': ['python_sa',\n",
       "  'cpp_sa',\n",
       "  'java_sa',\n",
       "  'cpp_sa',\n",
       "  'python_sa',\n",
       "  'java_sa'],\n",
       " 'mono_dataset': {'cpp_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.cpp_sa.pth',\n",
       "   'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa.pth',\n",
       "   'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa.pth'},\n",
       "  'java_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.java_sa.pth',\n",
       "   'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa.pth',\n",
       "   'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa.pth'},\n",
       "  'python_sa': {'train': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/train.python_sa.pth',\n",
       "   'valid': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.python_sa.pth',\n",
       "   'test': '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.python_sa.pth'}},\n",
       " 'para_dataset': {('cpp_sa',\n",
       "   'java_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-java_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-java_sa.java_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-java_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-java_sa.java_sa.pth')},\n",
       "  ('cpp_sa',\n",
       "   'python_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-python_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.cpp_sa-python_sa.python_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-python_sa.cpp_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.cpp_sa-python_sa.python_sa.pth')},\n",
       "  ('java_sa',\n",
       "   'python_sa'): {'valid': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa-python_sa.java_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/valid.java_sa-python_sa.python_sa.pth'), 'test': ('/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa-python_sa.java_sa.pth',\n",
       "    '/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test/test.java_sa-python_sa.python_sa.pth')}},\n",
       " 'word_mask': 0.8,\n",
       " 'word_keep': 0.1,\n",
       " 'word_rand': 0.1,\n",
       " 'is_slurm_job': True,\n",
       " 'n_nodes': 4,\n",
       " 'node_id': 0,\n",
       " 'global_rank': 0,\n",
       " 'world_size': 32,\n",
       " 'n_gpu_per_node': 8,\n",
       " 'master_addr': 'learnfair1506',\n",
       " 'is_master': True,\n",
       " 'multi_node': True,\n",
       " 'multi_gpu': True,\n",
       " 'command': 'python /private/home/malachaux/workdir/bt_with_comments_sa_final_modif_test/2020_05_22_06_57_35/XLM/train.py --n_heads 8 --bt_steps \\'python_sa-cpp_sa-python_sa,cpp_sa-python_sa-cpp_sa,java_sa-cpp_sa-java_sa,cpp_sa-java_sa-cpp_sa,python_sa-java_sa-python_sa,java_sa-python_sa-java_sa\\' --max_vocab \\'-1\\' --word_mask_keep_rand \\'0.8,0.1,0.1\\' --gen_tpb_multiplier 1 --word_blank \\'0.1\\' --n_layers 6 --save_periodic 1 --dump_path \\'/checkpoint/malachaux/dumped/\\' --max_len 512 --bptt 256 --lambda_clm 1 --ae_steps \\'cpp_sa,python_sa,java_sa\\' --fp16 true --share_inout_emb true --lambda_mlm 1 --sinusoidal_embeddings false --mlm_steps \\'\\' --word_shuffle 3 --tokens_per_batch 6000 --has_sentences_ids true --attention_dropout 0 --split_data false --length_penalty 1 --max_epoch 10000000 --stopping_criterion \\'\\' --lambda_bt 1 --generate_hypothesis true --lambda_mt 1 --epoch_size 30000 --data_path \\'/private/home/malachaux/data/XLM-cpp-java-python-with-comments-functions-sa-cl-split-test\\' --gelu_activation false --split_data_accross_gpu global --optimizer \\'adam_inverse_sqrt,warmup_updates=10000,lr=0.0001,weight_decay=0.01\\' --eval_computation true --validation_metrics \\'\\' --eval_bleu true --dropout \\'0.1\\' --mt_steps \\'\\' --reload_emb \\'\\' --batch_size 32 --context_size 0 --word_dropout \\'0.1\\' --reload_model \\'/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth,/checkpoint/malachaux/dumped/mlm_cpp_java_python_with_coms/24901617/checkpoint.pth\\' --min_count 0 --eval_bleu_test_only false --group_by_size true --early_stopping false --sample_alpha 0 --word_pred \\'0.15\\' --amp 2 --max_batch_size 128 --clip_grad_norm 5 --emb_dim 1024 --encoder_only false --lgs \\'cpp_sa-java_sa-python_sa\\' --clm_steps \\'\\' --exp_name bt_with_comments_sa_final_modif_test --beam_size 1 --lambda_ae \\'0:1,100000:0.1,300000:0\\' --lg_sampling_factor \\'-1\\' --eval_only false --exp_id 26703283 --master_port 14083 --exp_id \"26703283\"',\n",
       " 'n_words': 63961,\n",
       " 'bos_index': 0,\n",
       " 'eos_index': 1,\n",
       " 'pad_index': 2,\n",
       " 'unk_index': 3,\n",
       " 'mask_index': 5,\n",
       " 'sep_index': 147,\n",
       " 'pred_probs': tensor([0.8000, 0.1000, 0.1000]),\n",
       " 'mask_scores': array([0., 0., 0., ..., 1., 1., 1.]),\n",
       " 'lambda_clm_config': None,\n",
       " 'lambda_mlm_config': None,\n",
       " 'lambda_ae_config': [(0, 1.0), (100000, 0.1), (300000, 0.0)],\n",
       " 'lambda_mt_config': None,\n",
       " 'lambda_bt_config': None,\n",
       " 'bt_sample_temperature_config': None,\n",
       " 'hyp_path': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses',\n",
       " 'eval_scripts_root': '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts',\n",
       " 'ref_paths': {('java_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-cpp_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-java_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-cpp_sa.test.txt',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-java_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-cpp_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-cpp_sa.test.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.cpp_sa-python_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-java_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.python_sa-java_sa.test.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ref.java_sa-python_sa.test.txt'},\n",
       " 'id_paths': {('cpp_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.test.txt',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-java_sa.test.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.valid.txt',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.cpp_sa-python_sa.test.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.valid.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.valid.txt',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.test.txt',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/hypotheses/ids.java_sa-python_sa.test.txt'},\n",
       " 'eval_scripts_folders': {('cpp_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-java_sa.valid',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-cpp_sa.valid',\n",
       "  ('cpp_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-java_sa.test',\n",
       "  ('java_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-cpp_sa.test',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-python_sa.valid',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-cpp_sa.valid',\n",
       "  ('cpp_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/cpp_sa-python_sa.test',\n",
       "  ('python_sa',\n",
       "   'cpp_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-cpp_sa.test',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-python_sa.valid',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'valid'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-java_sa.valid',\n",
       "  ('java_sa',\n",
       "   'python_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/java_sa-python_sa.test',\n",
       "  ('python_sa',\n",
       "   'java_sa',\n",
       "   'test'): '/checkpoint/malachaux/dumped/bt_with_comments_sa_final_modif_test/26703283/eval_scripts/python_sa-java_sa.test'}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
